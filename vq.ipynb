{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 39832/39832 [00:30<00:00, 1305.41it/s]\n",
      "Nonterminal mappings: 100%|██████████| 39092/39092 [00:01<00:00, 21509.55it/s]\n",
      "Transform from strs to ints: 100%|██████████| 39092/39092 [00:05<00:00, 6985.61it/s]\n",
      "  0%|          | 0/39092 [00:00<?, ?it/s]/Users/phr/Desktop/Parser/training_/vq.py:46: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  ti, to = tuple(int(x[0]) for x in I.nonzero()), tuple(int(x[0]) for x in O.nonzero())\n",
      "100%|██████████| 39092/39092 [02:12<00:00, 295.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Loss: 19.122541\n",
      "Train Epoch: 1 Loss: 17.787765\n",
      "Train Epoch: 1 Loss: 16.532575\n",
      "Train Epoch: 1 Loss: 15.363268\n",
      "Train Epoch: 1 Loss: 14.281612\n",
      "Train Epoch: 1 Loss: 13.285691\n",
      "Train Epoch: 1 Loss: 12.371347\n",
      "Train Epoch: 1 Loss: 11.533268\n",
      "Train Epoch: 1 Loss: 10.765733\n",
      "Train Epoch: 1 Loss: 10.063013\n",
      "Train Epoch: 1 Loss: 9.419579\n",
      "Train Epoch: 1 Loss: 8.830201\n",
      "Train Epoch: 1 Loss: 8.290008\n",
      "Train Epoch: 1 Loss: 7.794498\n",
      "Train Epoch: 1 Loss: 7.339537\n",
      "Train Epoch: 1 Loss: 6.921363\n",
      "Train Epoch: 1 Loss: 6.536537\n",
      "Train Epoch: 1 Loss: 6.181962\n",
      "Train Epoch: 1 Loss: 5.854828\n",
      "Train Epoch: 1 Loss: 5.552599\n",
      "Train Epoch: 1 Loss: 5.272992\n",
      "Train Epoch: 1 Loss: 5.013951\n",
      "Train Epoch: 1 Loss: 4.773628\n",
      "Train Epoch: 2 Loss: 4.750559\n",
      "Train Epoch: 2 Loss: 4.528905\n",
      "Train Epoch: 2 Loss: 4.322656\n",
      "Train Epoch: 2 Loss: 4.130481\n",
      "Train Epoch: 2 Loss: 3.951174\n",
      "Train Epoch: 2 Loss: 3.783647\n",
      "Train Epoch: 2 Loss: 3.626923\n",
      "Train Epoch: 2 Loss: 3.480114\n",
      "Train Epoch: 2 Loss: 3.342421\n",
      "Train Epoch: 2 Loss: 3.213118\n",
      "Train Epoch: 2 Loss: 3.091552\n",
      "Train Epoch: 2 Loss: 2.977121\n",
      "Train Epoch: 2 Loss: 2.869287\n",
      "Train Epoch: 2 Loss: 2.767555\n",
      "Train Epoch: 2 Loss: 2.671479\n",
      "Train Epoch: 2 Loss: 2.580648\n",
      "Train Epoch: 2 Loss: 2.494689\n",
      "Train Epoch: 2 Loss: 2.413260\n",
      "Train Epoch: 2 Loss: 2.336047\n",
      "Train Epoch: 2 Loss: 2.262766\n",
      "Train Epoch: 2 Loss: 2.193151\n",
      "Train Epoch: 2 Loss: 2.126962\n",
      "Train Epoch: 2 Loss: 2.063977\n",
      "Train Epoch: 3 Loss: 2.057846\n",
      "Train Epoch: 3 Loss: 1.998148\n",
      "Train Epoch: 3 Loss: 1.941243\n",
      "Train Epoch: 3 Loss: 1.886955\n",
      "Train Epoch: 3 Loss: 1.835126\n",
      "Train Epoch: 3 Loss: 1.785609\n",
      "Train Epoch: 3 Loss: 1.738265\n",
      "Train Epoch: 3 Loss: 1.692968\n",
      "Train Epoch: 3 Loss: 1.649601\n",
      "Train Epoch: 3 Loss: 1.608052\n",
      "Train Epoch: 3 Loss: 1.568222\n",
      "Train Epoch: 3 Loss: 1.530014\n",
      "Train Epoch: 3 Loss: 1.493341\n",
      "Train Epoch: 3 Loss: 1.458120\n",
      "Train Epoch: 3 Loss: 1.424274\n",
      "Train Epoch: 3 Loss: 1.391730\n",
      "Train Epoch: 3 Loss: 1.360423\n",
      "Train Epoch: 3 Loss: 1.330288\n",
      "Train Epoch: 3 Loss: 1.301267\n",
      "Train Epoch: 3 Loss: 1.273305\n",
      "Train Epoch: 3 Loss: 1.246350\n",
      "Train Epoch: 3 Loss: 1.220352\n",
      "Train Epoch: 3 Loss: 1.195267\n",
      "Train Epoch: 4 Loss: 1.192807\n",
      "Train Epoch: 4 Loss: 1.168675\n",
      "Train Epoch: 4 Loss: 1.145367\n",
      "Train Epoch: 4 Loss: 1.122846\n",
      "Train Epoch: 4 Loss: 1.101077\n",
      "Train Epoch: 4 Loss: 1.080024\n",
      "Train Epoch: 4 Loss: 1.059656\n",
      "Train Epoch: 4 Loss: 1.039943\n",
      "Train Epoch: 4 Loss: 1.020858\n",
      "Train Epoch: 4 Loss: 1.002371\n",
      "Train Epoch: 4 Loss: 0.984459\n",
      "Train Epoch: 4 Loss: 0.967097\n",
      "Train Epoch: 4 Loss: 0.950263\n",
      "Train Epoch: 4 Loss: 0.933934\n",
      "Train Epoch: 4 Loss: 0.918090\n",
      "Train Epoch: 4 Loss: 0.902712\n",
      "Train Epoch: 4 Loss: 0.887781\n",
      "Train Epoch: 4 Loss: 0.873280\n",
      "Train Epoch: 4 Loss: 0.859191\n",
      "Train Epoch: 4 Loss: 0.845499\n",
      "Train Epoch: 4 Loss: 0.832189\n",
      "Train Epoch: 4 Loss: 0.819246\n",
      "Train Epoch: 4 Loss: 0.806656\n",
      "Train Epoch: 5 Loss: 0.805416\n",
      "Train Epoch: 5 Loss: 0.793200\n",
      "Train Epoch: 5 Loss: 0.781312\n",
      "Train Epoch: 5 Loss: 0.769738\n",
      "Train Epoch: 5 Loss: 0.758467\n",
      "Train Epoch: 5 Loss: 0.747490\n",
      "Train Epoch: 5 Loss: 0.736795\n",
      "Train Epoch: 5 Loss: 0.726373\n",
      "Train Epoch: 5 Loss: 0.716214\n",
      "Train Epoch: 5 Loss: 0.706309\n",
      "Train Epoch: 5 Loss: 0.696649\n",
      "Train Epoch: 5 Loss: 0.687227\n",
      "Train Epoch: 5 Loss: 0.678034\n",
      "Train Epoch: 5 Loss: 0.669063\n",
      "Train Epoch: 5 Loss: 0.660307\n",
      "Train Epoch: 5 Loss: 0.651758\n",
      "Train Epoch: 5 Loss: 0.643410\n",
      "Train Epoch: 5 Loss: 0.635256\n",
      "Train Epoch: 5 Loss: 0.627291\n",
      "Train Epoch: 5 Loss: 0.619508\n",
      "Train Epoch: 5 Loss: 0.611902\n",
      "Train Epoch: 5 Loss: 0.604467\n",
      "Train Epoch: 5 Loss: 0.597198\n",
      "Train Epoch: 6 Loss: 0.596481\n",
      "Train Epoch: 6 Loss: 0.589389\n",
      "Train Epoch: 6 Loss: 0.582453\n",
      "Train Epoch: 6 Loss: 0.575668\n",
      "Train Epoch: 6 Loss: 0.569029\n",
      "Train Epoch: 6 Loss: 0.562533\n",
      "Train Epoch: 6 Loss: 0.556175\n",
      "Train Epoch: 6 Loss: 0.549951\n",
      "Train Epoch: 6 Loss: 0.543857\n",
      "Train Epoch: 6 Loss: 0.537890\n",
      "Train Epoch: 6 Loss: 0.532046\n",
      "Train Epoch: 6 Loss: 0.526322\n",
      "Train Epoch: 6 Loss: 0.520714\n",
      "Train Epoch: 6 Loss: 0.515219\n",
      "Train Epoch: 6 Loss: 0.509834\n",
      "Train Epoch: 6 Loss: 0.504556\n",
      "Train Epoch: 6 Loss: 0.499382\n",
      "Train Epoch: 6 Loss: 0.494309\n",
      "Train Epoch: 6 Loss: 0.489335\n",
      "Train Epoch: 6 Loss: 0.484457\n",
      "Train Epoch: 6 Loss: 0.479672\n",
      "Train Epoch: 6 Loss: 0.474979\n",
      "Train Epoch: 6 Loss: 0.470374\n",
      "Train Epoch: 7 Loss: 0.469918\n",
      "Train Epoch: 7 Loss: 0.465409\n",
      "Train Epoch: 7 Loss: 0.460982\n",
      "Train Epoch: 7 Loss: 0.456639\n",
      "Train Epoch: 7 Loss: 0.452374\n",
      "Train Epoch: 7 Loss: 0.448188\n",
      "Train Epoch: 7 Loss: 0.444078\n",
      "Train Epoch: 7 Loss: 0.440042\n",
      "Train Epoch: 7 Loss: 0.436078\n",
      "Train Epoch: 7 Loss: 0.432184\n",
      "Train Epoch: 7 Loss: 0.428359\n",
      "Train Epoch: 7 Loss: 0.424602\n",
      "Train Epoch: 7 Loss: 0.420909\n",
      "Train Epoch: 7 Loss: 0.417281\n",
      "Train Epoch: 7 Loss: 0.413716\n",
      "Train Epoch: 7 Loss: 0.410211\n",
      "Train Epoch: 7 Loss: 0.406766\n",
      "Train Epoch: 7 Loss: 0.403379\n",
      "Train Epoch: 7 Loss: 0.400049\n",
      "Train Epoch: 7 Loss: 0.396775\n",
      "Train Epoch: 7 Loss: 0.393555\n",
      "Train Epoch: 7 Loss: 0.390388\n",
      "Train Epoch: 7 Loss: 0.387274\n",
      "Train Epoch: 8 Loss: 0.386965\n",
      "Train Epoch: 8 Loss: 0.383906\n",
      "Train Epoch: 8 Loss: 0.380897\n",
      "Train Epoch: 8 Loss: 0.377936\n",
      "Train Epoch: 8 Loss: 0.375022\n",
      "Train Epoch: 8 Loss: 0.372155\n",
      "Train Epoch: 8 Loss: 0.369333\n",
      "Train Epoch: 8 Loss: 0.366556\n",
      "Train Epoch: 8 Loss: 0.363822\n",
      "Train Epoch: 8 Loss: 0.361130\n",
      "Train Epoch: 8 Loss: 0.358481\n",
      "Train Epoch: 8 Loss: 0.355872\n",
      "Train Epoch: 8 Loss: 0.353303\n",
      "Train Epoch: 8 Loss: 0.350773\n",
      "Train Epoch: 8 Loss: 0.348281\n",
      "Train Epoch: 8 Loss: 0.345827\n",
      "Train Epoch: 8 Loss: 0.343410\n",
      "Train Epoch: 8 Loss: 0.341028\n",
      "Train Epoch: 8 Loss: 0.338683\n",
      "Train Epoch: 8 Loss: 0.336371\n",
      "Train Epoch: 8 Loss: 0.334094\n",
      "Train Epoch: 8 Loss: 0.331849\n",
      "Train Epoch: 8 Loss: 0.329637\n",
      "Train Epoch: 9 Loss: 0.329418\n",
      "Train Epoch: 9 Loss: 0.327241\n",
      "Train Epoch: 9 Loss: 0.325096\n",
      "Train Epoch: 9 Loss: 0.322981\n",
      "Train Epoch: 9 Loss: 0.320896\n",
      "Train Epoch: 9 Loss: 0.318841\n",
      "Train Epoch: 9 Loss: 0.316815\n",
      "Train Epoch: 9 Loss: 0.314817\n",
      "Train Epoch: 9 Loss: 0.312847\n",
      "Train Epoch: 9 Loss: 0.310904\n",
      "Train Epoch: 9 Loss: 0.308988\n",
      "Train Epoch: 9 Loss: 0.307098\n",
      "Train Epoch: 9 Loss: 0.305234\n",
      "Train Epoch: 9 Loss: 0.303396\n",
      "Train Epoch: 9 Loss: 0.301582\n",
      "Train Epoch: 9 Loss: 0.299793\n",
      "Train Epoch: 9 Loss: 0.298027\n",
      "Train Epoch: 9 Loss: 0.296286\n",
      "Train Epoch: 9 Loss: 0.294567\n",
      "Train Epoch: 9 Loss: 0.292871\n",
      "Train Epoch: 9 Loss: 0.291198\n",
      "Train Epoch: 9 Loss: 0.289546\n",
      "Train Epoch: 9 Loss: 0.287916\n",
      "Train Epoch: 10 Loss: 0.287754\n",
      "Train Epoch: 10 Loss: 0.286147\n",
      "Train Epoch: 10 Loss: 0.284561\n",
      "Train Epoch: 10 Loss: 0.282995\n",
      "Train Epoch: 10 Loss: 0.281449\n",
      "Train Epoch: 10 Loss: 0.279923\n",
      "Train Epoch: 10 Loss: 0.278417\n",
      "Train Epoch: 10 Loss: 0.276929\n",
      "Train Epoch: 10 Loss: 0.275460\n",
      "Train Epoch: 10 Loss: 0.274010\n",
      "Train Epoch: 10 Loss: 0.272577\n",
      "Train Epoch: 10 Loss: 0.271162\n",
      "Train Epoch: 10 Loss: 0.269765\n",
      "Train Epoch: 10 Loss: 0.268385\n",
      "Train Epoch: 10 Loss: 0.267022\n",
      "Train Epoch: 10 Loss: 0.265676\n",
      "Train Epoch: 10 Loss: 0.264346\n",
      "Train Epoch: 10 Loss: 0.263032\n",
      "Train Epoch: 10 Loss: 0.261733\n",
      "Train Epoch: 10 Loss: 0.260451\n",
      "Train Epoch: 10 Loss: 0.259184\n",
      "Train Epoch: 10 Loss: 0.257931\n",
      "Train Epoch: 10 Loss: 0.256694\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.122935\n",
      "Train Epoch: 1 Loss: 17.788327\n",
      "Train Epoch: 1 Loss: 16.533308\n",
      "Train Epoch: 1 Loss: 15.364182\n",
      "Train Epoch: 1 Loss: 14.282677\n",
      "Train Epoch: 1 Loss: 13.286891\n",
      "Train Epoch: 1 Loss: 12.372623\n",
      "Train Epoch: 1 Loss: 11.534566\n",
      "Train Epoch: 1 Loss: 10.766986\n",
      "Train Epoch: 1 Loss: 10.064163\n",
      "Train Epoch: 1 Loss: 9.420572\n",
      "Train Epoch: 1 Loss: 8.830987\n",
      "Train Epoch: 1 Loss: 8.290549\n",
      "Train Epoch: 1 Loss: 7.794765\n",
      "Train Epoch: 1 Loss: 7.339514\n",
      "Train Epoch: 1 Loss: 6.921027\n",
      "Train Epoch: 1 Loss: 6.535890\n",
      "Train Epoch: 1 Loss: 6.180996\n",
      "Train Epoch: 1 Loss: 5.853543\n",
      "Train Epoch: 1 Loss: 5.551003\n",
      "Train Epoch: 1 Loss: 5.271092\n",
      "Train Epoch: 1 Loss: 5.011756\n",
      "Train Epoch: 1 Loss: 4.771144\n",
      "Train Epoch: 2 Loss: 4.748048\n",
      "Train Epoch: 2 Loss: 4.526117\n",
      "Train Epoch: 2 Loss: 4.319606\n",
      "Train Epoch: 2 Loss: 4.127177\n",
      "Train Epoch: 2 Loss: 3.947627\n",
      "Train Epoch: 2 Loss: 3.779871\n",
      "Train Epoch: 2 Loss: 3.622926\n",
      "Train Epoch: 2 Loss: 3.475908\n",
      "Train Epoch: 2 Loss: 3.338015\n",
      "Train Epoch: 2 Loss: 3.208524\n",
      "Train Epoch: 2 Loss: 3.086776\n",
      "Train Epoch: 2 Loss: 2.972175\n",
      "Train Epoch: 2 Loss: 2.864178\n",
      "Train Epoch: 2 Loss: 2.762293\n",
      "Train Epoch: 2 Loss: 2.666070\n",
      "Train Epoch: 2 Loss: 2.575099\n",
      "Train Epoch: 2 Loss: 2.489009\n",
      "Train Epoch: 2 Loss: 2.407453\n",
      "Train Epoch: 2 Loss: 2.330121\n",
      "Train Epoch: 2 Loss: 2.256725\n",
      "Train Epoch: 2 Loss: 2.187003\n",
      "Train Epoch: 2 Loss: 2.120710\n",
      "Train Epoch: 2 Loss: 2.057627\n",
      "Train Epoch: 3 Loss: 2.051487\n",
      "Train Epoch: 3 Loss: 1.991696\n",
      "Train Epoch: 3 Loss: 1.934701\n",
      "Train Epoch: 3 Loss: 1.880328\n",
      "Train Epoch: 3 Loss: 1.828418\n",
      "Train Epoch: 3 Loss: 1.778823\n",
      "Train Epoch: 3 Loss: 1.731405\n",
      "Train Epoch: 3 Loss: 1.686037\n",
      "Train Epoch: 3 Loss: 1.642602\n",
      "Train Epoch: 3 Loss: 1.600989\n",
      "Train Epoch: 3 Loss: 1.561095\n",
      "Train Epoch: 3 Loss: 1.522828\n",
      "Train Epoch: 3 Loss: 1.486097\n",
      "Train Epoch: 3 Loss: 1.450821\n",
      "Train Epoch: 3 Loss: 1.416921\n",
      "Train Epoch: 3 Loss: 1.384327\n",
      "Train Epoch: 3 Loss: 1.352970\n",
      "Train Epoch: 3 Loss: 1.322789\n",
      "Train Epoch: 3 Loss: 1.293723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 Loss: 1.265716\n",
      "Train Epoch: 3 Loss: 1.238718\n",
      "Train Epoch: 3 Loss: 1.212680\n",
      "Train Epoch: 3 Loss: 1.187555\n",
      "Train Epoch: 4 Loss: 1.185091\n",
      "Train Epoch: 4 Loss: 1.160922\n",
      "Train Epoch: 4 Loss: 1.137578\n",
      "Train Epoch: 4 Loss: 1.115022\n",
      "Train Epoch: 4 Loss: 1.093218\n",
      "Train Epoch: 4 Loss: 1.072132\n",
      "Train Epoch: 4 Loss: 1.051732\n",
      "Train Epoch: 4 Loss: 1.031989\n",
      "Train Epoch: 4 Loss: 1.012873\n",
      "Train Epoch: 4 Loss: 0.994358\n",
      "Train Epoch: 4 Loss: 0.976418\n",
      "Train Epoch: 4 Loss: 0.959029\n",
      "Train Epoch: 4 Loss: 0.942168\n",
      "Train Epoch: 4 Loss: 0.925814\n",
      "Train Epoch: 4 Loss: 0.909945\n",
      "Train Epoch: 4 Loss: 0.894543\n",
      "Train Epoch: 4 Loss: 0.879589\n",
      "Train Epoch: 4 Loss: 0.865064\n",
      "Train Epoch: 4 Loss: 0.850953\n",
      "Train Epoch: 4 Loss: 0.837240\n",
      "Train Epoch: 4 Loss: 0.823909\n",
      "Train Epoch: 4 Loss: 0.810946\n",
      "Train Epoch: 4 Loss: 0.798337\n",
      "Train Epoch: 5 Loss: 0.797095\n",
      "Train Epoch: 5 Loss: 0.784860\n",
      "Train Epoch: 5 Loss: 0.772953\n",
      "Train Epoch: 5 Loss: 0.761361\n",
      "Train Epoch: 5 Loss: 0.750073\n",
      "Train Epoch: 5 Loss: 0.739078\n",
      "Train Epoch: 5 Loss: 0.728366\n",
      "Train Epoch: 5 Loss: 0.717928\n",
      "Train Epoch: 5 Loss: 0.707753\n",
      "Train Epoch: 5 Loss: 0.697832\n",
      "Train Epoch: 5 Loss: 0.688158\n",
      "Train Epoch: 5 Loss: 0.678721\n",
      "Train Epoch: 5 Loss: 0.669514\n",
      "Train Epoch: 5 Loss: 0.660529\n",
      "Train Epoch: 5 Loss: 0.651758\n",
      "Train Epoch: 5 Loss: 0.643196\n",
      "Train Epoch: 5 Loss: 0.634835\n",
      "Train Epoch: 5 Loss: 0.626669\n",
      "Train Epoch: 5 Loss: 0.618691\n",
      "Train Epoch: 5 Loss: 0.610896\n",
      "Train Epoch: 5 Loss: 0.603278\n",
      "Train Epoch: 5 Loss: 0.595832\n",
      "Train Epoch: 5 Loss: 0.588552\n",
      "Train Epoch: 6 Loss: 0.587833\n",
      "Train Epoch: 6 Loss: 0.580730\n",
      "Train Epoch: 6 Loss: 0.573783\n",
      "Train Epoch: 6 Loss: 0.566987\n",
      "Train Epoch: 6 Loss: 0.560338\n",
      "Train Epoch: 6 Loss: 0.553832\n",
      "Train Epoch: 6 Loss: 0.547464\n",
      "Train Epoch: 6 Loss: 0.541230\n",
      "Train Epoch: 6 Loss: 0.535127\n",
      "Train Epoch: 6 Loss: 0.529151\n",
      "Train Epoch: 6 Loss: 0.523298\n",
      "Train Epoch: 6 Loss: 0.517565\n",
      "Train Epoch: 6 Loss: 0.511948\n",
      "Train Epoch: 6 Loss: 0.506444\n",
      "Train Epoch: 6 Loss: 0.501051\n",
      "Train Epoch: 6 Loss: 0.495764\n",
      "Train Epoch: 6 Loss: 0.490582\n",
      "Train Epoch: 6 Loss: 0.485502\n",
      "Train Epoch: 6 Loss: 0.480520\n",
      "Train Epoch: 6 Loss: 0.475634\n",
      "Train Epoch: 6 Loss: 0.470842\n",
      "Train Epoch: 6 Loss: 0.466141\n",
      "Train Epoch: 6 Loss: 0.461529\n",
      "Train Epoch: 7 Loss: 0.461073\n",
      "Train Epoch: 7 Loss: 0.456556\n",
      "Train Epoch: 7 Loss: 0.452123\n",
      "Train Epoch: 7 Loss: 0.447773\n",
      "Train Epoch: 7 Loss: 0.443502\n",
      "Train Epoch: 7 Loss: 0.439309\n",
      "Train Epoch: 7 Loss: 0.435192\n",
      "Train Epoch: 7 Loss: 0.431150\n",
      "Train Epoch: 7 Loss: 0.427179\n",
      "Train Epoch: 7 Loss: 0.423280\n",
      "Train Epoch: 7 Loss: 0.419449\n",
      "Train Epoch: 7 Loss: 0.415685\n",
      "Train Epoch: 7 Loss: 0.411988\n",
      "Train Epoch: 7 Loss: 0.408354\n",
      "Train Epoch: 7 Loss: 0.404783\n",
      "Train Epoch: 7 Loss: 0.401273\n",
      "Train Epoch: 7 Loss: 0.397822\n",
      "Train Epoch: 7 Loss: 0.394430\n",
      "Train Epoch: 7 Loss: 0.391095\n",
      "Train Epoch: 7 Loss: 0.387816\n",
      "Train Epoch: 7 Loss: 0.384591\n",
      "Train Epoch: 7 Loss: 0.381419\n",
      "Train Epoch: 7 Loss: 0.378300\n",
      "Train Epoch: 8 Loss: 0.377990\n",
      "Train Epoch: 8 Loss: 0.374927\n",
      "Train Epoch: 8 Loss: 0.371913\n",
      "Train Epoch: 8 Loss: 0.368947\n",
      "Train Epoch: 8 Loss: 0.366029\n",
      "Train Epoch: 8 Loss: 0.363157\n",
      "Train Epoch: 8 Loss: 0.360331\n",
      "Train Epoch: 8 Loss: 0.357549\n",
      "Train Epoch: 8 Loss: 0.354811\n",
      "Train Epoch: 8 Loss: 0.352116\n",
      "Train Epoch: 8 Loss: 0.349462\n",
      "Train Epoch: 8 Loss: 0.346849\n",
      "Train Epoch: 8 Loss: 0.344276\n",
      "Train Epoch: 8 Loss: 0.341742\n",
      "Train Epoch: 8 Loss: 0.339246\n",
      "Train Epoch: 8 Loss: 0.336788\n",
      "Train Epoch: 8 Loss: 0.334367\n",
      "Train Epoch: 8 Loss: 0.331982\n",
      "Train Epoch: 8 Loss: 0.329633\n",
      "Train Epoch: 8 Loss: 0.327318\n",
      "Train Epoch: 8 Loss: 0.325037\n",
      "Train Epoch: 8 Loss: 0.322789\n",
      "Train Epoch: 8 Loss: 0.320574\n",
      "Train Epoch: 9 Loss: 0.320354\n",
      "Train Epoch: 9 Loss: 0.318174\n",
      "Train Epoch: 9 Loss: 0.316025\n",
      "Train Epoch: 9 Loss: 0.313907\n",
      "Train Epoch: 9 Loss: 0.311819\n",
      "Train Epoch: 9 Loss: 0.309760\n",
      "Train Epoch: 9 Loss: 0.307731\n",
      "Train Epoch: 9 Loss: 0.305730\n",
      "Train Epoch: 9 Loss: 0.303757\n",
      "Train Epoch: 9 Loss: 0.301811\n",
      "Train Epoch: 9 Loss: 0.299892\n",
      "Train Epoch: 9 Loss: 0.297999\n",
      "Train Epoch: 9 Loss: 0.296132\n",
      "Train Epoch: 9 Loss: 0.294291\n",
      "Train Epoch: 9 Loss: 0.292474\n",
      "Train Epoch: 9 Loss: 0.290682\n",
      "Train Epoch: 9 Loss: 0.288914\n",
      "Train Epoch: 9 Loss: 0.287170\n",
      "Train Epoch: 9 Loss: 0.285448\n",
      "Train Epoch: 9 Loss: 0.283750\n",
      "Train Epoch: 9 Loss: 0.282074\n",
      "Train Epoch: 9 Loss: 0.280420\n",
      "Train Epoch: 9 Loss: 0.278787\n",
      "Train Epoch: 10 Loss: 0.278625\n",
      "Train Epoch: 10 Loss: 0.277015\n",
      "Train Epoch: 10 Loss: 0.275427\n",
      "Train Epoch: 10 Loss: 0.273858\n",
      "Train Epoch: 10 Loss: 0.272310\n",
      "Train Epoch: 10 Loss: 0.270782\n",
      "Train Epoch: 10 Loss: 0.269273\n",
      "Train Epoch: 10 Loss: 0.267783\n",
      "Train Epoch: 10 Loss: 0.266312\n",
      "Train Epoch: 10 Loss: 0.264859\n",
      "Train Epoch: 10 Loss: 0.263424\n",
      "Train Epoch: 10 Loss: 0.262007\n",
      "Train Epoch: 10 Loss: 0.260608\n",
      "Train Epoch: 10 Loss: 0.259226\n",
      "Train Epoch: 10 Loss: 0.257861\n",
      "Train Epoch: 10 Loss: 0.256512\n",
      "Train Epoch: 10 Loss: 0.255180\n",
      "Train Epoch: 10 Loss: 0.253864\n",
      "Train Epoch: 10 Loss: 0.252564\n",
      "Train Epoch: 10 Loss: 0.251279\n",
      "Train Epoch: 10 Loss: 0.250010\n",
      "Train Epoch: 10 Loss: 0.248756\n",
      "Train Epoch: 10 Loss: 0.247517\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.143064\n",
      "Train Epoch: 1 Loss: 17.807355\n",
      "Train Epoch: 1 Loss: 16.551230\n",
      "Train Epoch: 1 Loss: 15.380980\n",
      "Train Epoch: 1 Loss: 14.298371\n",
      "Train Epoch: 1 Loss: 13.301503\n",
      "Train Epoch: 1 Loss: 12.386221\n",
      "Train Epoch: 1 Loss: 11.547215\n",
      "Train Epoch: 1 Loss: 10.778779\n",
      "Train Epoch: 1 Loss: 10.075193\n",
      "Train Epoch: 1 Loss: 9.430922\n",
      "Train Epoch: 1 Loss: 8.840752\n",
      "Train Epoch: 1 Loss: 8.299800\n",
      "Train Epoch: 1 Loss: 7.803577\n",
      "Train Epoch: 1 Loss: 7.347942\n",
      "Train Epoch: 1 Loss: 6.929126\n",
      "Train Epoch: 1 Loss: 6.543701\n",
      "Train Epoch: 1 Loss: 6.188555\n",
      "Train Epoch: 1 Loss: 5.860881\n",
      "Train Epoch: 1 Loss: 5.558146\n",
      "Train Epoch: 1 Loss: 5.278063\n",
      "Train Epoch: 1 Loss: 5.018571\n",
      "Train Epoch: 1 Loss: 4.777823\n",
      "Train Epoch: 2 Loss: 4.754712\n",
      "Train Epoch: 2 Loss: 4.532659\n",
      "Train Epoch: 2 Loss: 4.326036\n",
      "Train Epoch: 2 Loss: 4.133507\n",
      "Train Epoch: 2 Loss: 3.953865\n",
      "Train Epoch: 2 Loss: 3.786023\n",
      "Train Epoch: 2 Loss: 3.629002\n",
      "Train Epoch: 2 Loss: 3.481912\n",
      "Train Epoch: 2 Loss: 3.343954\n",
      "Train Epoch: 2 Loss: 3.214402\n",
      "Train Epoch: 2 Loss: 3.092597\n",
      "Train Epoch: 2 Loss: 2.977944\n",
      "Train Epoch: 2 Loss: 2.869897\n",
      "Train Epoch: 2 Loss: 2.767967\n",
      "Train Epoch: 2 Loss: 2.671702\n",
      "Train Epoch: 2 Loss: 2.580692\n",
      "Train Epoch: 2 Loss: 2.494563\n",
      "Train Epoch: 2 Loss: 2.412973\n",
      "Train Epoch: 2 Loss: 2.335608\n",
      "Train Epoch: 2 Loss: 2.262182\n",
      "Train Epoch: 2 Loss: 2.192429\n",
      "Train Epoch: 2 Loss: 2.126110\n",
      "Train Epoch: 2 Loss: 2.063001\n",
      "Train Epoch: 3 Loss: 2.056857\n",
      "Train Epoch: 3 Loss: 1.997042\n",
      "Train Epoch: 3 Loss: 1.940025\n",
      "Train Epoch: 3 Loss: 1.885631\n",
      "Train Epoch: 3 Loss: 1.833701\n",
      "Train Epoch: 3 Loss: 1.784086\n",
      "Train Epoch: 3 Loss: 1.736650\n",
      "Train Epoch: 3 Loss: 1.691265\n",
      "Train Epoch: 3 Loss: 1.647812\n",
      "Train Epoch: 3 Loss: 1.606183\n",
      "Train Epoch: 3 Loss: 1.566276\n",
      "Train Epoch: 3 Loss: 1.527994\n",
      "Train Epoch: 3 Loss: 1.491250\n",
      "Train Epoch: 3 Loss: 1.455960\n",
      "Train Epoch: 3 Loss: 1.422049\n",
      "Train Epoch: 3 Loss: 1.389443\n",
      "Train Epoch: 3 Loss: 1.358075\n",
      "Train Epoch: 3 Loss: 1.327883\n",
      "Train Epoch: 3 Loss: 1.298807\n",
      "Train Epoch: 3 Loss: 1.270791\n",
      "Train Epoch: 3 Loss: 1.243784\n",
      "Train Epoch: 3 Loss: 1.217736\n",
      "Train Epoch: 3 Loss: 1.192603\n",
      "Train Epoch: 4 Loss: 1.190139\n",
      "Train Epoch: 4 Loss: 1.165961\n",
      "Train Epoch: 4 Loss: 1.142609\n",
      "Train Epoch: 4 Loss: 1.120046\n",
      "Train Epoch: 4 Loss: 1.098235\n",
      "Train Epoch: 4 Loss: 1.077142\n",
      "Train Epoch: 4 Loss: 1.056735\n",
      "Train Epoch: 4 Loss: 1.036986\n",
      "Train Epoch: 4 Loss: 1.017864\n",
      "Train Epoch: 4 Loss: 0.999343\n",
      "Train Epoch: 4 Loss: 0.981397\n",
      "Train Epoch: 4 Loss: 0.964003\n",
      "Train Epoch: 4 Loss: 0.947137\n",
      "Train Epoch: 4 Loss: 0.930777\n",
      "Train Epoch: 4 Loss: 0.914904\n",
      "Train Epoch: 4 Loss: 0.899497\n",
      "Train Epoch: 4 Loss: 0.884538\n",
      "Train Epoch: 4 Loss: 0.870010\n",
      "Train Epoch: 4 Loss: 0.855895\n",
      "Train Epoch: 4 Loss: 0.842177\n",
      "Train Epoch: 4 Loss: 0.828842\n",
      "Train Epoch: 4 Loss: 0.815875\n",
      "Train Epoch: 4 Loss: 0.803263\n",
      "Train Epoch: 5 Loss: 0.802020\n",
      "Train Epoch: 5 Loss: 0.789782\n",
      "Train Epoch: 5 Loss: 0.777871\n",
      "Train Epoch: 5 Loss: 0.766276\n",
      "Train Epoch: 5 Loss: 0.754985\n",
      "Train Epoch: 5 Loss: 0.743987\n",
      "Train Epoch: 5 Loss: 0.733272\n",
      "Train Epoch: 5 Loss: 0.722831\n",
      "Train Epoch: 5 Loss: 0.712653\n",
      "Train Epoch: 5 Loss: 0.702730\n",
      "Train Epoch: 5 Loss: 0.693053\n",
      "Train Epoch: 5 Loss: 0.683613\n",
      "Train Epoch: 5 Loss: 0.674404\n",
      "Train Epoch: 5 Loss: 0.665416\n",
      "Train Epoch: 5 Loss: 0.656644\n",
      "Train Epoch: 5 Loss: 0.648079\n",
      "Train Epoch: 5 Loss: 0.639716\n",
      "Train Epoch: 5 Loss: 0.631547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Loss: 0.623568\n",
      "Train Epoch: 5 Loss: 0.615771\n",
      "Train Epoch: 5 Loss: 0.608151\n",
      "Train Epoch: 5 Loss: 0.600702\n",
      "Train Epoch: 5 Loss: 0.593421\n",
      "Train Epoch: 6 Loss: 0.592701\n",
      "Train Epoch: 6 Loss: 0.585597\n",
      "Train Epoch: 6 Loss: 0.578648\n",
      "Train Epoch: 6 Loss: 0.571851\n",
      "Train Epoch: 6 Loss: 0.565200\n",
      "Train Epoch: 6 Loss: 0.558692\n",
      "Train Epoch: 6 Loss: 0.552322\n",
      "Train Epoch: 6 Loss: 0.546087\n",
      "Train Epoch: 6 Loss: 0.539983\n",
      "Train Epoch: 6 Loss: 0.534005\n",
      "Train Epoch: 6 Loss: 0.528150\n",
      "Train Epoch: 6 Loss: 0.522416\n",
      "Train Epoch: 6 Loss: 0.516798\n",
      "Train Epoch: 6 Loss: 0.511293\n",
      "Train Epoch: 6 Loss: 0.505898\n",
      "Train Epoch: 6 Loss: 0.500610\n",
      "Train Epoch: 6 Loss: 0.495427\n",
      "Train Epoch: 6 Loss: 0.490345\n",
      "Train Epoch: 6 Loss: 0.485362\n",
      "Train Epoch: 6 Loss: 0.480475\n",
      "Train Epoch: 6 Loss: 0.475682\n",
      "Train Epoch: 6 Loss: 0.470980\n",
      "Train Epoch: 6 Loss: 0.466367\n",
      "Train Epoch: 7 Loss: 0.465911\n",
      "Train Epoch: 7 Loss: 0.461393\n",
      "Train Epoch: 7 Loss: 0.456959\n",
      "Train Epoch: 7 Loss: 0.452607\n",
      "Train Epoch: 7 Loss: 0.448336\n",
      "Train Epoch: 7 Loss: 0.444142\n",
      "Train Epoch: 7 Loss: 0.440024\n",
      "Train Epoch: 7 Loss: 0.435981\n",
      "Train Epoch: 7 Loss: 0.432010\n",
      "Train Epoch: 7 Loss: 0.428109\n",
      "Train Epoch: 7 Loss: 0.424277\n",
      "Train Epoch: 7 Loss: 0.420513\n",
      "Train Epoch: 7 Loss: 0.416814\n",
      "Train Epoch: 7 Loss: 0.413180\n",
      "Train Epoch: 7 Loss: 0.409608\n",
      "Train Epoch: 7 Loss: 0.406097\n",
      "Train Epoch: 7 Loss: 0.402646\n",
      "Train Epoch: 7 Loss: 0.399253\n",
      "Train Epoch: 7 Loss: 0.395917\n",
      "Train Epoch: 7 Loss: 0.392637\n",
      "Train Epoch: 7 Loss: 0.389412\n",
      "Train Epoch: 7 Loss: 0.386239\n",
      "Train Epoch: 7 Loss: 0.383119\n",
      "Train Epoch: 8 Loss: 0.382810\n",
      "Train Epoch: 8 Loss: 0.379745\n",
      "Train Epoch: 8 Loss: 0.376731\n",
      "Train Epoch: 8 Loss: 0.373764\n",
      "Train Epoch: 8 Loss: 0.370846\n",
      "Train Epoch: 8 Loss: 0.367973\n",
      "Train Epoch: 8 Loss: 0.365147\n",
      "Train Epoch: 8 Loss: 0.362364\n",
      "Train Epoch: 8 Loss: 0.359626\n",
      "Train Epoch: 8 Loss: 0.356929\n",
      "Train Epoch: 8 Loss: 0.354275\n",
      "Train Epoch: 8 Loss: 0.351662\n",
      "Train Epoch: 8 Loss: 0.349088\n",
      "Train Epoch: 8 Loss: 0.346554\n",
      "Train Epoch: 8 Loss: 0.344058\n",
      "Train Epoch: 8 Loss: 0.341599\n",
      "Train Epoch: 8 Loss: 0.339178\n",
      "Train Epoch: 8 Loss: 0.336792\n",
      "Train Epoch: 8 Loss: 0.334442\n",
      "Train Epoch: 8 Loss: 0.332126\n",
      "Train Epoch: 8 Loss: 0.329845\n",
      "Train Epoch: 8 Loss: 0.327597\n",
      "Train Epoch: 8 Loss: 0.325381\n",
      "Train Epoch: 9 Loss: 0.325161\n",
      "Train Epoch: 9 Loss: 0.322981\n",
      "Train Epoch: 9 Loss: 0.320832\n",
      "Train Epoch: 9 Loss: 0.318713\n",
      "Train Epoch: 9 Loss: 0.316625\n",
      "Train Epoch: 9 Loss: 0.314566\n",
      "Train Epoch: 9 Loss: 0.312536\n",
      "Train Epoch: 9 Loss: 0.310535\n",
      "Train Epoch: 9 Loss: 0.308561\n",
      "Train Epoch: 9 Loss: 0.306615\n",
      "Train Epoch: 9 Loss: 0.304695\n",
      "Train Epoch: 9 Loss: 0.302802\n",
      "Train Epoch: 9 Loss: 0.300935\n",
      "Train Epoch: 9 Loss: 0.299093\n",
      "Train Epoch: 9 Loss: 0.297276\n",
      "Train Epoch: 9 Loss: 0.295484\n",
      "Train Epoch: 9 Loss: 0.293716\n",
      "Train Epoch: 9 Loss: 0.291971\n",
      "Train Epoch: 9 Loss: 0.290249\n",
      "Train Epoch: 9 Loss: 0.288550\n",
      "Train Epoch: 9 Loss: 0.286874\n",
      "Train Epoch: 9 Loss: 0.285219\n",
      "Train Epoch: 9 Loss: 0.283586\n",
      "Train Epoch: 10 Loss: 0.283424\n",
      "Train Epoch: 10 Loss: 0.281814\n",
      "Train Epoch: 10 Loss: 0.280226\n",
      "Train Epoch: 10 Loss: 0.278657\n",
      "Train Epoch: 10 Loss: 0.277109\n",
      "Train Epoch: 10 Loss: 0.275580\n",
      "Train Epoch: 10 Loss: 0.274071\n",
      "Train Epoch: 10 Loss: 0.272580\n",
      "Train Epoch: 10 Loss: 0.271109\n",
      "Train Epoch: 10 Loss: 0.269656\n",
      "Train Epoch: 10 Loss: 0.268221\n",
      "Train Epoch: 10 Loss: 0.266804\n",
      "Train Epoch: 10 Loss: 0.265404\n",
      "Train Epoch: 10 Loss: 0.264022\n",
      "Train Epoch: 10 Loss: 0.262656\n",
      "Train Epoch: 10 Loss: 0.261308\n",
      "Train Epoch: 10 Loss: 0.259975\n",
      "Train Epoch: 10 Loss: 0.258659\n",
      "Train Epoch: 10 Loss: 0.257358\n",
      "Train Epoch: 10 Loss: 0.256074\n",
      "Train Epoch: 10 Loss: 0.254804\n",
      "Train Epoch: 10 Loss: 0.253550\n",
      "Train Epoch: 10 Loss: 0.252310\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.118615\n",
      "Train Epoch: 1 Loss: 17.784988\n",
      "Train Epoch: 1 Loss: 16.530853\n",
      "Train Epoch: 1 Loss: 15.362468\n",
      "Train Epoch: 1 Loss: 14.281587\n",
      "Train Epoch: 1 Loss: 13.286314\n",
      "Train Epoch: 1 Loss: 12.372489\n",
      "Train Epoch: 1 Loss: 11.534823\n",
      "Train Epoch: 1 Loss: 10.767612\n",
      "Train Epoch: 1 Loss: 10.065143\n",
      "Train Epoch: 1 Loss: 9.421894\n",
      "Train Epoch: 1 Loss: 8.832657\n",
      "Train Epoch: 1 Loss: 8.292564\n",
      "Train Epoch: 1 Loss: 7.797120\n",
      "Train Epoch: 1 Loss: 7.342202\n",
      "Train Epoch: 1 Loss: 6.924045\n",
      "Train Epoch: 1 Loss: 6.539226\n",
      "Train Epoch: 1 Loss: 6.184641\n",
      "Train Epoch: 1 Loss: 5.857485\n",
      "Train Epoch: 1 Loss: 5.555227\n",
      "Train Epoch: 1 Loss: 5.275586\n",
      "Train Epoch: 1 Loss: 5.016507\n",
      "Train Epoch: 1 Loss: 4.776139\n",
      "Train Epoch: 2 Loss: 4.753066\n",
      "Train Epoch: 2 Loss: 4.531364\n",
      "Train Epoch: 2 Loss: 4.325069\n",
      "Train Epoch: 2 Loss: 4.132846\n",
      "Train Epoch: 2 Loss: 3.953489\n",
      "Train Epoch: 2 Loss: 3.785913\n",
      "Train Epoch: 2 Loss: 3.629143\n",
      "Train Epoch: 2 Loss: 3.482286\n",
      "Train Epoch: 2 Loss: 3.344546\n",
      "Train Epoch: 2 Loss: 3.215199\n",
      "Train Epoch: 2 Loss: 3.093587\n",
      "Train Epoch: 2 Loss: 2.979114\n",
      "Train Epoch: 2 Loss: 2.871238\n",
      "Train Epoch: 2 Loss: 2.769468\n",
      "Train Epoch: 2 Loss: 2.673354\n",
      "Train Epoch: 2 Loss: 2.582486\n",
      "Train Epoch: 2 Loss: 2.496491\n",
      "Train Epoch: 2 Loss: 2.415029\n",
      "Train Epoch: 2 Loss: 2.337785\n",
      "Train Epoch: 2 Loss: 2.264472\n",
      "Train Epoch: 2 Loss: 2.194828\n",
      "Train Epoch: 2 Loss: 2.128611\n",
      "Train Epoch: 2 Loss: 2.065599\n",
      "Train Epoch: 3 Loss: 2.059465\n",
      "Train Epoch: 3 Loss: 1.999742\n",
      "Train Epoch: 3 Loss: 1.942811\n",
      "Train Epoch: 3 Loss: 1.888501\n",
      "Train Epoch: 3 Loss: 1.836650\n",
      "Train Epoch: 3 Loss: 1.787111\n",
      "Train Epoch: 3 Loss: 1.739747\n",
      "Train Epoch: 3 Loss: 1.694430\n",
      "Train Epoch: 3 Loss: 1.651044\n",
      "Train Epoch: 3 Loss: 1.609478\n",
      "Train Epoch: 3 Loss: 1.569630\n",
      "Train Epoch: 3 Loss: 1.531406\n",
      "Train Epoch: 3 Loss: 1.494717\n",
      "Train Epoch: 3 Loss: 1.459480\n",
      "Train Epoch: 3 Loss: 1.425619\n",
      "Train Epoch: 3 Loss: 1.393062\n",
      "Train Epoch: 3 Loss: 1.361741\n",
      "Train Epoch: 3 Loss: 1.331593\n",
      "Train Epoch: 3 Loss: 1.302560\n",
      "Train Epoch: 3 Loss: 1.274585\n",
      "Train Epoch: 3 Loss: 1.247618\n",
      "Train Epoch: 3 Loss: 1.221609\n",
      "Train Epoch: 3 Loss: 1.196513\n",
      "Train Epoch: 4 Loss: 1.194052\n",
      "Train Epoch: 4 Loss: 1.169909\n",
      "Train Epoch: 4 Loss: 1.146592\n",
      "Train Epoch: 4 Loss: 1.124061\n",
      "Train Epoch: 4 Loss: 1.102282\n",
      "Train Epoch: 4 Loss: 1.081220\n",
      "Train Epoch: 4 Loss: 1.060844\n",
      "Train Epoch: 4 Loss: 1.041122\n",
      "Train Epoch: 4 Loss: 1.022028\n",
      "Train Epoch: 4 Loss: 1.003534\n",
      "Train Epoch: 4 Loss: 0.985614\n",
      "Train Epoch: 4 Loss: 0.968245\n",
      "Train Epoch: 4 Loss: 0.951403\n",
      "Train Epoch: 4 Loss: 0.935067\n",
      "Train Epoch: 4 Loss: 0.919216\n",
      "Train Epoch: 4 Loss: 0.903832\n",
      "Train Epoch: 4 Loss: 0.888894\n",
      "Train Epoch: 4 Loss: 0.874386\n",
      "Train Epoch: 4 Loss: 0.860292\n",
      "Train Epoch: 4 Loss: 0.846593\n",
      "Train Epoch: 4 Loss: 0.833278\n",
      "Train Epoch: 4 Loss: 0.820329\n",
      "Train Epoch: 4 Loss: 0.807734\n",
      "Train Epoch: 5 Loss: 0.806494\n",
      "Train Epoch: 5 Loss: 0.794273\n",
      "Train Epoch: 5 Loss: 0.782379\n",
      "Train Epoch: 5 Loss: 0.770800\n",
      "Train Epoch: 5 Loss: 0.759525\n",
      "Train Epoch: 5 Loss: 0.748543\n",
      "Train Epoch: 5 Loss: 0.737843\n",
      "Train Epoch: 5 Loss: 0.727416\n",
      "Train Epoch: 5 Loss: 0.717253\n",
      "Train Epoch: 5 Loss: 0.707344\n",
      "Train Epoch: 5 Loss: 0.697680\n",
      "Train Epoch: 5 Loss: 0.688254\n",
      "Train Epoch: 5 Loss: 0.679057\n",
      "Train Epoch: 5 Loss: 0.670082\n",
      "Train Epoch: 5 Loss: 0.661322\n",
      "Train Epoch: 5 Loss: 0.652769\n",
      "Train Epoch: 5 Loss: 0.644418\n",
      "Train Epoch: 5 Loss: 0.636261\n",
      "Train Epoch: 5 Loss: 0.628292\n",
      "Train Epoch: 5 Loss: 0.620506\n",
      "Train Epoch: 5 Loss: 0.612896\n",
      "Train Epoch: 5 Loss: 0.605459\n",
      "Train Epoch: 5 Loss: 0.598187\n",
      "Train Epoch: 6 Loss: 0.597469\n",
      "Train Epoch: 6 Loss: 0.590374\n",
      "Train Epoch: 6 Loss: 0.583435\n",
      "Train Epoch: 6 Loss: 0.576647\n",
      "Train Epoch: 6 Loss: 0.570005\n",
      "Train Epoch: 6 Loss: 0.563506\n",
      "Train Epoch: 6 Loss: 0.557145\n",
      "Train Epoch: 6 Loss: 0.550919\n",
      "Train Epoch: 6 Loss: 0.544823\n",
      "Train Epoch: 6 Loss: 0.538853\n",
      "Train Epoch: 6 Loss: 0.533007\n",
      "Train Epoch: 6 Loss: 0.527280\n",
      "Train Epoch: 6 Loss: 0.521670\n",
      "Train Epoch: 6 Loss: 0.516172\n",
      "Train Epoch: 6 Loss: 0.510785\n",
      "Train Epoch: 6 Loss: 0.505504\n",
      "Train Epoch: 6 Loss: 0.500328\n",
      "Train Epoch: 6 Loss: 0.495253\n",
      "Train Epoch: 6 Loss: 0.490277\n",
      "Train Epoch: 6 Loss: 0.485397\n",
      "Train Epoch: 6 Loss: 0.480610\n",
      "Train Epoch: 6 Loss: 0.475915\n",
      "Train Epoch: 6 Loss: 0.471308\n",
      "Train Epoch: 7 Loss: 0.470852\n",
      "Train Epoch: 7 Loss: 0.466341\n",
      "Train Epoch: 7 Loss: 0.461913\n",
      "Train Epoch: 7 Loss: 0.457567\n",
      "Train Epoch: 7 Loss: 0.453301\n",
      "Train Epoch: 7 Loss: 0.449113\n",
      "Train Epoch: 7 Loss: 0.445001\n",
      "Train Epoch: 7 Loss: 0.440963\n",
      "Train Epoch: 7 Loss: 0.436997\n",
      "Train Epoch: 7 Loss: 0.433102\n",
      "Train Epoch: 7 Loss: 0.429276\n",
      "Train Epoch: 7 Loss: 0.425516\n",
      "Train Epoch: 7 Loss: 0.421823\n",
      "Train Epoch: 7 Loss: 0.418193\n",
      "Train Epoch: 7 Loss: 0.414626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 Loss: 0.411120\n",
      "Train Epoch: 7 Loss: 0.407674\n",
      "Train Epoch: 7 Loss: 0.404285\n",
      "Train Epoch: 7 Loss: 0.400954\n",
      "Train Epoch: 7 Loss: 0.397678\n",
      "Train Epoch: 7 Loss: 0.394457\n",
      "Train Epoch: 7 Loss: 0.391289\n",
      "Train Epoch: 7 Loss: 0.388173\n",
      "Train Epoch: 8 Loss: 0.387864\n",
      "Train Epoch: 8 Loss: 0.384804\n",
      "Train Epoch: 8 Loss: 0.381793\n",
      "Train Epoch: 8 Loss: 0.378831\n",
      "Train Epoch: 8 Loss: 0.375916\n",
      "Train Epoch: 8 Loss: 0.373048\n",
      "Train Epoch: 8 Loss: 0.370225\n",
      "Train Epoch: 8 Loss: 0.367446\n",
      "Train Epoch: 8 Loss: 0.364711\n",
      "Train Epoch: 8 Loss: 0.362019\n",
      "Train Epoch: 8 Loss: 0.359368\n",
      "Train Epoch: 8 Loss: 0.356758\n",
      "Train Epoch: 8 Loss: 0.354188\n",
      "Train Epoch: 8 Loss: 0.351657\n",
      "Train Epoch: 8 Loss: 0.349164\n",
      "Train Epoch: 8 Loss: 0.346709\n",
      "Train Epoch: 8 Loss: 0.344291\n",
      "Train Epoch: 8 Loss: 0.341908\n",
      "Train Epoch: 8 Loss: 0.339561\n",
      "Train Epoch: 8 Loss: 0.337249\n",
      "Train Epoch: 8 Loss: 0.334971\n",
      "Train Epoch: 8 Loss: 0.332725\n",
      "Train Epoch: 8 Loss: 0.330513\n",
      "Train Epoch: 9 Loss: 0.330293\n",
      "Train Epoch: 9 Loss: 0.328116\n",
      "Train Epoch: 9 Loss: 0.325969\n",
      "Train Epoch: 9 Loss: 0.323854\n",
      "Train Epoch: 9 Loss: 0.321768\n",
      "Train Epoch: 9 Loss: 0.319712\n",
      "Train Epoch: 9 Loss: 0.317685\n",
      "Train Epoch: 9 Loss: 0.315686\n",
      "Train Epoch: 9 Loss: 0.313715\n",
      "Train Epoch: 9 Loss: 0.311771\n",
      "Train Epoch: 9 Loss: 0.309854\n",
      "Train Epoch: 9 Loss: 0.307964\n",
      "Train Epoch: 9 Loss: 0.306099\n",
      "Train Epoch: 9 Loss: 0.304260\n",
      "Train Epoch: 9 Loss: 0.302445\n",
      "Train Epoch: 9 Loss: 0.300655\n",
      "Train Epoch: 9 Loss: 0.298889\n",
      "Train Epoch: 9 Loss: 0.297147\n",
      "Train Epoch: 9 Loss: 0.295428\n",
      "Train Epoch: 9 Loss: 0.293731\n",
      "Train Epoch: 9 Loss: 0.292057\n",
      "Train Epoch: 9 Loss: 0.290404\n",
      "Train Epoch: 9 Loss: 0.288774\n",
      "Train Epoch: 10 Loss: 0.288612\n",
      "Train Epoch: 10 Loss: 0.287004\n",
      "Train Epoch: 10 Loss: 0.285417\n",
      "Train Epoch: 10 Loss: 0.283851\n",
      "Train Epoch: 10 Loss: 0.282305\n",
      "Train Epoch: 10 Loss: 0.280778\n",
      "Train Epoch: 10 Loss: 0.279271\n",
      "Train Epoch: 10 Loss: 0.277782\n",
      "Train Epoch: 10 Loss: 0.276313\n",
      "Train Epoch: 10 Loss: 0.274862\n",
      "Train Epoch: 10 Loss: 0.273429\n",
      "Train Epoch: 10 Loss: 0.272013\n",
      "Train Epoch: 10 Loss: 0.270616\n",
      "Train Epoch: 10 Loss: 0.269235\n",
      "Train Epoch: 10 Loss: 0.267871\n",
      "Train Epoch: 10 Loss: 0.266524\n",
      "Train Epoch: 10 Loss: 0.265194\n",
      "Train Epoch: 10 Loss: 0.263879\n",
      "Train Epoch: 10 Loss: 0.262581\n",
      "Train Epoch: 10 Loss: 0.261298\n",
      "Train Epoch: 10 Loss: 0.260030\n",
      "Train Epoch: 10 Loss: 0.258777\n",
      "Train Epoch: 10 Loss: 0.257539\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.137172\n",
      "Train Epoch: 1 Loss: 17.802075\n",
      "Train Epoch: 1 Loss: 16.546539\n",
      "Train Epoch: 1 Loss: 15.376859\n",
      "Train Epoch: 1 Loss: 14.294794\n",
      "Train Epoch: 1 Loss: 13.298436\n",
      "Train Epoch: 1 Loss: 12.383614\n",
      "Train Epoch: 1 Loss: 11.545042\n",
      "Train Epoch: 1 Loss: 10.776994\n",
      "Train Epoch: 1 Loss: 10.073745\n",
      "Train Epoch: 1 Loss: 9.429783\n",
      "Train Epoch: 1 Loss: 8.839876\n",
      "Train Epoch: 1 Loss: 8.299170\n",
      "Train Epoch: 1 Loss: 7.803152\n",
      "Train Epoch: 1 Loss: 7.347706\n",
      "Train Epoch: 1 Loss: 6.929058\n",
      "Train Epoch: 1 Loss: 6.543786\n",
      "Train Epoch: 1 Loss: 6.188777\n",
      "Train Epoch: 1 Loss: 5.861232\n",
      "Train Epoch: 1 Loss: 5.558614\n",
      "Train Epoch: 1 Loss: 5.278637\n",
      "Train Epoch: 1 Loss: 5.019246\n",
      "Train Epoch: 1 Loss: 4.778590\n",
      "Train Epoch: 2 Loss: 4.755490\n",
      "Train Epoch: 2 Loss: 4.533521\n",
      "Train Epoch: 2 Loss: 4.326979\n",
      "Train Epoch: 2 Loss: 4.134525\n",
      "Train Epoch: 2 Loss: 3.954953\n",
      "Train Epoch: 2 Loss: 3.787177\n",
      "Train Epoch: 2 Loss: 3.630217\n",
      "Train Epoch: 2 Loss: 3.483186\n",
      "Train Epoch: 2 Loss: 3.345282\n",
      "Train Epoch: 2 Loss: 3.215781\n",
      "Train Epoch: 2 Loss: 3.094025\n",
      "Train Epoch: 2 Loss: 2.979415\n",
      "Train Epoch: 2 Loss: 2.871413\n",
      "Train Epoch: 2 Loss: 2.769521\n",
      "Train Epoch: 2 Loss: 2.673293\n",
      "Train Epoch: 2 Loss: 2.582319\n",
      "Train Epoch: 2 Loss: 2.496222\n",
      "Train Epoch: 2 Loss: 2.414664\n",
      "Train Epoch: 2 Loss: 2.337329\n",
      "Train Epoch: 2 Loss: 2.263931\n",
      "Train Epoch: 2 Loss: 2.194205\n",
      "Train Epoch: 2 Loss: 2.127911\n",
      "Train Epoch: 2 Loss: 2.064825\n",
      "Train Epoch: 3 Loss: 2.058686\n",
      "Train Epoch: 3 Loss: 1.998892\n",
      "Train Epoch: 3 Loss: 1.941896\n",
      "Train Epoch: 3 Loss: 1.887522\n",
      "Train Epoch: 3 Loss: 1.835612\n",
      "Train Epoch: 3 Loss: 1.786015\n",
      "Train Epoch: 3 Loss: 1.738596\n",
      "Train Epoch: 3 Loss: 1.693228\n",
      "Train Epoch: 3 Loss: 1.649792\n",
      "Train Epoch: 3 Loss: 1.608178\n",
      "Train Epoch: 3 Loss: 1.568285\n",
      "Train Epoch: 3 Loss: 1.530017\n",
      "Train Epoch: 3 Loss: 1.493286\n",
      "Train Epoch: 3 Loss: 1.458010\n",
      "Train Epoch: 3 Loss: 1.424110\n",
      "Train Epoch: 3 Loss: 1.391516\n",
      "Train Epoch: 3 Loss: 1.360159\n",
      "Train Epoch: 3 Loss: 1.329978\n",
      "Train Epoch: 3 Loss: 1.300912\n",
      "Train Epoch: 3 Loss: 1.272906\n",
      "Train Epoch: 3 Loss: 1.245908\n",
      "Train Epoch: 3 Loss: 1.219870\n",
      "Train Epoch: 3 Loss: 1.194746\n",
      "Train Epoch: 4 Loss: 1.192282\n",
      "Train Epoch: 4 Loss: 1.168112\n",
      "Train Epoch: 4 Loss: 1.144769\n",
      "Train Epoch: 4 Loss: 1.122213\n",
      "Train Epoch: 4 Loss: 1.100410\n",
      "Train Epoch: 4 Loss: 1.079324\n",
      "Train Epoch: 4 Loss: 1.058925\n",
      "Train Epoch: 4 Loss: 1.039182\n",
      "Train Epoch: 4 Loss: 1.020067\n",
      "Train Epoch: 4 Loss: 1.001552\n",
      "Train Epoch: 4 Loss: 0.983613\n",
      "Train Epoch: 4 Loss: 0.966224\n",
      "Train Epoch: 4 Loss: 0.949364\n",
      "Train Epoch: 4 Loss: 0.933010\n",
      "Train Epoch: 4 Loss: 0.917142\n",
      "Train Epoch: 4 Loss: 0.901740\n",
      "Train Epoch: 4 Loss: 0.886786\n",
      "Train Epoch: 4 Loss: 0.872263\n",
      "Train Epoch: 4 Loss: 0.858152\n",
      "Train Epoch: 4 Loss: 0.844439\n",
      "Train Epoch: 4 Loss: 0.831109\n",
      "Train Epoch: 4 Loss: 0.818146\n",
      "Train Epoch: 4 Loss: 0.805537\n",
      "Train Epoch: 5 Loss: 0.804295\n",
      "Train Epoch: 5 Loss: 0.792061\n",
      "Train Epoch: 5 Loss: 0.780154\n",
      "Train Epoch: 5 Loss: 0.768563\n",
      "Train Epoch: 5 Loss: 0.757275\n",
      "Train Epoch: 5 Loss: 0.746281\n",
      "Train Epoch: 5 Loss: 0.735570\n",
      "Train Epoch: 5 Loss: 0.725132\n",
      "Train Epoch: 5 Loss: 0.714957\n",
      "Train Epoch: 5 Loss: 0.705037\n",
      "Train Epoch: 5 Loss: 0.695363\n",
      "Train Epoch: 5 Loss: 0.685927\n",
      "Train Epoch: 5 Loss: 0.676720\n",
      "Train Epoch: 5 Loss: 0.667736\n",
      "Train Epoch: 5 Loss: 0.658966\n",
      "Train Epoch: 5 Loss: 0.650404\n",
      "Train Epoch: 5 Loss: 0.642044\n",
      "Train Epoch: 5 Loss: 0.633878\n",
      "Train Epoch: 5 Loss: 0.625901\n",
      "Train Epoch: 5 Loss: 0.618106\n",
      "Train Epoch: 5 Loss: 0.610488\n",
      "Train Epoch: 5 Loss: 0.603043\n",
      "Train Epoch: 5 Loss: 0.595763\n",
      "Train Epoch: 6 Loss: 0.595044\n",
      "Train Epoch: 6 Loss: 0.587942\n",
      "Train Epoch: 6 Loss: 0.580995\n",
      "Train Epoch: 6 Loss: 0.574200\n",
      "Train Epoch: 6 Loss: 0.567551\n",
      "Train Epoch: 6 Loss: 0.561045\n",
      "Train Epoch: 6 Loss: 0.554678\n",
      "Train Epoch: 6 Loss: 0.548445\n",
      "Train Epoch: 6 Loss: 0.542342\n",
      "Train Epoch: 6 Loss: 0.536366\n",
      "Train Epoch: 6 Loss: 0.530513\n",
      "Train Epoch: 6 Loss: 0.524780\n",
      "Train Epoch: 6 Loss: 0.519164\n",
      "Train Epoch: 6 Loss: 0.513661\n",
      "Train Epoch: 6 Loss: 0.508267\n",
      "Train Epoch: 6 Loss: 0.502982\n",
      "Train Epoch: 6 Loss: 0.497800\n",
      "Train Epoch: 6 Loss: 0.492720\n",
      "Train Epoch: 6 Loss: 0.487738\n",
      "Train Epoch: 6 Loss: 0.482853\n",
      "Train Epoch: 6 Loss: 0.478061\n",
      "Train Epoch: 6 Loss: 0.473361\n",
      "Train Epoch: 6 Loss: 0.468749\n",
      "Train Epoch: 7 Loss: 0.468292\n",
      "Train Epoch: 7 Loss: 0.463776\n",
      "Train Epoch: 7 Loss: 0.459343\n",
      "Train Epoch: 7 Loss: 0.454993\n",
      "Train Epoch: 7 Loss: 0.450723\n",
      "Train Epoch: 7 Loss: 0.446530\n",
      "Train Epoch: 7 Loss: 0.442414\n",
      "Train Epoch: 7 Loss: 0.438372\n",
      "Train Epoch: 7 Loss: 0.434402\n",
      "Train Epoch: 7 Loss: 0.430502\n",
      "Train Epoch: 7 Loss: 0.426672\n",
      "Train Epoch: 7 Loss: 0.422909\n",
      "Train Epoch: 7 Loss: 0.419211\n",
      "Train Epoch: 7 Loss: 0.415578\n",
      "Train Epoch: 7 Loss: 0.412007\n",
      "Train Epoch: 7 Loss: 0.408497\n",
      "Train Epoch: 7 Loss: 0.405047\n",
      "Train Epoch: 7 Loss: 0.401655\n",
      "Train Epoch: 7 Loss: 0.398320\n",
      "Train Epoch: 7 Loss: 0.395041\n",
      "Train Epoch: 7 Loss: 0.391817\n",
      "Train Epoch: 7 Loss: 0.388645\n",
      "Train Epoch: 7 Loss: 0.385526\n",
      "Train Epoch: 8 Loss: 0.385217\n",
      "Train Epoch: 8 Loss: 0.382153\n",
      "Train Epoch: 8 Loss: 0.379139\n",
      "Train Epoch: 8 Loss: 0.376174\n",
      "Train Epoch: 8 Loss: 0.373256\n",
      "Train Epoch: 8 Loss: 0.370384\n",
      "Train Epoch: 8 Loss: 0.367558\n",
      "Train Epoch: 8 Loss: 0.364777\n",
      "Train Epoch: 8 Loss: 0.362039\n",
      "Train Epoch: 8 Loss: 0.359344\n",
      "Train Epoch: 8 Loss: 0.356690\n",
      "Train Epoch: 8 Loss: 0.354077\n",
      "Train Epoch: 8 Loss: 0.351505\n",
      "Train Epoch: 8 Loss: 0.348971\n",
      "Train Epoch: 8 Loss: 0.346476\n",
      "Train Epoch: 8 Loss: 0.344018\n",
      "Train Epoch: 8 Loss: 0.341597\n",
      "Train Epoch: 8 Loss: 0.339212\n",
      "Train Epoch: 8 Loss: 0.336863\n",
      "Train Epoch: 8 Loss: 0.334548\n",
      "Train Epoch: 8 Loss: 0.332267\n",
      "Train Epoch: 8 Loss: 0.330020\n",
      "Train Epoch: 8 Loss: 0.327805\n",
      "Train Epoch: 9 Loss: 0.327585\n",
      "Train Epoch: 9 Loss: 0.325405\n",
      "Train Epoch: 9 Loss: 0.323256\n",
      "Train Epoch: 9 Loss: 0.321139\n",
      "Train Epoch: 9 Loss: 0.319051\n",
      "Train Epoch: 9 Loss: 0.316992\n",
      "Train Epoch: 9 Loss: 0.314963\n",
      "Train Epoch: 9 Loss: 0.312962\n",
      "Train Epoch: 9 Loss: 0.310989\n",
      "Train Epoch: 9 Loss: 0.309044\n",
      "Train Epoch: 9 Loss: 0.307125\n",
      "Train Epoch: 9 Loss: 0.305232\n",
      "Train Epoch: 9 Loss: 0.303366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 Loss: 0.301524\n",
      "Train Epoch: 9 Loss: 0.299708\n",
      "Train Epoch: 9 Loss: 0.297916\n",
      "Train Epoch: 9 Loss: 0.296148\n",
      "Train Epoch: 9 Loss: 0.294404\n",
      "Train Epoch: 9 Loss: 0.292683\n",
      "Train Epoch: 9 Loss: 0.290984\n",
      "Train Epoch: 9 Loss: 0.289308\n",
      "Train Epoch: 9 Loss: 0.287654\n",
      "Train Epoch: 9 Loss: 0.286022\n",
      "Train Epoch: 10 Loss: 0.285860\n",
      "Train Epoch: 10 Loss: 0.284250\n",
      "Train Epoch: 10 Loss: 0.282662\n",
      "Train Epoch: 10 Loss: 0.281094\n",
      "Train Epoch: 10 Loss: 0.279546\n",
      "Train Epoch: 10 Loss: 0.278018\n",
      "Train Epoch: 10 Loss: 0.276509\n",
      "Train Epoch: 10 Loss: 0.275019\n",
      "Train Epoch: 10 Loss: 0.273548\n",
      "Train Epoch: 10 Loss: 0.272095\n",
      "Train Epoch: 10 Loss: 0.270661\n",
      "Train Epoch: 10 Loss: 0.269244\n",
      "Train Epoch: 10 Loss: 0.267845\n",
      "Train Epoch: 10 Loss: 0.266463\n",
      "Train Epoch: 10 Loss: 0.265098\n",
      "Train Epoch: 10 Loss: 0.263749\n",
      "Train Epoch: 10 Loss: 0.262417\n",
      "Train Epoch: 10 Loss: 0.261101\n",
      "Train Epoch: 10 Loss: 0.259801\n",
      "Train Epoch: 10 Loss: 0.258517\n",
      "Train Epoch: 10 Loss: 0.257248\n",
      "Train Epoch: 10 Loss: 0.255994\n",
      "Train Epoch: 10 Loss: 0.254755\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.129529\n",
      "Train Epoch: 1 Loss: 17.795445\n",
      "Train Epoch: 1 Loss: 16.540959\n",
      "Train Epoch: 1 Loss: 15.372371\n",
      "Train Epoch: 1 Loss: 14.291418\n",
      "Train Epoch: 1 Loss: 13.296186\n",
      "Train Epoch: 1 Loss: 12.382491\n",
      "Train Epoch: 1 Loss: 11.545012\n",
      "Train Epoch: 1 Loss: 10.778032\n",
      "Train Epoch: 1 Loss: 10.075824\n",
      "Train Epoch: 1 Loss: 9.432854\n",
      "Train Epoch: 1 Loss: 8.843907\n",
      "Train Epoch: 1 Loss: 8.304101\n",
      "Train Epoch: 1 Loss: 7.808946\n",
      "Train Epoch: 1 Loss: 7.354311\n",
      "Train Epoch: 1 Loss: 6.936433\n",
      "Train Epoch: 1 Loss: 6.551883\n",
      "Train Epoch: 1 Loss: 6.197562\n",
      "Train Epoch: 1 Loss: 5.870660\n",
      "Train Epoch: 1 Loss: 5.568647\n",
      "Train Epoch: 1 Loss: 5.289243\n",
      "Train Epoch: 1 Loss: 5.030387\n",
      "Train Epoch: 1 Loss: 4.790235\n",
      "Train Epoch: 2 Loss: 4.767182\n",
      "Train Epoch: 2 Loss: 4.545685\n",
      "Train Epoch: 2 Loss: 4.339586\n",
      "Train Epoch: 2 Loss: 4.147548\n",
      "Train Epoch: 2 Loss: 3.968367\n",
      "Train Epoch: 2 Loss: 3.800959\n",
      "Train Epoch: 2 Loss: 3.644346\n",
      "Train Epoch: 2 Loss: 3.497642\n",
      "Train Epoch: 2 Loss: 3.360047\n",
      "Train Epoch: 2 Loss: 3.230837\n",
      "Train Epoch: 2 Loss: 3.109355\n",
      "Train Epoch: 2 Loss: 2.995004\n",
      "Train Epoch: 2 Loss: 2.887247\n",
      "Train Epoch: 2 Loss: 2.785588\n",
      "Train Epoch: 2 Loss: 2.689579\n",
      "Train Epoch: 2 Loss: 2.598813\n",
      "Train Epoch: 2 Loss: 2.512914\n",
      "Train Epoch: 2 Loss: 2.431542\n",
      "Train Epoch: 2 Loss: 2.354386\n",
      "Train Epoch: 2 Loss: 2.281156\n",
      "Train Epoch: 2 Loss: 2.211591\n",
      "Train Epoch: 2 Loss: 2.145450\n",
      "Train Epoch: 2 Loss: 2.082510\n",
      "Train Epoch: 3 Loss: 2.076384\n",
      "Train Epoch: 3 Loss: 2.016729\n",
      "Train Epoch: 3 Loss: 1.959864\n",
      "Train Epoch: 3 Loss: 1.905615\n",
      "Train Epoch: 3 Loss: 1.853825\n",
      "Train Epoch: 3 Loss: 1.804343\n",
      "Train Epoch: 3 Loss: 1.757036\n",
      "Train Epoch: 3 Loss: 1.711772\n",
      "Train Epoch: 3 Loss: 1.668436\n",
      "Train Epoch: 3 Loss: 1.626919\n",
      "Train Epoch: 3 Loss: 1.587118\n",
      "Train Epoch: 3 Loss: 1.548938\n",
      "Train Epoch: 3 Loss: 1.512293\n",
      "Train Epoch: 3 Loss: 1.477099\n",
      "Train Epoch: 3 Loss: 1.443277\n",
      "Train Epoch: 3 Loss: 1.410759\n",
      "Train Epoch: 3 Loss: 1.379475\n",
      "Train Epoch: 3 Loss: 1.349364\n",
      "Train Epoch: 3 Loss: 1.320365\n",
      "Train Epoch: 3 Loss: 1.292424\n",
      "Train Epoch: 3 Loss: 1.265489\n",
      "Train Epoch: 3 Loss: 1.239512\n",
      "Train Epoch: 3 Loss: 1.214446\n",
      "Train Epoch: 4 Loss: 1.211988\n",
      "Train Epoch: 4 Loss: 1.187875\n",
      "Train Epoch: 4 Loss: 1.164586\n",
      "Train Epoch: 4 Loss: 1.142082\n",
      "Train Epoch: 4 Loss: 1.120330\n",
      "Train Epoch: 4 Loss: 1.099293\n",
      "Train Epoch: 4 Loss: 1.078941\n",
      "Train Epoch: 4 Loss: 1.059244\n",
      "Train Epoch: 4 Loss: 1.040173\n",
      "Train Epoch: 4 Loss: 1.021702\n",
      "Train Epoch: 4 Loss: 1.003804\n",
      "Train Epoch: 4 Loss: 0.986456\n",
      "Train Epoch: 4 Loss: 0.969635\n",
      "Train Epoch: 4 Loss: 0.953319\n",
      "Train Epoch: 4 Loss: 0.937488\n",
      "Train Epoch: 4 Loss: 0.922123\n",
      "Train Epoch: 4 Loss: 0.907203\n",
      "Train Epoch: 4 Loss: 0.892714\n",
      "Train Epoch: 4 Loss: 0.878636\n",
      "Train Epoch: 4 Loss: 0.864955\n",
      "Train Epoch: 4 Loss: 0.851656\n",
      "Train Epoch: 4 Loss: 0.838724\n",
      "Train Epoch: 4 Loss: 0.826144\n",
      "Train Epoch: 5 Loss: 0.824905\n",
      "Train Epoch: 5 Loss: 0.812700\n",
      "Train Epoch: 5 Loss: 0.800821\n",
      "Train Epoch: 5 Loss: 0.789256\n",
      "Train Epoch: 5 Loss: 0.777995\n",
      "Train Epoch: 5 Loss: 0.767027\n",
      "Train Epoch: 5 Loss: 0.756341\n",
      "Train Epoch: 5 Loss: 0.745927\n",
      "Train Epoch: 5 Loss: 0.735776\n",
      "Train Epoch: 5 Loss: 0.725879\n",
      "Train Epoch: 5 Loss: 0.716228\n",
      "Train Epoch: 5 Loss: 0.706814\n",
      "Train Epoch: 5 Loss: 0.697629\n",
      "Train Epoch: 5 Loss: 0.688665\n",
      "Train Epoch: 5 Loss: 0.679916\n",
      "Train Epoch: 5 Loss: 0.671374\n",
      "Train Epoch: 5 Loss: 0.663033\n",
      "Train Epoch: 5 Loss: 0.654886\n",
      "Train Epoch: 5 Loss: 0.646928\n",
      "Train Epoch: 5 Loss: 0.639152\n",
      "Train Epoch: 5 Loss: 0.631552\n",
      "Train Epoch: 5 Loss: 0.624123\n",
      "Train Epoch: 5 Loss: 0.616861\n",
      "Train Epoch: 6 Loss: 0.616144\n",
      "Train Epoch: 6 Loss: 0.609058\n",
      "Train Epoch: 6 Loss: 0.602128\n",
      "Train Epoch: 6 Loss: 0.595348\n",
      "Train Epoch: 6 Loss: 0.588715\n",
      "Train Epoch: 6 Loss: 0.582225\n",
      "Train Epoch: 6 Loss: 0.575872\n",
      "Train Epoch: 6 Loss: 0.569653\n",
      "Train Epoch: 6 Loss: 0.563565\n",
      "Train Epoch: 6 Loss: 0.557603\n",
      "Train Epoch: 6 Loss: 0.551764\n",
      "Train Epoch: 6 Loss: 0.546045\n",
      "Train Epoch: 6 Loss: 0.540442\n",
      "Train Epoch: 6 Loss: 0.534951\n",
      "Train Epoch: 6 Loss: 0.529571\n",
      "Train Epoch: 6 Loss: 0.524297\n",
      "Train Epoch: 6 Loss: 0.519128\n",
      "Train Epoch: 6 Loss: 0.514059\n",
      "Train Epoch: 6 Loss: 0.509090\n",
      "Train Epoch: 6 Loss: 0.504216\n",
      "Train Epoch: 6 Loss: 0.499435\n",
      "Train Epoch: 6 Loss: 0.494746\n",
      "Train Epoch: 6 Loss: 0.490145\n",
      "Train Epoch: 7 Loss: 0.489690\n",
      "Train Epoch: 7 Loss: 0.485184\n",
      "Train Epoch: 7 Loss: 0.480762\n",
      "Train Epoch: 7 Loss: 0.476422\n",
      "Train Epoch: 7 Loss: 0.472162\n",
      "Train Epoch: 7 Loss: 0.467979\n",
      "Train Epoch: 7 Loss: 0.463872\n",
      "Train Epoch: 7 Loss: 0.459839\n",
      "Train Epoch: 7 Loss: 0.455879\n",
      "Train Epoch: 7 Loss: 0.451989\n",
      "Train Epoch: 7 Loss: 0.448167\n",
      "Train Epoch: 7 Loss: 0.444413\n",
      "Train Epoch: 7 Loss: 0.440724\n",
      "Train Epoch: 7 Loss: 0.437099\n",
      "Train Epoch: 7 Loss: 0.433537\n",
      "Train Epoch: 7 Loss: 0.430035\n",
      "Train Epoch: 7 Loss: 0.426593\n",
      "Train Epoch: 7 Loss: 0.423209\n",
      "Train Epoch: 7 Loss: 0.419883\n",
      "Train Epoch: 7 Loss: 0.416611\n",
      "Train Epoch: 7 Loss: 0.413394\n",
      "Train Epoch: 7 Loss: 0.410230\n",
      "Train Epoch: 7 Loss: 0.407118\n",
      "Train Epoch: 8 Loss: 0.406810\n",
      "Train Epoch: 8 Loss: 0.403754\n",
      "Train Epoch: 8 Loss: 0.400747\n",
      "Train Epoch: 8 Loss: 0.397789\n",
      "Train Epoch: 8 Loss: 0.394878\n",
      "Train Epoch: 8 Loss: 0.392013\n",
      "Train Epoch: 8 Loss: 0.389194\n",
      "Train Epoch: 8 Loss: 0.386419\n",
      "Train Epoch: 8 Loss: 0.383687\n",
      "Train Epoch: 8 Loss: 0.380998\n",
      "Train Epoch: 8 Loss: 0.378351\n",
      "Train Epoch: 8 Loss: 0.375744\n",
      "Train Epoch: 8 Loss: 0.373178\n",
      "Train Epoch: 8 Loss: 0.370650\n",
      "Train Epoch: 8 Loss: 0.368161\n",
      "Train Epoch: 8 Loss: 0.365709\n",
      "Train Epoch: 8 Loss: 0.363294\n",
      "Train Epoch: 8 Loss: 0.360915\n",
      "Train Epoch: 8 Loss: 0.358571\n",
      "Train Epoch: 8 Loss: 0.356261\n",
      "Train Epoch: 8 Loss: 0.353986\n",
      "Train Epoch: 8 Loss: 0.351744\n",
      "Train Epoch: 8 Loss: 0.349534\n",
      "Train Epoch: 9 Loss: 0.349315\n",
      "Train Epoch: 9 Loss: 0.347140\n",
      "Train Epoch: 9 Loss: 0.344997\n",
      "Train Epoch: 9 Loss: 0.342884\n",
      "Train Epoch: 9 Loss: 0.340801\n",
      "Train Epoch: 9 Loss: 0.338748\n",
      "Train Epoch: 9 Loss: 0.336723\n",
      "Train Epoch: 9 Loss: 0.334727\n",
      "Train Epoch: 9 Loss: 0.332759\n",
      "Train Epoch: 9 Loss: 0.330817\n",
      "Train Epoch: 9 Loss: 0.328903\n",
      "Train Epoch: 9 Loss: 0.327015\n",
      "Train Epoch: 9 Loss: 0.325153\n",
      "Train Epoch: 9 Loss: 0.323316\n",
      "Train Epoch: 9 Loss: 0.321504\n",
      "Train Epoch: 9 Loss: 0.319716\n",
      "Train Epoch: 9 Loss: 0.317953\n",
      "Train Epoch: 9 Loss: 0.316213\n",
      "Train Epoch: 9 Loss: 0.314496\n",
      "Train Epoch: 9 Loss: 0.312801\n",
      "Train Epoch: 9 Loss: 0.311129\n",
      "Train Epoch: 9 Loss: 0.309479\n",
      "Train Epoch: 9 Loss: 0.307850\n",
      "Train Epoch: 10 Loss: 0.307689\n",
      "Train Epoch: 10 Loss: 0.306083\n",
      "Train Epoch: 10 Loss: 0.304499\n",
      "Train Epoch: 10 Loss: 0.302934\n",
      "Train Epoch: 10 Loss: 0.301390\n",
      "Train Epoch: 10 Loss: 0.299865\n",
      "Train Epoch: 10 Loss: 0.298360\n",
      "Train Epoch: 10 Loss: 0.296874\n",
      "Train Epoch: 10 Loss: 0.295406\n",
      "Train Epoch: 10 Loss: 0.293957\n",
      "Train Epoch: 10 Loss: 0.292526\n",
      "Train Epoch: 10 Loss: 0.291113\n",
      "Train Epoch: 10 Loss: 0.289717\n",
      "Train Epoch: 10 Loss: 0.288338\n",
      "Train Epoch: 10 Loss: 0.286976\n",
      "Train Epoch: 10 Loss: 0.285631\n",
      "Train Epoch: 10 Loss: 0.284302\n",
      "Train Epoch: 10 Loss: 0.282990\n",
      "Train Epoch: 10 Loss: 0.281693\n",
      "Train Epoch: 10 Loss: 0.280411\n",
      "Train Epoch: 10 Loss: 0.279145\n",
      "Train Epoch: 10 Loss: 0.277894\n",
      "Train Epoch: 10 Loss: 0.276658\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.118229\n",
      "Train Epoch: 1 Loss: 17.783705\n",
      "Train Epoch: 1 Loss: 16.528735\n",
      "Train Epoch: 1 Loss: 15.359609\n",
      "Train Epoch: 1 Loss: 14.278079\n",
      "Train Epoch: 1 Loss: 13.282246\n",
      "Train Epoch: 1 Loss: 12.367924\n",
      "Train Epoch: 1 Loss: 11.529816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Loss: 10.762199\n",
      "Train Epoch: 1 Loss: 10.059353\n",
      "Train Epoch: 1 Loss: 9.415746\n",
      "Train Epoch: 1 Loss: 8.826170\n",
      "Train Epoch: 1 Loss: 8.285752\n",
      "Train Epoch: 1 Loss: 7.790004\n",
      "Train Epoch: 1 Loss: 7.334790\n",
      "Train Epoch: 1 Loss: 6.916349\n",
      "Train Epoch: 1 Loss: 6.531259\n",
      "Train Epoch: 1 Loss: 6.176416\n",
      "Train Epoch: 1 Loss: 5.849014\n",
      "Train Epoch: 1 Loss: 5.546523\n",
      "Train Epoch: 1 Loss: 5.266659\n",
      "Train Epoch: 1 Loss: 5.007368\n",
      "Train Epoch: 1 Loss: 4.766800\n",
      "Train Epoch: 2 Loss: 4.743708\n",
      "Train Epoch: 2 Loss: 4.521818\n",
      "Train Epoch: 2 Loss: 4.315345\n",
      "Train Epoch: 2 Loss: 4.122951\n",
      "Train Epoch: 2 Loss: 3.943436\n",
      "Train Epoch: 2 Loss: 3.775709\n",
      "Train Epoch: 2 Loss: 3.618794\n",
      "Train Epoch: 2 Loss: 3.471802\n",
      "Train Epoch: 2 Loss: 3.333936\n",
      "Train Epoch: 2 Loss: 3.204468\n",
      "Train Epoch: 2 Loss: 3.082742\n",
      "Train Epoch: 2 Loss: 2.968162\n",
      "Train Epoch: 2 Loss: 2.860184\n",
      "Train Epoch: 2 Loss: 2.758316\n",
      "Train Epoch: 2 Loss: 2.662110\n",
      "Train Epoch: 2 Loss: 2.571155\n",
      "Train Epoch: 2 Loss: 2.485079\n",
      "Train Epoch: 2 Loss: 2.403538\n",
      "Train Epoch: 2 Loss: 2.326218\n",
      "Train Epoch: 2 Loss: 2.252834\n",
      "Train Epoch: 2 Loss: 2.183122\n",
      "Train Epoch: 2 Loss: 2.116842\n",
      "Train Epoch: 2 Loss: 2.053768\n",
      "Train Epoch: 3 Loss: 2.047629\n",
      "Train Epoch: 3 Loss: 1.987848\n",
      "Train Epoch: 3 Loss: 1.930861\n",
      "Train Epoch: 3 Loss: 1.876497\n",
      "Train Epoch: 3 Loss: 1.824596\n",
      "Train Epoch: 3 Loss: 1.775008\n",
      "Train Epoch: 3 Loss: 1.727597\n",
      "Train Epoch: 3 Loss: 1.682236\n",
      "Train Epoch: 3 Loss: 1.638807\n",
      "Train Epoch: 3 Loss: 1.597200\n",
      "Train Epoch: 3 Loss: 1.557313\n",
      "Train Epoch: 3 Loss: 1.519050\n",
      "Train Epoch: 3 Loss: 1.482325\n",
      "Train Epoch: 3 Loss: 1.447054\n",
      "Train Epoch: 3 Loss: 1.413159\n",
      "Train Epoch: 3 Loss: 1.380569\n",
      "Train Epoch: 3 Loss: 1.349217\n",
      "Train Epoch: 3 Loss: 1.319039\n",
      "Train Epoch: 3 Loss: 1.289977\n",
      "Train Epoch: 3 Loss: 1.261975\n",
      "Train Epoch: 3 Loss: 1.234981\n",
      "Train Epoch: 3 Loss: 1.208946\n",
      "Train Epoch: 3 Loss: 1.183824\n",
      "Train Epoch: 4 Loss: 1.181361\n",
      "Train Epoch: 4 Loss: 1.157194\n",
      "Train Epoch: 4 Loss: 1.133853\n",
      "Train Epoch: 4 Loss: 1.111300\n",
      "Train Epoch: 4 Loss: 1.089499\n",
      "Train Epoch: 4 Loss: 1.068416\n",
      "Train Epoch: 4 Loss: 1.048019\n",
      "Train Epoch: 4 Loss: 1.028278\n",
      "Train Epoch: 4 Loss: 1.009164\n",
      "Train Epoch: 4 Loss: 0.990652\n",
      "Train Epoch: 4 Loss: 0.972714\n",
      "Train Epoch: 4 Loss: 0.955327\n",
      "Train Epoch: 4 Loss: 0.938468\n",
      "Train Epoch: 4 Loss: 0.922116\n",
      "Train Epoch: 4 Loss: 0.906249\n",
      "Train Epoch: 4 Loss: 0.890849\n",
      "Train Epoch: 4 Loss: 0.875896\n",
      "Train Epoch: 4 Loss: 0.861373\n",
      "Train Epoch: 4 Loss: 0.847264\n",
      "Train Epoch: 4 Loss: 0.833552\n",
      "Train Epoch: 4 Loss: 0.820223\n",
      "Train Epoch: 4 Loss: 0.807261\n",
      "Train Epoch: 4 Loss: 0.794653\n",
      "Train Epoch: 5 Loss: 0.793412\n",
      "Train Epoch: 5 Loss: 0.781178\n",
      "Train Epoch: 5 Loss: 0.769272\n",
      "Train Epoch: 5 Loss: 0.757681\n",
      "Train Epoch: 5 Loss: 0.746395\n",
      "Train Epoch: 5 Loss: 0.735401\n",
      "Train Epoch: 5 Loss: 0.724691\n",
      "Train Epoch: 5 Loss: 0.714253\n",
      "Train Epoch: 5 Loss: 0.704079\n",
      "Train Epoch: 5 Loss: 0.694160\n",
      "Train Epoch: 5 Loss: 0.684486\n",
      "Train Epoch: 5 Loss: 0.675050\n",
      "Train Epoch: 5 Loss: 0.665844\n",
      "Train Epoch: 5 Loss: 0.656860\n",
      "Train Epoch: 5 Loss: 0.648091\n",
      "Train Epoch: 5 Loss: 0.639530\n",
      "Train Epoch: 5 Loss: 0.631169\n",
      "Train Epoch: 5 Loss: 0.623004\n",
      "Train Epoch: 5 Loss: 0.615027\n",
      "Train Epoch: 5 Loss: 0.607233\n",
      "Train Epoch: 5 Loss: 0.599616\n",
      "Train Epoch: 5 Loss: 0.592170\n",
      "Train Epoch: 5 Loss: 0.584891\n",
      "Train Epoch: 6 Loss: 0.584172\n",
      "Train Epoch: 6 Loss: 0.577070\n",
      "Train Epoch: 6 Loss: 0.570123\n",
      "Train Epoch: 6 Loss: 0.563328\n",
      "Train Epoch: 6 Loss: 0.556680\n",
      "Train Epoch: 6 Loss: 0.550174\n",
      "Train Epoch: 6 Loss: 0.543807\n",
      "Train Epoch: 6 Loss: 0.537574\n",
      "Train Epoch: 6 Loss: 0.531472\n",
      "Train Epoch: 6 Loss: 0.525496\n",
      "Train Epoch: 6 Loss: 0.519643\n",
      "Train Epoch: 6 Loss: 0.513911\n",
      "Train Epoch: 6 Loss: 0.508294\n",
      "Train Epoch: 6 Loss: 0.502791\n",
      "Train Epoch: 6 Loss: 0.497398\n",
      "Train Epoch: 6 Loss: 0.492112\n",
      "Train Epoch: 6 Loss: 0.486931\n",
      "Train Epoch: 6 Loss: 0.481851\n",
      "Train Epoch: 6 Loss: 0.476869\n",
      "Train Epoch: 6 Loss: 0.471984\n",
      "Train Epoch: 6 Loss: 0.467192\n",
      "Train Epoch: 6 Loss: 0.462492\n",
      "Train Epoch: 6 Loss: 0.457880\n",
      "Train Epoch: 7 Loss: 0.457424\n",
      "Train Epoch: 7 Loss: 0.452907\n",
      "Train Epoch: 7 Loss: 0.448475\n",
      "Train Epoch: 7 Loss: 0.444125\n",
      "Train Epoch: 7 Loss: 0.439854\n",
      "Train Epoch: 7 Loss: 0.435662\n",
      "Train Epoch: 7 Loss: 0.431545\n",
      "Train Epoch: 7 Loss: 0.427503\n",
      "Train Epoch: 7 Loss: 0.423533\n",
      "Train Epoch: 7 Loss: 0.419634\n",
      "Train Epoch: 7 Loss: 0.415804\n",
      "Train Epoch: 7 Loss: 0.412041\n",
      "Train Epoch: 7 Loss: 0.408343\n",
      "Train Epoch: 7 Loss: 0.404709\n",
      "Train Epoch: 7 Loss: 0.401139\n",
      "Train Epoch: 7 Loss: 0.397629\n",
      "Train Epoch: 7 Loss: 0.394179\n",
      "Train Epoch: 7 Loss: 0.390787\n",
      "Train Epoch: 7 Loss: 0.387452\n",
      "Train Epoch: 7 Loss: 0.384173\n",
      "Train Epoch: 7 Loss: 0.380948\n",
      "Train Epoch: 7 Loss: 0.377777\n",
      "Train Epoch: 7 Loss: 0.374657\n",
      "Train Epoch: 8 Loss: 0.374348\n",
      "Train Epoch: 8 Loss: 0.371285\n",
      "Train Epoch: 8 Loss: 0.368271\n",
      "Train Epoch: 8 Loss: 0.365306\n",
      "Train Epoch: 8 Loss: 0.362388\n",
      "Train Epoch: 8 Loss: 0.359516\n",
      "Train Epoch: 8 Loss: 0.356690\n",
      "Train Epoch: 8 Loss: 0.353909\n",
      "Train Epoch: 8 Loss: 0.351171\n",
      "Train Epoch: 8 Loss: 0.348476\n",
      "Train Epoch: 8 Loss: 0.345822\n",
      "Train Epoch: 8 Loss: 0.343209\n",
      "Train Epoch: 8 Loss: 0.340636\n",
      "Train Epoch: 8 Loss: 0.338103\n",
      "Train Epoch: 8 Loss: 0.335607\n",
      "Train Epoch: 8 Loss: 0.333150\n",
      "Train Epoch: 8 Loss: 0.330729\n",
      "Train Epoch: 8 Loss: 0.328344\n",
      "Train Epoch: 8 Loss: 0.325994\n",
      "Train Epoch: 8 Loss: 0.323680\n",
      "Train Epoch: 8 Loss: 0.321399\n",
      "Train Epoch: 8 Loss: 0.319151\n",
      "Train Epoch: 8 Loss: 0.316936\n",
      "Train Epoch: 9 Loss: 0.316716\n",
      "Train Epoch: 9 Loss: 0.314536\n",
      "Train Epoch: 9 Loss: 0.312388\n",
      "Train Epoch: 9 Loss: 0.310270\n",
      "Train Epoch: 9 Loss: 0.308182\n",
      "Train Epoch: 9 Loss: 0.306124\n",
      "Train Epoch: 9 Loss: 0.304094\n",
      "Train Epoch: 9 Loss: 0.302093\n",
      "Train Epoch: 9 Loss: 0.300120\n",
      "Train Epoch: 9 Loss: 0.298175\n",
      "Train Epoch: 9 Loss: 0.296256\n",
      "Train Epoch: 9 Loss: 0.294363\n",
      "Train Epoch: 9 Loss: 0.292497\n",
      "Train Epoch: 9 Loss: 0.290655\n",
      "Train Epoch: 9 Loss: 0.288839\n",
      "Train Epoch: 9 Loss: 0.287047\n",
      "Train Epoch: 9 Loss: 0.285279\n",
      "Train Epoch: 9 Loss: 0.283535\n",
      "Train Epoch: 9 Loss: 0.281813\n",
      "Train Epoch: 9 Loss: 0.280115\n",
      "Train Epoch: 9 Loss: 0.278439\n",
      "Train Epoch: 9 Loss: 0.276785\n",
      "Train Epoch: 9 Loss: 0.275152\n",
      "Train Epoch: 10 Loss: 0.274990\n",
      "Train Epoch: 10 Loss: 0.273381\n",
      "Train Epoch: 10 Loss: 0.271792\n",
      "Train Epoch: 10 Loss: 0.270224\n",
      "Train Epoch: 10 Loss: 0.268676\n",
      "Train Epoch: 10 Loss: 0.267148\n",
      "Train Epoch: 10 Loss: 0.265639\n",
      "Train Epoch: 10 Loss: 0.264149\n",
      "Train Epoch: 10 Loss: 0.262678\n",
      "Train Epoch: 10 Loss: 0.261225\n",
      "Train Epoch: 10 Loss: 0.259791\n",
      "Train Epoch: 10 Loss: 0.258374\n",
      "Train Epoch: 10 Loss: 0.256975\n",
      "Train Epoch: 10 Loss: 0.255593\n",
      "Train Epoch: 10 Loss: 0.254228\n",
      "Train Epoch: 10 Loss: 0.252879\n",
      "Train Epoch: 10 Loss: 0.251547\n",
      "Train Epoch: 10 Loss: 0.250231\n",
      "Train Epoch: 10 Loss: 0.248931\n",
      "Train Epoch: 10 Loss: 0.247646\n",
      "Train Epoch: 10 Loss: 0.246377\n",
      "Train Epoch: 10 Loss: 0.245123\n",
      "Train Epoch: 10 Loss: 0.243884\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.126798\n",
      "Train Epoch: 1 Loss: 17.791965\n",
      "Train Epoch: 1 Loss: 16.536673\n",
      "Train Epoch: 1 Loss: 15.367220\n",
      "Train Epoch: 1 Loss: 14.285352\n",
      "Train Epoch: 1 Loss: 13.289183\n",
      "Train Epoch: 1 Loss: 12.374547\n",
      "Train Epoch: 1 Loss: 11.536152\n",
      "Train Epoch: 1 Loss: 10.768291\n",
      "Train Epoch: 1 Loss: 10.065227\n",
      "Train Epoch: 1 Loss: 9.421441\n",
      "Train Epoch: 1 Loss: 8.831716\n",
      "Train Epoch: 1 Loss: 8.291172\n",
      "Train Epoch: 1 Loss: 7.795315\n",
      "Train Epoch: 1 Loss: 7.340014\n",
      "Train Epoch: 1 Loss: 6.921502\n",
      "Train Epoch: 1 Loss: 6.536350\n",
      "Train Epoch: 1 Loss: 6.181456\n",
      "Train Epoch: 1 Loss: 5.854010\n",
      "Train Epoch: 1 Loss: 5.551480\n",
      "Train Epoch: 1 Loss: 5.271581\n",
      "Train Epoch: 1 Loss: 5.012262\n",
      "Train Epoch: 1 Loss: 4.771664\n",
      "Train Epoch: 2 Loss: 4.748570\n",
      "Train Epoch: 2 Loss: 4.526656\n",
      "Train Epoch: 2 Loss: 4.320162\n",
      "Train Epoch: 2 Loss: 4.127750\n",
      "Train Epoch: 2 Loss: 3.948215\n",
      "Train Epoch: 2 Loss: 3.780472\n",
      "Train Epoch: 2 Loss: 3.623542\n",
      "Train Epoch: 2 Loss: 3.476538\n",
      "Train Epoch: 2 Loss: 3.338659\n",
      "Train Epoch: 2 Loss: 3.209180\n",
      "Train Epoch: 2 Loss: 3.087442\n",
      "Train Epoch: 2 Loss: 2.972852\n",
      "Train Epoch: 2 Loss: 2.864866\n",
      "Train Epoch: 2 Loss: 2.762990\n",
      "Train Epoch: 2 Loss: 2.666777\n",
      "Train Epoch: 2 Loss: 2.575815\n",
      "Train Epoch: 2 Loss: 2.489732\n",
      "Train Epoch: 2 Loss: 2.408185\n",
      "Train Epoch: 2 Loss: 2.330860\n",
      "Train Epoch: 2 Loss: 2.257471\n",
      "Train Epoch: 2 Loss: 2.187755\n",
      "Train Epoch: 2 Loss: 2.121470\n",
      "Train Epoch: 2 Loss: 2.058392\n",
      "Train Epoch: 3 Loss: 2.052252\n",
      "Train Epoch: 3 Loss: 1.992467\n",
      "Train Epoch: 3 Loss: 1.935477\n",
      "Train Epoch: 3 Loss: 1.881111\n",
      "Train Epoch: 3 Loss: 1.829206\n",
      "Train Epoch: 3 Loss: 1.779615\n",
      "Train Epoch: 3 Loss: 1.732202\n",
      "Train Epoch: 3 Loss: 1.686839\n",
      "Train Epoch: 3 Loss: 1.643408\n",
      "Train Epoch: 3 Loss: 1.601798\n",
      "Train Epoch: 3 Loss: 1.561910\n",
      "Train Epoch: 3 Loss: 1.523646\n",
      "Train Epoch: 3 Loss: 1.486919\n",
      "Train Epoch: 3 Loss: 1.451646\n",
      "Train Epoch: 3 Loss: 1.417750\n",
      "Train Epoch: 3 Loss: 1.385159\n",
      "Train Epoch: 3 Loss: 1.353805\n",
      "Train Epoch: 3 Loss: 1.323627\n",
      "Train Epoch: 3 Loss: 1.294563\n",
      "Train Epoch: 3 Loss: 1.266560\n",
      "Train Epoch: 3 Loss: 1.239565\n",
      "Train Epoch: 3 Loss: 1.213529\n",
      "Train Epoch: 3 Loss: 1.188407\n",
      "Train Epoch: 4 Loss: 1.185943\n",
      "Train Epoch: 4 Loss: 1.161776\n",
      "Train Epoch: 4 Loss: 1.138435\n",
      "Train Epoch: 4 Loss: 1.115881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Loss: 1.094079\n",
      "Train Epoch: 4 Loss: 1.072995\n",
      "Train Epoch: 4 Loss: 1.052598\n",
      "Train Epoch: 4 Loss: 1.032857\n",
      "Train Epoch: 4 Loss: 1.013742\n",
      "Train Epoch: 4 Loss: 0.995230\n",
      "Train Epoch: 4 Loss: 0.977291\n",
      "Train Epoch: 4 Loss: 0.959904\n",
      "Train Epoch: 4 Loss: 0.943045\n",
      "Train Epoch: 4 Loss: 0.926692\n",
      "Train Epoch: 4 Loss: 0.910826\n",
      "Train Epoch: 4 Loss: 0.895425\n",
      "Train Epoch: 4 Loss: 0.880472\n",
      "Train Epoch: 4 Loss: 0.865949\n",
      "Train Epoch: 4 Loss: 0.851840\n",
      "Train Epoch: 4 Loss: 0.838128\n",
      "Train Epoch: 4 Loss: 0.824798\n",
      "Train Epoch: 4 Loss: 0.811837\n",
      "Train Epoch: 4 Loss: 0.799229\n",
      "Train Epoch: 5 Loss: 0.797987\n",
      "Train Epoch: 5 Loss: 0.785754\n",
      "Train Epoch: 5 Loss: 0.773847\n",
      "Train Epoch: 5 Loss: 0.762257\n",
      "Train Epoch: 5 Loss: 0.750970\n",
      "Train Epoch: 5 Loss: 0.739976\n",
      "Train Epoch: 5 Loss: 0.729266\n",
      "Train Epoch: 5 Loss: 0.718828\n",
      "Train Epoch: 5 Loss: 0.708654\n",
      "Train Epoch: 5 Loss: 0.698735\n",
      "Train Epoch: 5 Loss: 0.689061\n",
      "Train Epoch: 5 Loss: 0.679626\n",
      "Train Epoch: 5 Loss: 0.670419\n",
      "Train Epoch: 5 Loss: 0.661435\n",
      "Train Epoch: 5 Loss: 0.652666\n",
      "Train Epoch: 5 Loss: 0.644105\n",
      "Train Epoch: 5 Loss: 0.635744\n",
      "Train Epoch: 5 Loss: 0.627579\n",
      "Train Epoch: 5 Loss: 0.619602\n",
      "Train Epoch: 5 Loss: 0.611808\n",
      "Train Epoch: 5 Loss: 0.604191\n",
      "Train Epoch: 5 Loss: 0.596746\n",
      "Train Epoch: 5 Loss: 0.589466\n",
      "Train Epoch: 6 Loss: 0.588747\n",
      "Train Epoch: 6 Loss: 0.581645\n",
      "Train Epoch: 6 Loss: 0.574699\n",
      "Train Epoch: 6 Loss: 0.567904\n",
      "Train Epoch: 6 Loss: 0.561256\n",
      "Train Epoch: 6 Loss: 0.554750\n",
      "Train Epoch: 6 Loss: 0.548383\n",
      "Train Epoch: 6 Loss: 0.542150\n",
      "Train Epoch: 6 Loss: 0.536048\n",
      "Train Epoch: 6 Loss: 0.530072\n",
      "Train Epoch: 6 Loss: 0.524219\n",
      "Train Epoch: 6 Loss: 0.518487\n",
      "Train Epoch: 6 Loss: 0.512871\n",
      "Train Epoch: 6 Loss: 0.507368\n",
      "Train Epoch: 6 Loss: 0.501975\n",
      "Train Epoch: 6 Loss: 0.496689\n",
      "Train Epoch: 6 Loss: 0.491507\n",
      "Train Epoch: 6 Loss: 0.486427\n",
      "Train Epoch: 6 Loss: 0.481446\n",
      "Train Epoch: 6 Loss: 0.476561\n",
      "Train Epoch: 6 Loss: 0.471769\n",
      "Train Epoch: 6 Loss: 0.467069\n",
      "Train Epoch: 6 Loss: 0.462458\n",
      "Train Epoch: 7 Loss: 0.462001\n",
      "Train Epoch: 7 Loss: 0.457485\n",
      "Train Epoch: 7 Loss: 0.453053\n",
      "Train Epoch: 7 Loss: 0.448703\n",
      "Train Epoch: 7 Loss: 0.444432\n",
      "Train Epoch: 7 Loss: 0.440240\n",
      "Train Epoch: 7 Loss: 0.436124\n",
      "Train Epoch: 7 Loss: 0.432081\n",
      "Train Epoch: 7 Loss: 0.428111\n",
      "Train Epoch: 7 Loss: 0.424212\n",
      "Train Epoch: 7 Loss: 0.420382\n",
      "Train Epoch: 7 Loss: 0.416619\n",
      "Train Epoch: 7 Loss: 0.412922\n",
      "Train Epoch: 7 Loss: 0.409288\n",
      "Train Epoch: 7 Loss: 0.405717\n",
      "Train Epoch: 7 Loss: 0.402208\n",
      "Train Epoch: 7 Loss: 0.398758\n",
      "Train Epoch: 7 Loss: 0.395366\n",
      "Train Epoch: 7 Loss: 0.392031\n",
      "Train Epoch: 7 Loss: 0.388752\n",
      "Train Epoch: 7 Loss: 0.385528\n",
      "Train Epoch: 7 Loss: 0.382356\n",
      "Train Epoch: 7 Loss: 0.379237\n",
      "Train Epoch: 8 Loss: 0.378928\n",
      "Train Epoch: 8 Loss: 0.375865\n",
      "Train Epoch: 8 Loss: 0.372851\n",
      "Train Epoch: 8 Loss: 0.369886\n",
      "Train Epoch: 8 Loss: 0.366968\n",
      "Train Epoch: 8 Loss: 0.364096\n",
      "Train Epoch: 8 Loss: 0.361271\n",
      "Train Epoch: 8 Loss: 0.358489\n",
      "Train Epoch: 8 Loss: 0.355751\n",
      "Train Epoch: 8 Loss: 0.353056\n",
      "Train Epoch: 8 Loss: 0.350402\n",
      "Train Epoch: 8 Loss: 0.347790\n",
      "Train Epoch: 8 Loss: 0.345217\n",
      "Train Epoch: 8 Loss: 0.342683\n",
      "Train Epoch: 8 Loss: 0.340188\n",
      "Train Epoch: 8 Loss: 0.337731\n",
      "Train Epoch: 8 Loss: 0.335310\n",
      "Train Epoch: 8 Loss: 0.332925\n",
      "Train Epoch: 8 Loss: 0.330576\n",
      "Train Epoch: 8 Loss: 0.328261\n",
      "Train Epoch: 8 Loss: 0.325980\n",
      "Train Epoch: 8 Loss: 0.323732\n",
      "Train Epoch: 8 Loss: 0.321517\n",
      "Train Epoch: 9 Loss: 0.321298\n",
      "Train Epoch: 9 Loss: 0.319118\n",
      "Train Epoch: 9 Loss: 0.316969\n",
      "Train Epoch: 9 Loss: 0.314852\n",
      "Train Epoch: 9 Loss: 0.312764\n",
      "Train Epoch: 9 Loss: 0.310706\n",
      "Train Epoch: 9 Loss: 0.308676\n",
      "Train Epoch: 9 Loss: 0.306675\n",
      "Train Epoch: 9 Loss: 0.304702\n",
      "Train Epoch: 9 Loss: 0.302757\n",
      "Train Epoch: 9 Loss: 0.300838\n",
      "Train Epoch: 9 Loss: 0.298946\n",
      "Train Epoch: 9 Loss: 0.297079\n",
      "Train Epoch: 9 Loss: 0.295238\n",
      "Train Epoch: 9 Loss: 0.293421\n",
      "Train Epoch: 9 Loss: 0.291630\n",
      "Train Epoch: 9 Loss: 0.289862\n",
      "Train Epoch: 9 Loss: 0.288117\n",
      "Train Epoch: 9 Loss: 0.286396\n",
      "Train Epoch: 9 Loss: 0.284698\n",
      "Train Epoch: 9 Loss: 0.283022\n",
      "Train Epoch: 9 Loss: 0.281368\n",
      "Train Epoch: 9 Loss: 0.279735\n",
      "Train Epoch: 10 Loss: 0.279573\n",
      "Train Epoch: 10 Loss: 0.277964\n",
      "Train Epoch: 10 Loss: 0.276376\n",
      "Train Epoch: 10 Loss: 0.274808\n",
      "Train Epoch: 10 Loss: 0.273260\n",
      "Train Epoch: 10 Loss: 0.271732\n",
      "Train Epoch: 10 Loss: 0.270223\n",
      "Train Epoch: 10 Loss: 0.268733\n",
      "Train Epoch: 10 Loss: 0.267262\n",
      "Train Epoch: 10 Loss: 0.265809\n",
      "Train Epoch: 10 Loss: 0.264375\n",
      "Train Epoch: 10 Loss: 0.262958\n",
      "Train Epoch: 10 Loss: 0.261559\n",
      "Train Epoch: 10 Loss: 0.260177\n",
      "Train Epoch: 10 Loss: 0.258812\n",
      "Train Epoch: 10 Loss: 0.257463\n",
      "Train Epoch: 10 Loss: 0.256131\n",
      "Train Epoch: 10 Loss: 0.254815\n",
      "Train Epoch: 10 Loss: 0.253515\n",
      "Train Epoch: 10 Loss: 0.252231\n",
      "Train Epoch: 10 Loss: 0.250962\n",
      "Train Epoch: 10 Loss: 0.249708\n",
      "Train Epoch: 10 Loss: 0.248469\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.125577\n",
      "Train Epoch: 1 Loss: 17.790136\n",
      "Train Epoch: 1 Loss: 16.534263\n",
      "Train Epoch: 1 Loss: 15.364266\n",
      "Train Epoch: 1 Loss: 14.281891\n",
      "Train Epoch: 1 Loss: 13.285252\n",
      "Train Epoch: 1 Loss: 12.370152\n",
      "Train Epoch: 1 Loss: 11.531302\n",
      "Train Epoch: 1 Loss: 10.762975\n",
      "Train Epoch: 1 Loss: 10.059448\n",
      "Train Epoch: 1 Loss: 9.415197\n",
      "Train Epoch: 1 Loss: 8.825008\n",
      "Train Epoch: 1 Loss: 8.284005\n",
      "Train Epoch: 1 Loss: 7.787702\n",
      "Train Epoch: 1 Loss: 7.331972\n",
      "Train Epoch: 1 Loss: 6.913042\n",
      "Train Epoch: 1 Loss: 6.527496\n",
      "Train Epoch: 1 Loss: 6.172223\n",
      "Train Epoch: 1 Loss: 5.844422\n",
      "Train Epoch: 1 Loss: 5.541557\n",
      "Train Epoch: 1 Loss: 5.261345\n",
      "Train Epoch: 1 Loss: 5.001730\n",
      "Train Epoch: 1 Loss: 4.760861\n",
      "Train Epoch: 2 Loss: 4.737738\n",
      "Train Epoch: 2 Loss: 4.515567\n",
      "Train Epoch: 2 Loss: 4.308833\n",
      "Train Epoch: 2 Loss: 4.116195\n",
      "Train Epoch: 2 Loss: 3.936450\n",
      "Train Epoch: 2 Loss: 3.768511\n",
      "Train Epoch: 2 Loss: 3.611394\n",
      "Train Epoch: 2 Loss: 3.464216\n",
      "Train Epoch: 2 Loss: 3.326173\n",
      "Train Epoch: 2 Loss: 3.196540\n",
      "Train Epoch: 2 Loss: 3.074659\n",
      "Train Epoch: 2 Loss: 2.959932\n",
      "Train Epoch: 2 Loss: 2.851816\n",
      "Train Epoch: 2 Loss: 2.749820\n",
      "Train Epoch: 2 Loss: 2.653490\n",
      "Train Epoch: 2 Loss: 2.562420\n",
      "Train Epoch: 2 Loss: 2.476233\n",
      "Train Epoch: 2 Loss: 2.394588\n",
      "Train Epoch: 2 Loss: 2.317170\n",
      "Train Epoch: 2 Loss: 2.243694\n",
      "Train Epoch: 2 Loss: 2.173893\n",
      "Train Epoch: 2 Loss: 2.107528\n",
      "Train Epoch: 2 Loss: 2.044374\n",
      "Train Epoch: 3 Loss: 2.038228\n",
      "Train Epoch: 3 Loss: 1.978370\n",
      "Train Epoch: 3 Loss: 1.921312\n",
      "Train Epoch: 3 Loss: 1.866878\n",
      "Train Epoch: 3 Loss: 1.814911\n",
      "Train Epoch: 3 Loss: 1.765261\n",
      "Train Epoch: 3 Loss: 1.717790\n",
      "Train Epoch: 3 Loss: 1.672372\n",
      "Train Epoch: 3 Loss: 1.628887\n",
      "Train Epoch: 3 Loss: 1.587228\n",
      "Train Epoch: 3 Loss: 1.547291\n",
      "Train Epoch: 3 Loss: 1.508980\n",
      "Train Epoch: 3 Loss: 1.472208\n",
      "Train Epoch: 3 Loss: 1.436892\n",
      "Train Epoch: 3 Loss: 1.402955\n",
      "Train Epoch: 3 Loss: 1.370324\n",
      "Train Epoch: 3 Loss: 1.338932\n",
      "Train Epoch: 3 Loss: 1.308717\n",
      "Train Epoch: 3 Loss: 1.279618\n",
      "Train Epoch: 3 Loss: 1.251580\n",
      "Train Epoch: 3 Loss: 1.224552\n",
      "Train Epoch: 3 Loss: 1.198485\n",
      "Train Epoch: 3 Loss: 1.173332\n",
      "Train Epoch: 4 Loss: 1.170865\n",
      "Train Epoch: 4 Loss: 1.146668\n",
      "Train Epoch: 4 Loss: 1.123298\n",
      "Train Epoch: 4 Loss: 1.100717\n",
      "Train Epoch: 4 Loss: 1.078888\n",
      "Train Epoch: 4 Loss: 1.057779\n",
      "Train Epoch: 4 Loss: 1.037356\n",
      "Train Epoch: 4 Loss: 1.017590\n",
      "Train Epoch: 4 Loss: 0.998453\n",
      "Train Epoch: 4 Loss: 0.979917\n",
      "Train Epoch: 4 Loss: 0.961956\n",
      "Train Epoch: 4 Loss: 0.944548\n",
      "Train Epoch: 4 Loss: 0.927668\n",
      "Train Epoch: 4 Loss: 0.911295\n",
      "Train Epoch: 4 Loss: 0.895409\n",
      "Train Epoch: 4 Loss: 0.879989\n",
      "Train Epoch: 4 Loss: 0.865018\n",
      "Train Epoch: 4 Loss: 0.850477\n",
      "Train Epoch: 4 Loss: 0.836350\n",
      "Train Epoch: 4 Loss: 0.822621\n",
      "Train Epoch: 4 Loss: 0.809275\n",
      "Train Epoch: 4 Loss: 0.796297\n",
      "Train Epoch: 4 Loss: 0.783674\n",
      "Train Epoch: 5 Loss: 0.782430\n",
      "Train Epoch: 5 Loss: 0.770182\n",
      "Train Epoch: 5 Loss: 0.758261\n",
      "Train Epoch: 5 Loss: 0.746656\n",
      "Train Epoch: 5 Loss: 0.735355\n",
      "Train Epoch: 5 Loss: 0.724348\n",
      "Train Epoch: 5 Loss: 0.713624\n",
      "Train Epoch: 5 Loss: 0.703174\n",
      "Train Epoch: 5 Loss: 0.692987\n",
      "Train Epoch: 5 Loss: 0.683055\n",
      "Train Epoch: 5 Loss: 0.673370\n",
      "Train Epoch: 5 Loss: 0.663922\n",
      "Train Epoch: 5 Loss: 0.654704\n",
      "Train Epoch: 5 Loss: 0.645709\n",
      "Train Epoch: 5 Loss: 0.636929\n",
      "Train Epoch: 5 Loss: 0.628357\n",
      "Train Epoch: 5 Loss: 0.619986\n",
      "Train Epoch: 5 Loss: 0.611811\n",
      "Train Epoch: 5 Loss: 0.603824\n",
      "Train Epoch: 5 Loss: 0.596020\n",
      "Train Epoch: 5 Loss: 0.588394\n",
      "Train Epoch: 5 Loss: 0.580939\n",
      "Train Epoch: 5 Loss: 0.573650\n",
      "Train Epoch: 6 Loss: 0.572931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 Loss: 0.565819\n",
      "Train Epoch: 6 Loss: 0.558865\n",
      "Train Epoch: 6 Loss: 0.552061\n",
      "Train Epoch: 6 Loss: 0.545405\n",
      "Train Epoch: 6 Loss: 0.538891\n",
      "Train Epoch: 6 Loss: 0.532516\n",
      "Train Epoch: 6 Loss: 0.526275\n",
      "Train Epoch: 6 Loss: 0.520165\n",
      "Train Epoch: 6 Loss: 0.514182\n",
      "Train Epoch: 6 Loss: 0.508322\n",
      "Train Epoch: 6 Loss: 0.502582\n",
      "Train Epoch: 6 Loss: 0.496959\n",
      "Train Epoch: 6 Loss: 0.491449\n",
      "Train Epoch: 6 Loss: 0.486049\n",
      "Train Epoch: 6 Loss: 0.480757\n",
      "Train Epoch: 6 Loss: 0.475569\n",
      "Train Epoch: 6 Loss: 0.470483\n",
      "Train Epoch: 6 Loss: 0.465495\n",
      "Train Epoch: 6 Loss: 0.460604\n",
      "Train Epoch: 6 Loss: 0.455806\n",
      "Train Epoch: 6 Loss: 0.451100\n",
      "Train Epoch: 6 Loss: 0.446483\n",
      "Train Epoch: 7 Loss: 0.446026\n",
      "Train Epoch: 7 Loss: 0.441504\n",
      "Train Epoch: 7 Loss: 0.437066\n",
      "Train Epoch: 7 Loss: 0.432710\n",
      "Train Epoch: 7 Loss: 0.428435\n",
      "Train Epoch: 7 Loss: 0.424237\n",
      "Train Epoch: 7 Loss: 0.420115\n",
      "Train Epoch: 7 Loss: 0.416068\n",
      "Train Epoch: 7 Loss: 0.412093\n",
      "Train Epoch: 7 Loss: 0.408189\n",
      "Train Epoch: 7 Loss: 0.404354\n",
      "Train Epoch: 7 Loss: 0.400586\n",
      "Train Epoch: 7 Loss: 0.396884\n",
      "Train Epoch: 7 Loss: 0.393246\n",
      "Train Epoch: 7 Loss: 0.389671\n",
      "Train Epoch: 7 Loss: 0.386157\n",
      "Train Epoch: 7 Loss: 0.382702\n",
      "Train Epoch: 7 Loss: 0.379306\n",
      "Train Epoch: 7 Loss: 0.375967\n",
      "Train Epoch: 7 Loss: 0.372684\n",
      "Train Epoch: 7 Loss: 0.369456\n",
      "Train Epoch: 7 Loss: 0.366280\n",
      "Train Epoch: 7 Loss: 0.363157\n",
      "Train Epoch: 8 Loss: 0.362848\n",
      "Train Epoch: 8 Loss: 0.359780\n",
      "Train Epoch: 8 Loss: 0.356763\n",
      "Train Epoch: 8 Loss: 0.353794\n",
      "Train Epoch: 8 Loss: 0.350872\n",
      "Train Epoch: 8 Loss: 0.347997\n",
      "Train Epoch: 8 Loss: 0.345168\n",
      "Train Epoch: 8 Loss: 0.342383\n",
      "Train Epoch: 8 Loss: 0.339641\n",
      "Train Epoch: 8 Loss: 0.336943\n",
      "Train Epoch: 8 Loss: 0.334286\n",
      "Train Epoch: 8 Loss: 0.331670\n",
      "Train Epoch: 8 Loss: 0.329094\n",
      "Train Epoch: 8 Loss: 0.326557\n",
      "Train Epoch: 8 Loss: 0.324059\n",
      "Train Epoch: 8 Loss: 0.321598\n",
      "Train Epoch: 8 Loss: 0.319174\n",
      "Train Epoch: 8 Loss: 0.316786\n",
      "Train Epoch: 8 Loss: 0.314434\n",
      "Train Epoch: 8 Loss: 0.312116\n",
      "Train Epoch: 8 Loss: 0.309832\n",
      "Train Epoch: 8 Loss: 0.307582\n",
      "Train Epoch: 8 Loss: 0.305364\n",
      "Train Epoch: 9 Loss: 0.305144\n",
      "Train Epoch: 9 Loss: 0.302962\n",
      "Train Epoch: 9 Loss: 0.300810\n",
      "Train Epoch: 9 Loss: 0.298690\n",
      "Train Epoch: 9 Loss: 0.296600\n",
      "Train Epoch: 9 Loss: 0.294538\n",
      "Train Epoch: 9 Loss: 0.292507\n",
      "Train Epoch: 9 Loss: 0.290503\n",
      "Train Epoch: 9 Loss: 0.288528\n",
      "Train Epoch: 9 Loss: 0.286580\n",
      "Train Epoch: 9 Loss: 0.284658\n",
      "Train Epoch: 9 Loss: 0.282764\n",
      "Train Epoch: 9 Loss: 0.280895\n",
      "Train Epoch: 9 Loss: 0.279051\n",
      "Train Epoch: 9 Loss: 0.277232\n",
      "Train Epoch: 9 Loss: 0.275438\n",
      "Train Epoch: 9 Loss: 0.273668\n",
      "Train Epoch: 9 Loss: 0.271922\n",
      "Train Epoch: 9 Loss: 0.270198\n",
      "Train Epoch: 9 Loss: 0.268498\n",
      "Train Epoch: 9 Loss: 0.266820\n",
      "Train Epoch: 9 Loss: 0.265163\n",
      "Train Epoch: 9 Loss: 0.263529\n",
      "Train Epoch: 10 Loss: 0.263367\n",
      "Train Epoch: 10 Loss: 0.261755\n",
      "Train Epoch: 10 Loss: 0.260165\n",
      "Train Epoch: 10 Loss: 0.258595\n",
      "Train Epoch: 10 Loss: 0.257045\n",
      "Train Epoch: 10 Loss: 0.255515\n",
      "Train Epoch: 10 Loss: 0.254004\n",
      "Train Epoch: 10 Loss: 0.252512\n",
      "Train Epoch: 10 Loss: 0.251039\n",
      "Train Epoch: 10 Loss: 0.249585\n",
      "Train Epoch: 10 Loss: 0.248148\n",
      "Train Epoch: 10 Loss: 0.246730\n",
      "Train Epoch: 10 Loss: 0.245329\n",
      "Train Epoch: 10 Loss: 0.243945\n",
      "Train Epoch: 10 Loss: 0.242578\n",
      "Train Epoch: 10 Loss: 0.241228\n",
      "Train Epoch: 10 Loss: 0.239894\n",
      "Train Epoch: 10 Loss: 0.238577\n",
      "Train Epoch: 10 Loss: 0.237275\n",
      "Train Epoch: 10 Loss: 0.235989\n",
      "Train Epoch: 10 Loss: 0.234718\n",
      "Train Epoch: 10 Loss: 0.233463\n",
      "Train Epoch: 10 Loss: 0.232222\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.135776\n",
      "Train Epoch: 1 Loss: 17.801607\n",
      "Train Epoch: 1 Loss: 16.547040\n",
      "Train Epoch: 1 Loss: 15.378362\n",
      "Train Epoch: 1 Loss: 14.297340\n",
      "Train Epoch: 1 Loss: 13.302058\n",
      "Train Epoch: 1 Loss: 12.388333\n",
      "Train Epoch: 1 Loss: 11.550849\n",
      "Train Epoch: 1 Loss: 10.783885\n",
      "Train Epoch: 1 Loss: 10.081697\n",
      "Train Epoch: 1 Loss: 9.438757\n",
      "Train Epoch: 1 Loss: 8.849829\n",
      "Train Epoch: 1 Loss: 8.310046\n",
      "Train Epoch: 1 Loss: 7.814902\n",
      "Train Epoch: 1 Loss: 7.360269\n",
      "Train Epoch: 1 Loss: 6.942384\n",
      "Train Epoch: 1 Loss: 6.557815\n",
      "Train Epoch: 1 Loss: 6.203463\n",
      "Train Epoch: 1 Loss: 5.876523\n",
      "Train Epoch: 1 Loss: 5.574462\n",
      "Train Epoch: 1 Loss: 5.295004\n",
      "Train Epoch: 1 Loss: 5.036090\n",
      "Train Epoch: 1 Loss: 4.795877\n",
      "Train Epoch: 2 Loss: 4.772818\n",
      "Train Epoch: 2 Loss: 4.551255\n",
      "Train Epoch: 2 Loss: 4.345090\n",
      "Train Epoch: 2 Loss: 4.152985\n",
      "Train Epoch: 2 Loss: 3.973740\n",
      "Train Epoch: 2 Loss: 3.806266\n",
      "Train Epoch: 2 Loss: 3.649590\n",
      "Train Epoch: 2 Loss: 3.502823\n",
      "Train Epoch: 2 Loss: 3.365168\n",
      "Train Epoch: 2 Loss: 3.235900\n",
      "Train Epoch: 2 Loss: 3.114362\n",
      "Train Epoch: 2 Loss: 2.999960\n",
      "Train Epoch: 2 Loss: 2.892149\n",
      "Train Epoch: 2 Loss: 2.790442\n",
      "Train Epoch: 2 Loss: 2.694387\n",
      "Train Epoch: 2 Loss: 2.603576\n",
      "Train Epoch: 2 Loss: 2.517636\n",
      "Train Epoch: 2 Loss: 2.436224\n",
      "Train Epoch: 2 Loss: 2.359028\n",
      "Train Epoch: 2 Loss: 2.285763\n",
      "Train Epoch: 2 Loss: 2.216164\n",
      "Train Epoch: 2 Loss: 2.149989\n",
      "Train Epoch: 2 Loss: 2.087017\n",
      "Train Epoch: 3 Loss: 2.080888\n",
      "Train Epoch: 3 Loss: 2.021204\n",
      "Train Epoch: 3 Loss: 1.964310\n",
      "Train Epoch: 3 Loss: 1.910035\n",
      "Train Epoch: 3 Loss: 1.858219\n",
      "Train Epoch: 3 Loss: 1.808713\n",
      "Train Epoch: 3 Loss: 1.761381\n",
      "Train Epoch: 3 Loss: 1.716095\n",
      "Train Epoch: 3 Loss: 1.672738\n",
      "Train Epoch: 3 Loss: 1.631200\n",
      "Train Epoch: 3 Loss: 1.591380\n",
      "Train Epoch: 3 Loss: 1.553182\n",
      "Train Epoch: 3 Loss: 1.516518\n",
      "Train Epoch: 3 Loss: 1.481306\n",
      "Train Epoch: 3 Loss: 1.447469\n",
      "Train Epoch: 3 Loss: 1.414934\n",
      "Train Epoch: 3 Loss: 1.383635\n",
      "Train Epoch: 3 Loss: 1.353509\n",
      "Train Epoch: 3 Loss: 1.324496\n",
      "Train Epoch: 3 Loss: 1.296542\n",
      "Train Epoch: 3 Loss: 1.269594\n",
      "Train Epoch: 3 Loss: 1.243603\n",
      "Train Epoch: 3 Loss: 1.218525\n",
      "Train Epoch: 4 Loss: 1.216066\n",
      "Train Epoch: 4 Loss: 1.191941\n",
      "Train Epoch: 4 Loss: 1.168640\n",
      "Train Epoch: 4 Loss: 1.146126\n",
      "Train Epoch: 4 Loss: 1.124363\n",
      "Train Epoch: 4 Loss: 1.103316\n",
      "Train Epoch: 4 Loss: 1.082955\n",
      "Train Epoch: 4 Loss: 1.063248\n",
      "Train Epoch: 4 Loss: 1.044169\n",
      "Train Epoch: 4 Loss: 1.025688\n",
      "Train Epoch: 4 Loss: 1.007782\n",
      "Train Epoch: 4 Loss: 0.990425\n",
      "Train Epoch: 4 Loss: 0.973596\n",
      "Train Epoch: 4 Loss: 0.957273\n",
      "Train Epoch: 4 Loss: 0.941434\n",
      "Train Epoch: 4 Loss: 0.926061\n",
      "Train Epoch: 4 Loss: 0.911134\n",
      "Train Epoch: 4 Loss: 0.896638\n",
      "Train Epoch: 4 Loss: 0.882554\n",
      "Train Epoch: 4 Loss: 0.868867\n",
      "Train Epoch: 4 Loss: 0.855560\n",
      "Train Epoch: 4 Loss: 0.842622\n",
      "Train Epoch: 4 Loss: 0.830037\n",
      "Train Epoch: 5 Loss: 0.828797\n",
      "Train Epoch: 5 Loss: 0.816586\n",
      "Train Epoch: 5 Loss: 0.804701\n",
      "Train Epoch: 5 Loss: 0.793131\n",
      "Train Epoch: 5 Loss: 0.781865\n",
      "Train Epoch: 5 Loss: 0.770891\n",
      "Train Epoch: 5 Loss: 0.760200\n",
      "Train Epoch: 5 Loss: 0.749781\n",
      "Train Epoch: 5 Loss: 0.739626\n",
      "Train Epoch: 5 Loss: 0.729725\n",
      "Train Epoch: 5 Loss: 0.720069\n",
      "Train Epoch: 5 Loss: 0.710650\n",
      "Train Epoch: 5 Loss: 0.701460\n",
      "Train Epoch: 5 Loss: 0.692493\n",
      "Train Epoch: 5 Loss: 0.683739\n",
      "Train Epoch: 5 Loss: 0.675194\n",
      "Train Epoch: 5 Loss: 0.666849\n",
      "Train Epoch: 5 Loss: 0.658698\n",
      "Train Epoch: 5 Loss: 0.650736\n",
      "Train Epoch: 5 Loss: 0.642956\n",
      "Train Epoch: 5 Loss: 0.635353\n",
      "Train Epoch: 5 Loss: 0.627921\n",
      "Train Epoch: 5 Loss: 0.620655\n",
      "Train Epoch: 6 Loss: 0.619937\n",
      "Train Epoch: 6 Loss: 0.612848\n",
      "Train Epoch: 6 Loss: 0.605915\n",
      "Train Epoch: 6 Loss: 0.599132\n",
      "Train Epoch: 6 Loss: 0.592496\n",
      "Train Epoch: 6 Loss: 0.586002\n",
      "Train Epoch: 6 Loss: 0.579647\n",
      "Train Epoch: 6 Loss: 0.573425\n",
      "Train Epoch: 6 Loss: 0.567334\n",
      "Train Epoch: 6 Loss: 0.561370\n",
      "Train Epoch: 6 Loss: 0.555528\n",
      "Train Epoch: 6 Loss: 0.549806\n",
      "Train Epoch: 6 Loss: 0.544200\n",
      "Train Epoch: 6 Loss: 0.538707\n",
      "Train Epoch: 6 Loss: 0.533324\n",
      "Train Epoch: 6 Loss: 0.528048\n",
      "Train Epoch: 6 Loss: 0.522876\n",
      "Train Epoch: 6 Loss: 0.517806\n",
      "Train Epoch: 6 Loss: 0.512834\n",
      "Train Epoch: 6 Loss: 0.507957\n",
      "Train Epoch: 6 Loss: 0.503175\n",
      "Train Epoch: 6 Loss: 0.498483\n",
      "Train Epoch: 6 Loss: 0.493880\n",
      "Train Epoch: 7 Loss: 0.493425\n",
      "Train Epoch: 7 Loss: 0.488917\n",
      "Train Epoch: 7 Loss: 0.484493\n",
      "Train Epoch: 7 Loss: 0.480151\n",
      "Train Epoch: 7 Loss: 0.475888\n",
      "Train Epoch: 7 Loss: 0.471704\n",
      "Train Epoch: 7 Loss: 0.467595\n",
      "Train Epoch: 7 Loss: 0.463561\n",
      "Train Epoch: 7 Loss: 0.459598\n",
      "Train Epoch: 7 Loss: 0.455706\n",
      "Train Epoch: 7 Loss: 0.451883\n",
      "Train Epoch: 7 Loss: 0.448127\n",
      "Train Epoch: 7 Loss: 0.444436\n",
      "Train Epoch: 7 Loss: 0.440810\n",
      "Train Epoch: 7 Loss: 0.437246\n",
      "Train Epoch: 7 Loss: 0.433743\n",
      "Train Epoch: 7 Loss: 0.430299\n",
      "Train Epoch: 7 Loss: 0.426914\n",
      "Train Epoch: 7 Loss: 0.423585\n",
      "Train Epoch: 7 Loss: 0.420313\n",
      "Train Epoch: 7 Loss: 0.417094\n",
      "Train Epoch: 7 Loss: 0.413929\n",
      "Train Epoch: 7 Loss: 0.410815\n",
      "Train Epoch: 8 Loss: 0.410507\n",
      "Train Epoch: 8 Loss: 0.407449\n",
      "Train Epoch: 8 Loss: 0.404441\n",
      "Train Epoch: 8 Loss: 0.401481\n",
      "Train Epoch: 8 Loss: 0.398569\n",
      "Train Epoch: 8 Loss: 0.395703\n",
      "Train Epoch: 8 Loss: 0.392883\n",
      "Train Epoch: 8 Loss: 0.390106\n",
      "Train Epoch: 8 Loss: 0.387374\n",
      "Train Epoch: 8 Loss: 0.384684\n",
      "Train Epoch: 8 Loss: 0.382035\n",
      "Train Epoch: 8 Loss: 0.379427\n",
      "Train Epoch: 8 Loss: 0.376859\n",
      "Train Epoch: 8 Loss: 0.374330\n",
      "Train Epoch: 8 Loss: 0.371840\n",
      "Train Epoch: 8 Loss: 0.369387\n",
      "Train Epoch: 8 Loss: 0.366971\n",
      "Train Epoch: 8 Loss: 0.364591\n",
      "Train Epoch: 8 Loss: 0.362246\n",
      "Train Epoch: 8 Loss: 0.359935\n",
      "Train Epoch: 8 Loss: 0.357659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 Loss: 0.355415\n",
      "Train Epoch: 8 Loss: 0.353205\n",
      "Train Epoch: 9 Loss: 0.352985\n",
      "Train Epoch: 9 Loss: 0.350810\n",
      "Train Epoch: 9 Loss: 0.348665\n",
      "Train Epoch: 9 Loss: 0.346551\n",
      "Train Epoch: 9 Loss: 0.344468\n",
      "Train Epoch: 9 Loss: 0.342413\n",
      "Train Epoch: 9 Loss: 0.340388\n",
      "Train Epoch: 9 Loss: 0.338391\n",
      "Train Epoch: 9 Loss: 0.336422\n",
      "Train Epoch: 9 Loss: 0.334480\n",
      "Train Epoch: 9 Loss: 0.332565\n",
      "Train Epoch: 9 Loss: 0.330676\n",
      "Train Epoch: 9 Loss: 0.328813\n",
      "Train Epoch: 9 Loss: 0.326975\n",
      "Train Epoch: 9 Loss: 0.325162\n",
      "Train Epoch: 9 Loss: 0.323374\n",
      "Train Epoch: 9 Loss: 0.321609\n",
      "Train Epoch: 9 Loss: 0.319868\n",
      "Train Epoch: 9 Loss: 0.318150\n",
      "Train Epoch: 9 Loss: 0.316455\n",
      "Train Epoch: 9 Loss: 0.314783\n",
      "Train Epoch: 9 Loss: 0.313132\n",
      "Train Epoch: 9 Loss: 0.311502\n",
      "Train Epoch: 10 Loss: 0.311341\n",
      "Train Epoch: 10 Loss: 0.309734\n",
      "Train Epoch: 10 Loss: 0.308149\n",
      "Train Epoch: 10 Loss: 0.306584\n",
      "Train Epoch: 10 Loss: 0.305039\n",
      "Train Epoch: 10 Loss: 0.303514\n",
      "Train Epoch: 10 Loss: 0.302008\n",
      "Train Epoch: 10 Loss: 0.300521\n",
      "Train Epoch: 10 Loss: 0.299053\n",
      "Train Epoch: 10 Loss: 0.297603\n",
      "Train Epoch: 10 Loss: 0.296171\n",
      "Train Epoch: 10 Loss: 0.294757\n",
      "Train Epoch: 10 Loss: 0.293361\n",
      "Train Epoch: 10 Loss: 0.291981\n",
      "Train Epoch: 10 Loss: 0.290619\n",
      "Train Epoch: 10 Loss: 0.289273\n",
      "Train Epoch: 10 Loss: 0.287944\n",
      "Train Epoch: 10 Loss: 0.286630\n",
      "Train Epoch: 10 Loss: 0.285333\n",
      "Train Epoch: 10 Loss: 0.284051\n",
      "Train Epoch: 10 Loss: 0.282784\n",
      "Train Epoch: 10 Loss: 0.281532\n",
      "Train Epoch: 10 Loss: 0.280296\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.130849\n",
      "Train Epoch: 1 Loss: 17.797625\n",
      "Train Epoch: 1 Loss: 16.543916\n",
      "Train Epoch: 1 Loss: 15.375967\n",
      "Train Epoch: 1 Loss: 14.295533\n",
      "Train Epoch: 1 Loss: 13.300701\n",
      "Train Epoch: 1 Loss: 12.387309\n",
      "Train Epoch: 1 Loss: 11.550048\n",
      "Train Epoch: 1 Loss: 10.783209\n",
      "Train Epoch: 1 Loss: 10.081072\n",
      "Train Epoch: 1 Loss: 9.438123\n",
      "Train Epoch: 1 Loss: 8.849144\n",
      "Train Epoch: 1 Loss: 8.309276\n",
      "Train Epoch: 1 Loss: 7.814022\n",
      "Train Epoch: 1 Loss: 7.359269\n",
      "Train Epoch: 1 Loss: 6.941256\n",
      "Train Epoch: 1 Loss: 6.556554\n",
      "Train Epoch: 1 Loss: 6.202072\n",
      "Train Epoch: 1 Loss: 5.875003\n",
      "Train Epoch: 1 Loss: 5.572821\n",
      "Train Epoch: 1 Loss: 5.293245\n",
      "Train Epoch: 1 Loss: 5.034222\n",
      "Train Epoch: 1 Loss: 4.793902\n",
      "Train Epoch: 2 Loss: 4.770833\n",
      "Train Epoch: 2 Loss: 4.549174\n",
      "Train Epoch: 2 Loss: 4.342917\n",
      "Train Epoch: 2 Loss: 4.150727\n",
      "Train Epoch: 2 Loss: 3.971401\n",
      "Train Epoch: 2 Loss: 3.803856\n",
      "Train Epoch: 2 Loss: 3.647107\n",
      "Train Epoch: 2 Loss: 3.500275\n",
      "Train Epoch: 2 Loss: 3.362558\n",
      "Train Epoch: 2 Loss: 3.233231\n",
      "Train Epoch: 2 Loss: 3.111639\n",
      "Train Epoch: 2 Loss: 2.997186\n",
      "Train Epoch: 2 Loss: 2.889328\n",
      "Train Epoch: 2 Loss: 2.787574\n",
      "Train Epoch: 2 Loss: 2.691476\n",
      "Train Epoch: 2 Loss: 2.600625\n",
      "Train Epoch: 2 Loss: 2.514645\n",
      "Train Epoch: 2 Loss: 2.433197\n",
      "Train Epoch: 2 Loss: 2.355967\n",
      "Train Epoch: 2 Loss: 2.282669\n",
      "Train Epoch: 2 Loss: 2.213038\n",
      "Train Epoch: 2 Loss: 2.146834\n",
      "Train Epoch: 2 Loss: 2.083833\n",
      "Train Epoch: 3 Loss: 2.077702\n",
      "Train Epoch: 3 Loss: 2.017990\n",
      "Train Epoch: 3 Loss: 1.961071\n",
      "Train Epoch: 3 Loss: 1.906772\n",
      "Train Epoch: 3 Loss: 1.854932\n",
      "Train Epoch: 3 Loss: 1.805404\n",
      "Train Epoch: 3 Loss: 1.758050\n",
      "Train Epoch: 3 Loss: 1.712744\n",
      "Train Epoch: 3 Loss: 1.669367\n",
      "Train Epoch: 3 Loss: 1.627811\n",
      "Train Epoch: 3 Loss: 1.587972\n",
      "Train Epoch: 3 Loss: 1.549757\n",
      "Train Epoch: 3 Loss: 1.513076\n",
      "Train Epoch: 3 Loss: 1.477848\n",
      "Train Epoch: 3 Loss: 1.443996\n",
      "Train Epoch: 3 Loss: 1.411446\n",
      "Train Epoch: 3 Loss: 1.380133\n",
      "Train Epoch: 3 Loss: 1.349993\n",
      "Train Epoch: 3 Loss: 1.320967\n",
      "Train Epoch: 3 Loss: 1.293000\n",
      "Train Epoch: 3 Loss: 1.266040\n",
      "Train Epoch: 3 Loss: 1.240038\n",
      "Train Epoch: 3 Loss: 1.214948\n",
      "Train Epoch: 4 Loss: 1.212488\n",
      "Train Epoch: 4 Loss: 1.188352\n",
      "Train Epoch: 4 Loss: 1.165041\n",
      "Train Epoch: 4 Loss: 1.142516\n",
      "Train Epoch: 4 Loss: 1.120743\n",
      "Train Epoch: 4 Loss: 1.099687\n",
      "Train Epoch: 4 Loss: 1.079316\n",
      "Train Epoch: 4 Loss: 1.059600\n",
      "Train Epoch: 4 Loss: 1.040512\n",
      "Train Epoch: 4 Loss: 1.022023\n",
      "Train Epoch: 4 Loss: 1.004108\n",
      "Train Epoch: 4 Loss: 0.986744\n",
      "Train Epoch: 4 Loss: 0.969907\n",
      "Train Epoch: 4 Loss: 0.953576\n",
      "Train Epoch: 4 Loss: 0.937730\n",
      "Train Epoch: 4 Loss: 0.922350\n",
      "Train Epoch: 4 Loss: 0.907417\n",
      "Train Epoch: 4 Loss: 0.892913\n",
      "Train Epoch: 4 Loss: 0.878823\n",
      "Train Epoch: 4 Loss: 0.865129\n",
      "Train Epoch: 4 Loss: 0.851817\n",
      "Train Epoch: 4 Loss: 0.838873\n",
      "Train Epoch: 4 Loss: 0.826282\n",
      "Train Epoch: 5 Loss: 0.825042\n",
      "Train Epoch: 5 Loss: 0.812825\n",
      "Train Epoch: 5 Loss: 0.800934\n",
      "Train Epoch: 5 Loss: 0.789359\n",
      "Train Epoch: 5 Loss: 0.778088\n",
      "Train Epoch: 5 Loss: 0.767109\n",
      "Train Epoch: 5 Loss: 0.756413\n",
      "Train Epoch: 5 Loss: 0.745989\n",
      "Train Epoch: 5 Loss: 0.735829\n",
      "Train Epoch: 5 Loss: 0.725923\n",
      "Train Epoch: 5 Loss: 0.716263\n",
      "Train Epoch: 5 Loss: 0.706840\n",
      "Train Epoch: 5 Loss: 0.697646\n",
      "Train Epoch: 5 Loss: 0.688674\n",
      "Train Epoch: 5 Loss: 0.679917\n",
      "Train Epoch: 5 Loss: 0.671367\n",
      "Train Epoch: 5 Loss: 0.663018\n",
      "Train Epoch: 5 Loss: 0.654864\n",
      "Train Epoch: 5 Loss: 0.646898\n",
      "Train Epoch: 5 Loss: 0.639114\n",
      "Train Epoch: 5 Loss: 0.631508\n",
      "Train Epoch: 5 Loss: 0.624072\n",
      "Train Epoch: 5 Loss: 0.616803\n",
      "Train Epoch: 6 Loss: 0.616085\n",
      "Train Epoch: 6 Loss: 0.608993\n",
      "Train Epoch: 6 Loss: 0.602056\n",
      "Train Epoch: 6 Loss: 0.595270\n",
      "Train Epoch: 6 Loss: 0.588631\n",
      "Train Epoch: 6 Loss: 0.582135\n",
      "Train Epoch: 6 Loss: 0.575776\n",
      "Train Epoch: 6 Loss: 0.569552\n",
      "Train Epoch: 6 Loss: 0.563458\n",
      "Train Epoch: 6 Loss: 0.557490\n",
      "Train Epoch: 6 Loss: 0.551646\n",
      "Train Epoch: 6 Loss: 0.545921\n",
      "Train Epoch: 6 Loss: 0.540313\n",
      "Train Epoch: 6 Loss: 0.534817\n",
      "Train Epoch: 6 Loss: 0.529432\n",
      "Train Epoch: 6 Loss: 0.524154\n",
      "Train Epoch: 6 Loss: 0.518979\n",
      "Train Epoch: 6 Loss: 0.513906\n",
      "Train Epoch: 6 Loss: 0.508932\n",
      "Train Epoch: 6 Loss: 0.504054\n",
      "Train Epoch: 6 Loss: 0.499269\n",
      "Train Epoch: 6 Loss: 0.494575\n",
      "Train Epoch: 6 Loss: 0.489970\n",
      "Train Epoch: 7 Loss: 0.489514\n",
      "Train Epoch: 7 Loss: 0.485004\n",
      "Train Epoch: 7 Loss: 0.480578\n",
      "Train Epoch: 7 Loss: 0.476234\n",
      "Train Epoch: 7 Loss: 0.471969\n",
      "Train Epoch: 7 Loss: 0.467783\n",
      "Train Epoch: 7 Loss: 0.463673\n",
      "Train Epoch: 7 Loss: 0.459636\n",
      "Train Epoch: 7 Loss: 0.455672\n",
      "Train Epoch: 7 Loss: 0.451778\n",
      "Train Epoch: 7 Loss: 0.447953\n",
      "Train Epoch: 7 Loss: 0.444195\n",
      "Train Epoch: 7 Loss: 0.440503\n",
      "Train Epoch: 7 Loss: 0.436875\n",
      "Train Epoch: 7 Loss: 0.433309\n",
      "Train Epoch: 7 Loss: 0.429804\n",
      "Train Epoch: 7 Loss: 0.426359\n",
      "Train Epoch: 7 Loss: 0.422972\n",
      "Train Epoch: 7 Loss: 0.419642\n",
      "Train Epoch: 7 Loss: 0.416368\n",
      "Train Epoch: 7 Loss: 0.413148\n",
      "Train Epoch: 7 Loss: 0.409981\n",
      "Train Epoch: 7 Loss: 0.406866\n",
      "Train Epoch: 8 Loss: 0.406558\n",
      "Train Epoch: 8 Loss: 0.403499\n",
      "Train Epoch: 8 Loss: 0.400489\n",
      "Train Epoch: 8 Loss: 0.397528\n",
      "Train Epoch: 8 Loss: 0.394614\n",
      "Train Epoch: 8 Loss: 0.391747\n",
      "Train Epoch: 8 Loss: 0.388925\n",
      "Train Epoch: 8 Loss: 0.386148\n",
      "Train Epoch: 8 Loss: 0.383414\n",
      "Train Epoch: 8 Loss: 0.380722\n",
      "Train Epoch: 8 Loss: 0.378073\n",
      "Train Epoch: 8 Loss: 0.375464\n",
      "Train Epoch: 8 Loss: 0.372895\n",
      "Train Epoch: 8 Loss: 0.370365\n",
      "Train Epoch: 8 Loss: 0.367873\n",
      "Train Epoch: 8 Loss: 0.365419\n",
      "Train Epoch: 8 Loss: 0.363002\n",
      "Train Epoch: 8 Loss: 0.360620\n",
      "Train Epoch: 8 Loss: 0.358274\n",
      "Train Epoch: 8 Loss: 0.355963\n",
      "Train Epoch: 8 Loss: 0.353685\n",
      "Train Epoch: 8 Loss: 0.351441\n",
      "Train Epoch: 8 Loss: 0.349229\n",
      "Train Epoch: 9 Loss: 0.349010\n",
      "Train Epoch: 9 Loss: 0.346833\n",
      "Train Epoch: 9 Loss: 0.344687\n",
      "Train Epoch: 9 Loss: 0.342573\n",
      "Train Epoch: 9 Loss: 0.340488\n",
      "Train Epoch: 9 Loss: 0.338433\n",
      "Train Epoch: 9 Loss: 0.336406\n",
      "Train Epoch: 9 Loss: 0.334408\n",
      "Train Epoch: 9 Loss: 0.332438\n",
      "Train Epoch: 9 Loss: 0.330495\n",
      "Train Epoch: 9 Loss: 0.328579\n",
      "Train Epoch: 9 Loss: 0.326690\n",
      "Train Epoch: 9 Loss: 0.324826\n",
      "Train Epoch: 9 Loss: 0.322987\n",
      "Train Epoch: 9 Loss: 0.321173\n",
      "Train Epoch: 9 Loss: 0.319384\n",
      "Train Epoch: 9 Loss: 0.317619\n",
      "Train Epoch: 9 Loss: 0.315877\n",
      "Train Epoch: 9 Loss: 0.314159\n",
      "Train Epoch: 9 Loss: 0.312463\n",
      "Train Epoch: 9 Loss: 0.310789\n",
      "Train Epoch: 9 Loss: 0.309138\n",
      "Train Epoch: 9 Loss: 0.307507\n",
      "Train Epoch: 10 Loss: 0.307346\n",
      "Train Epoch: 10 Loss: 0.305739\n",
      "Train Epoch: 10 Loss: 0.304153\n",
      "Train Epoch: 10 Loss: 0.302587\n",
      "Train Epoch: 10 Loss: 0.301041\n",
      "Train Epoch: 10 Loss: 0.299515\n",
      "Train Epoch: 10 Loss: 0.298008\n",
      "Train Epoch: 10 Loss: 0.296521\n",
      "Train Epoch: 10 Loss: 0.295052\n",
      "Train Epoch: 10 Loss: 0.293601\n",
      "Train Epoch: 10 Loss: 0.292169\n",
      "Train Epoch: 10 Loss: 0.290754\n",
      "Train Epoch: 10 Loss: 0.289357\n",
      "Train Epoch: 10 Loss: 0.287977\n",
      "Train Epoch: 10 Loss: 0.286614\n",
      "Train Epoch: 10 Loss: 0.285268\n",
      "Train Epoch: 10 Loss: 0.283938\n",
      "Train Epoch: 10 Loss: 0.282624\n",
      "Train Epoch: 10 Loss: 0.281326\n",
      "Train Epoch: 10 Loss: 0.280043\n",
      "Train Epoch: 10 Loss: 0.278776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 Loss: 0.277524\n",
      "Train Epoch: 10 Loss: 0.276286\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.119813\n",
      "Train Epoch: 1 Loss: 17.786248\n",
      "Train Epoch: 1 Loss: 16.532184\n",
      "Train Epoch: 1 Loss: 15.363889\n",
      "Train Epoch: 1 Loss: 14.283107\n",
      "Train Epoch: 1 Loss: 13.287954\n",
      "Train Epoch: 1 Loss: 12.374264\n",
      "Train Epoch: 1 Loss: 11.536743\n",
      "Train Epoch: 1 Loss: 10.769680\n",
      "Train Epoch: 1 Loss: 10.067363\n",
      "Train Epoch: 1 Loss: 9.424264\n",
      "Train Epoch: 1 Loss: 8.835162\n",
      "Train Epoch: 1 Loss: 8.295196\n",
      "Train Epoch: 1 Loss: 7.799868\n",
      "Train Epoch: 1 Loss: 7.345051\n",
      "Train Epoch: 1 Loss: 6.926989\n",
      "Train Epoch: 1 Loss: 6.542246\n",
      "Train Epoch: 1 Loss: 6.187727\n",
      "Train Epoch: 1 Loss: 5.860631\n",
      "Train Epoch: 1 Loss: 5.558421\n",
      "Train Epoch: 1 Loss: 5.278821\n",
      "Train Epoch: 1 Loss: 5.019775\n",
      "Train Epoch: 1 Loss: 4.779435\n",
      "Train Epoch: 2 Loss: 4.756363\n",
      "Train Epoch: 2 Loss: 4.534686\n",
      "Train Epoch: 2 Loss: 4.328412\n",
      "Train Epoch: 2 Loss: 4.136202\n",
      "Train Epoch: 2 Loss: 3.956860\n",
      "Train Epoch: 2 Loss: 3.789295\n",
      "Train Epoch: 2 Loss: 3.632531\n",
      "Train Epoch: 2 Loss: 3.485684\n",
      "Train Epoch: 2 Loss: 3.347951\n",
      "Train Epoch: 2 Loss: 3.218611\n",
      "Train Epoch: 2 Loss: 3.097004\n",
      "Train Epoch: 2 Loss: 2.982536\n",
      "Train Epoch: 2 Loss: 2.874666\n",
      "Train Epoch: 2 Loss: 2.772899\n",
      "Train Epoch: 2 Loss: 2.676788\n",
      "Train Epoch: 2 Loss: 2.585925\n",
      "Train Epoch: 2 Loss: 2.499933\n",
      "Train Epoch: 2 Loss: 2.418472\n",
      "Train Epoch: 2 Loss: 2.341230\n",
      "Train Epoch: 2 Loss: 2.267921\n",
      "Train Epoch: 2 Loss: 2.198279\n",
      "Train Epoch: 2 Loss: 2.132066\n",
      "Train Epoch: 2 Loss: 2.069055\n",
      "Train Epoch: 3 Loss: 2.062922\n",
      "Train Epoch: 3 Loss: 2.003202\n",
      "Train Epoch: 3 Loss: 1.946273\n",
      "Train Epoch: 3 Loss: 1.891964\n",
      "Train Epoch: 3 Loss: 1.840115\n",
      "Train Epoch: 3 Loss: 1.790578\n",
      "Train Epoch: 3 Loss: 1.743215\n",
      "Train Epoch: 3 Loss: 1.697901\n",
      "Train Epoch: 3 Loss: 1.654516\n",
      "Train Epoch: 3 Loss: 1.612952\n",
      "Train Epoch: 3 Loss: 1.573106\n",
      "Train Epoch: 3 Loss: 1.534883\n",
      "Train Epoch: 3 Loss: 1.498195\n",
      "Train Epoch: 3 Loss: 1.462960\n",
      "Train Epoch: 3 Loss: 1.429101\n",
      "Train Epoch: 3 Loss: 1.396544\n",
      "Train Epoch: 3 Loss: 1.365225\n",
      "Train Epoch: 3 Loss: 1.335079\n",
      "Train Epoch: 3 Loss: 1.306047\n",
      "Train Epoch: 3 Loss: 1.278073\n",
      "Train Epoch: 3 Loss: 1.251107\n",
      "Train Epoch: 3 Loss: 1.225100\n",
      "Train Epoch: 3 Loss: 1.200004\n",
      "Train Epoch: 4 Loss: 1.197543\n",
      "Train Epoch: 4 Loss: 1.173402\n",
      "Train Epoch: 4 Loss: 1.150086\n",
      "Train Epoch: 4 Loss: 1.127556\n",
      "Train Epoch: 4 Loss: 1.105778\n",
      "Train Epoch: 4 Loss: 1.084717\n",
      "Train Epoch: 4 Loss: 1.064341\n",
      "Train Epoch: 4 Loss: 1.044621\n",
      "Train Epoch: 4 Loss: 1.025528\n",
      "Train Epoch: 4 Loss: 1.007034\n",
      "Train Epoch: 4 Loss: 0.989115\n",
      "Train Epoch: 4 Loss: 0.971747\n",
      "Train Epoch: 4 Loss: 0.954906\n",
      "Train Epoch: 4 Loss: 0.938571\n",
      "Train Epoch: 4 Loss: 0.922721\n",
      "Train Epoch: 4 Loss: 0.907337\n",
      "Train Epoch: 4 Loss: 0.892400\n",
      "Train Epoch: 4 Loss: 0.877893\n",
      "Train Epoch: 4 Loss: 0.863799\n",
      "Train Epoch: 4 Loss: 0.850101\n",
      "Train Epoch: 4 Loss: 0.836786\n",
      "Train Epoch: 4 Loss: 0.823838\n",
      "Train Epoch: 4 Loss: 0.811244\n",
      "Train Epoch: 5 Loss: 0.810004\n",
      "Train Epoch: 5 Loss: 0.797784\n",
      "Train Epoch: 5 Loss: 0.785890\n",
      "Train Epoch: 5 Loss: 0.774312\n",
      "Train Epoch: 5 Loss: 0.763037\n",
      "Train Epoch: 5 Loss: 0.752056\n",
      "Train Epoch: 5 Loss: 0.741357\n",
      "Train Epoch: 5 Loss: 0.730931\n",
      "Train Epoch: 5 Loss: 0.720767\n",
      "Train Epoch: 5 Loss: 0.710858\n",
      "Train Epoch: 5 Loss: 0.701195\n",
      "Train Epoch: 5 Loss: 0.691770\n",
      "Train Epoch: 5 Loss: 0.682573\n",
      "Train Epoch: 5 Loss: 0.673599\n",
      "Train Epoch: 5 Loss: 0.664839\n",
      "Train Epoch: 5 Loss: 0.656287\n",
      "Train Epoch: 5 Loss: 0.647936\n",
      "Train Epoch: 5 Loss: 0.639779\n",
      "Train Epoch: 5 Loss: 0.631811\n",
      "Train Epoch: 5 Loss: 0.624025\n",
      "Train Epoch: 5 Loss: 0.616416\n",
      "Train Epoch: 5 Loss: 0.608979\n",
      "Train Epoch: 5 Loss: 0.601707\n",
      "Train Epoch: 6 Loss: 0.600989\n",
      "Train Epoch: 6 Loss: 0.593895\n",
      "Train Epoch: 6 Loss: 0.586956\n",
      "Train Epoch: 6 Loss: 0.580168\n",
      "Train Epoch: 6 Loss: 0.573527\n",
      "Train Epoch: 6 Loss: 0.567029\n",
      "Train Epoch: 6 Loss: 0.560668\n",
      "Train Epoch: 6 Loss: 0.554442\n",
      "Train Epoch: 6 Loss: 0.548346\n",
      "Train Epoch: 6 Loss: 0.542377\n",
      "Train Epoch: 6 Loss: 0.536531\n",
      "Train Epoch: 6 Loss: 0.530805\n",
      "Train Epoch: 6 Loss: 0.525194\n",
      "Train Epoch: 6 Loss: 0.519697\n",
      "Train Epoch: 6 Loss: 0.514310\n",
      "Train Epoch: 6 Loss: 0.509030\n",
      "Train Epoch: 6 Loss: 0.503854\n",
      "Train Epoch: 6 Loss: 0.498780\n",
      "Train Epoch: 6 Loss: 0.493804\n",
      "Train Epoch: 6 Loss: 0.488924\n",
      "Train Epoch: 6 Loss: 0.484138\n",
      "Train Epoch: 6 Loss: 0.479442\n",
      "Train Epoch: 6 Loss: 0.474836\n",
      "Train Epoch: 7 Loss: 0.474380\n",
      "Train Epoch: 7 Loss: 0.469868\n",
      "Train Epoch: 7 Loss: 0.465441\n",
      "Train Epoch: 7 Loss: 0.461095\n",
      "Train Epoch: 7 Loss: 0.456830\n",
      "Train Epoch: 7 Loss: 0.452642\n",
      "Train Epoch: 7 Loss: 0.448530\n",
      "Train Epoch: 7 Loss: 0.444492\n",
      "Train Epoch: 7 Loss: 0.440527\n",
      "Train Epoch: 7 Loss: 0.436632\n",
      "Train Epoch: 7 Loss: 0.432806\n",
      "Train Epoch: 7 Loss: 0.429047\n",
      "Train Epoch: 7 Loss: 0.425353\n",
      "Train Epoch: 7 Loss: 0.421724\n",
      "Train Epoch: 7 Loss: 0.418157\n",
      "Train Epoch: 7 Loss: 0.414651\n",
      "Train Epoch: 7 Loss: 0.411205\n",
      "Train Epoch: 7 Loss: 0.407817\n",
      "Train Epoch: 7 Loss: 0.404486\n",
      "Train Epoch: 7 Loss: 0.401210\n",
      "Train Epoch: 7 Loss: 0.397989\n",
      "Train Epoch: 7 Loss: 0.394821\n",
      "Train Epoch: 7 Loss: 0.391705\n",
      "Train Epoch: 8 Loss: 0.391396\n",
      "Train Epoch: 8 Loss: 0.388336\n",
      "Train Epoch: 8 Loss: 0.385326\n",
      "Train Epoch: 8 Loss: 0.382364\n",
      "Train Epoch: 8 Loss: 0.379449\n",
      "Train Epoch: 8 Loss: 0.376581\n",
      "Train Epoch: 8 Loss: 0.373758\n",
      "Train Epoch: 8 Loss: 0.370980\n",
      "Train Epoch: 8 Loss: 0.368245\n",
      "Train Epoch: 8 Loss: 0.365552\n",
      "Train Epoch: 8 Loss: 0.362902\n",
      "Train Epoch: 8 Loss: 0.360292\n",
      "Train Epoch: 8 Loss: 0.357722\n",
      "Train Epoch: 8 Loss: 0.355191\n",
      "Train Epoch: 8 Loss: 0.352699\n",
      "Train Epoch: 8 Loss: 0.350244\n",
      "Train Epoch: 8 Loss: 0.347826\n",
      "Train Epoch: 8 Loss: 0.345443\n",
      "Train Epoch: 8 Loss: 0.343097\n",
      "Train Epoch: 8 Loss: 0.340784\n",
      "Train Epoch: 8 Loss: 0.338506\n",
      "Train Epoch: 8 Loss: 0.336261\n",
      "Train Epoch: 8 Loss: 0.334048\n",
      "Train Epoch: 9 Loss: 0.333829\n",
      "Train Epoch: 9 Loss: 0.331651\n",
      "Train Epoch: 9 Loss: 0.329505\n",
      "Train Epoch: 9 Loss: 0.327390\n",
      "Train Epoch: 9 Loss: 0.325304\n",
      "Train Epoch: 9 Loss: 0.323248\n",
      "Train Epoch: 9 Loss: 0.321221\n",
      "Train Epoch: 9 Loss: 0.319222\n",
      "Train Epoch: 9 Loss: 0.317252\n",
      "Train Epoch: 9 Loss: 0.315308\n",
      "Train Epoch: 9 Loss: 0.313391\n",
      "Train Epoch: 9 Loss: 0.311501\n",
      "Train Epoch: 9 Loss: 0.309636\n",
      "Train Epoch: 9 Loss: 0.307797\n",
      "Train Epoch: 9 Loss: 0.305983\n",
      "Train Epoch: 9 Loss: 0.304193\n",
      "Train Epoch: 9 Loss: 0.302427\n",
      "Train Epoch: 9 Loss: 0.300685\n",
      "Train Epoch: 9 Loss: 0.298965\n",
      "Train Epoch: 9 Loss: 0.297269\n",
      "Train Epoch: 9 Loss: 0.295595\n",
      "Train Epoch: 9 Loss: 0.293942\n",
      "Train Epoch: 9 Loss: 0.292312\n",
      "Train Epoch: 10 Loss: 0.292150\n",
      "Train Epoch: 10 Loss: 0.290542\n",
      "Train Epoch: 10 Loss: 0.288956\n",
      "Train Epoch: 10 Loss: 0.287389\n",
      "Train Epoch: 10 Loss: 0.285843\n",
      "Train Epoch: 10 Loss: 0.284317\n",
      "Train Epoch: 10 Loss: 0.282809\n",
      "Train Epoch: 10 Loss: 0.281321\n",
      "Train Epoch: 10 Loss: 0.279852\n",
      "Train Epoch: 10 Loss: 0.278401\n",
      "Train Epoch: 10 Loss: 0.276968\n",
      "Train Epoch: 10 Loss: 0.275553\n",
      "Train Epoch: 10 Loss: 0.274155\n",
      "Train Epoch: 10 Loss: 0.272774\n",
      "Train Epoch: 10 Loss: 0.271411\n",
      "Train Epoch: 10 Loss: 0.270064\n",
      "Train Epoch: 10 Loss: 0.268733\n",
      "Train Epoch: 10 Loss: 0.267419\n",
      "Train Epoch: 10 Loss: 0.266120\n",
      "Train Epoch: 10 Loss: 0.264837\n",
      "Train Epoch: 10 Loss: 0.263570\n",
      "Train Epoch: 10 Loss: 0.262317\n",
      "Train Epoch: 10 Loss: 0.261079\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.124922\n",
      "Train Epoch: 1 Loss: 17.789646\n",
      "Train Epoch: 1 Loss: 16.533906\n",
      "Train Epoch: 1 Loss: 15.364006\n",
      "Train Epoch: 1 Loss: 14.281706\n",
      "Train Epoch: 1 Loss: 13.285131\n",
      "Train Epoch: 1 Loss: 12.370109\n",
      "Train Epoch: 1 Loss: 11.531361\n",
      "Train Epoch: 1 Loss: 10.763167\n",
      "Train Epoch: 1 Loss: 10.059804\n",
      "Train Epoch: 1 Loss: 9.415753\n",
      "Train Epoch: 1 Loss: 8.825779\n",
      "Train Epoch: 1 Loss: 8.285013\n",
      "Train Epoch: 1 Loss: 7.788955\n",
      "Train Epoch: 1 Loss: 7.333474\n",
      "Train Epoch: 1 Loss: 6.914793\n",
      "Train Epoch: 1 Loss: 6.529489\n",
      "Train Epoch: 1 Loss: 6.174454\n",
      "Train Epoch: 1 Loss: 5.846879\n",
      "Train Epoch: 1 Loss: 5.544229\n",
      "Train Epoch: 1 Loss: 5.264223\n",
      "Train Epoch: 1 Loss: 5.004801\n",
      "Train Epoch: 1 Loss: 4.764111\n",
      "Train Epoch: 2 Loss: 4.741006\n",
      "Train Epoch: 2 Loss: 4.519005\n",
      "Train Epoch: 2 Loss: 4.312430\n",
      "Train Epoch: 2 Loss: 4.119942\n",
      "Train Epoch: 2 Loss: 3.940338\n",
      "Train Epoch: 2 Loss: 3.772530\n",
      "Train Epoch: 2 Loss: 3.615538\n",
      "Train Epoch: 2 Loss: 3.468475\n",
      "Train Epoch: 2 Loss: 3.330541\n",
      "Train Epoch: 2 Loss: 3.201011\n",
      "Train Epoch: 2 Loss: 3.079227\n",
      "Train Epoch: 2 Loss: 2.964591\n",
      "Train Epoch: 2 Loss: 2.856562\n",
      "Train Epoch: 2 Loss: 2.754646\n",
      "Train Epoch: 2 Loss: 2.658395\n",
      "Train Epoch: 2 Loss: 2.567398\n",
      "Train Epoch: 2 Loss: 2.481280\n",
      "Train Epoch: 2 Loss: 2.399700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 Loss: 2.322345\n",
      "Train Epoch: 2 Loss: 2.248928\n",
      "Train Epoch: 2 Loss: 2.179185\n",
      "Train Epoch: 2 Loss: 2.112872\n",
      "Train Epoch: 2 Loss: 2.049770\n",
      "Train Epoch: 3 Loss: 2.043627\n",
      "Train Epoch: 3 Loss: 1.983819\n",
      "Train Epoch: 3 Loss: 1.926807\n",
      "Train Epoch: 3 Loss: 1.872418\n",
      "Train Epoch: 3 Loss: 1.820493\n",
      "Train Epoch: 3 Loss: 1.770883\n",
      "Train Epoch: 3 Loss: 1.723451\n",
      "Train Epoch: 3 Loss: 1.678069\n",
      "Train Epoch: 3 Loss: 1.634621\n",
      "Train Epoch: 3 Loss: 1.592996\n",
      "Train Epoch: 3 Loss: 1.553091\n",
      "Train Epoch: 3 Loss: 1.514812\n",
      "Train Epoch: 3 Loss: 1.478070\n",
      "Train Epoch: 3 Loss: 1.442783\n",
      "Train Epoch: 3 Loss: 1.408874\n",
      "Train Epoch: 3 Loss: 1.376270\n",
      "Train Epoch: 3 Loss: 1.344904\n",
      "Train Epoch: 3 Loss: 1.314713\n",
      "Train Epoch: 3 Loss: 1.285638\n",
      "Train Epoch: 3 Loss: 1.257624\n",
      "Train Epoch: 3 Loss: 1.230618\n",
      "Train Epoch: 3 Loss: 1.204572\n",
      "Train Epoch: 3 Loss: 1.179440\n",
      "Train Epoch: 4 Loss: 1.176975\n",
      "Train Epoch: 4 Loss: 1.152798\n",
      "Train Epoch: 4 Loss: 1.129447\n",
      "Train Epoch: 4 Loss: 1.106885\n",
      "Train Epoch: 4 Loss: 1.085074\n",
      "Train Epoch: 4 Loss: 1.063982\n",
      "Train Epoch: 4 Loss: 1.043577\n",
      "Train Epoch: 4 Loss: 1.023827\n",
      "Train Epoch: 4 Loss: 1.004706\n",
      "Train Epoch: 4 Loss: 0.986185\n",
      "Train Epoch: 4 Loss: 0.968240\n",
      "Train Epoch: 4 Loss: 0.950846\n",
      "Train Epoch: 4 Loss: 0.933980\n",
      "Train Epoch: 4 Loss: 0.917620\n",
      "Train Epoch: 4 Loss: 0.901747\n",
      "Train Epoch: 4 Loss: 0.886341\n",
      "Train Epoch: 4 Loss: 0.871382\n",
      "Train Epoch: 4 Loss: 0.856853\n",
      "Train Epoch: 4 Loss: 0.842738\n",
      "Train Epoch: 4 Loss: 0.829021\n",
      "Train Epoch: 4 Loss: 0.815686\n",
      "Train Epoch: 4 Loss: 0.802719\n",
      "Train Epoch: 4 Loss: 0.790106\n",
      "Train Epoch: 5 Loss: 0.788864\n",
      "Train Epoch: 5 Loss: 0.776626\n",
      "Train Epoch: 5 Loss: 0.764715\n",
      "Train Epoch: 5 Loss: 0.753119\n",
      "Train Epoch: 5 Loss: 0.741828\n",
      "Train Epoch: 5 Loss: 0.730830\n",
      "Train Epoch: 5 Loss: 0.720115\n",
      "Train Epoch: 5 Loss: 0.709673\n",
      "Train Epoch: 5 Loss: 0.699495\n",
      "Train Epoch: 5 Loss: 0.689572\n",
      "Train Epoch: 5 Loss: 0.679895\n",
      "Train Epoch: 5 Loss: 0.670455\n",
      "Train Epoch: 5 Loss: 0.661245\n",
      "Train Epoch: 5 Loss: 0.652257\n",
      "Train Epoch: 5 Loss: 0.643485\n",
      "Train Epoch: 5 Loss: 0.634920\n",
      "Train Epoch: 5 Loss: 0.626556\n",
      "Train Epoch: 5 Loss: 0.618388\n",
      "Train Epoch: 5 Loss: 0.610408\n",
      "Train Epoch: 5 Loss: 0.602611\n",
      "Train Epoch: 5 Loss: 0.594990\n",
      "Train Epoch: 5 Loss: 0.587542\n",
      "Train Epoch: 5 Loss: 0.580260\n",
      "Train Epoch: 6 Loss: 0.579540\n",
      "Train Epoch: 6 Loss: 0.572435\n",
      "Train Epoch: 6 Loss: 0.565486\n",
      "Train Epoch: 6 Loss: 0.558689\n",
      "Train Epoch: 6 Loss: 0.552038\n",
      "Train Epoch: 6 Loss: 0.545529\n",
      "Train Epoch: 6 Loss: 0.539160\n",
      "Train Epoch: 6 Loss: 0.532924\n",
      "Train Epoch: 6 Loss: 0.526820\n",
      "Train Epoch: 6 Loss: 0.520841\n",
      "Train Epoch: 6 Loss: 0.514987\n",
      "Train Epoch: 6 Loss: 0.509252\n",
      "Train Epoch: 6 Loss: 0.503633\n",
      "Train Epoch: 6 Loss: 0.498128\n",
      "Train Epoch: 6 Loss: 0.492733\n",
      "Train Epoch: 6 Loss: 0.487445\n",
      "Train Epoch: 6 Loss: 0.482261\n",
      "Train Epoch: 6 Loss: 0.477179\n",
      "Train Epoch: 6 Loss: 0.472196\n",
      "Train Epoch: 6 Loss: 0.467309\n",
      "Train Epoch: 6 Loss: 0.462515\n",
      "Train Epoch: 6 Loss: 0.457813\n",
      "Train Epoch: 6 Loss: 0.453200\n",
      "Train Epoch: 7 Loss: 0.452743\n",
      "Train Epoch: 7 Loss: 0.448225\n",
      "Train Epoch: 7 Loss: 0.443791\n",
      "Train Epoch: 7 Loss: 0.439439\n",
      "Train Epoch: 7 Loss: 0.435167\n",
      "Train Epoch: 7 Loss: 0.430973\n",
      "Train Epoch: 7 Loss: 0.426855\n",
      "Train Epoch: 7 Loss: 0.422811\n",
      "Train Epoch: 7 Loss: 0.418840\n",
      "Train Epoch: 7 Loss: 0.414939\n",
      "Train Epoch: 7 Loss: 0.411107\n",
      "Train Epoch: 7 Loss: 0.407343\n",
      "Train Epoch: 7 Loss: 0.403644\n",
      "Train Epoch: 7 Loss: 0.400009\n",
      "Train Epoch: 7 Loss: 0.396437\n",
      "Train Epoch: 7 Loss: 0.392926\n",
      "Train Epoch: 7 Loss: 0.389474\n",
      "Train Epoch: 7 Loss: 0.386081\n",
      "Train Epoch: 7 Loss: 0.382745\n",
      "Train Epoch: 7 Loss: 0.379465\n",
      "Train Epoch: 7 Loss: 0.376239\n",
      "Train Epoch: 7 Loss: 0.373066\n",
      "Train Epoch: 7 Loss: 0.369946\n",
      "Train Epoch: 8 Loss: 0.369637\n",
      "Train Epoch: 8 Loss: 0.366572\n",
      "Train Epoch: 8 Loss: 0.363557\n",
      "Train Epoch: 8 Loss: 0.360590\n",
      "Train Epoch: 8 Loss: 0.357671\n",
      "Train Epoch: 8 Loss: 0.354799\n",
      "Train Epoch: 8 Loss: 0.351972\n",
      "Train Epoch: 8 Loss: 0.349189\n",
      "Train Epoch: 8 Loss: 0.346450\n",
      "Train Epoch: 8 Loss: 0.343754\n",
      "Train Epoch: 8 Loss: 0.341099\n",
      "Train Epoch: 8 Loss: 0.338486\n",
      "Train Epoch: 8 Loss: 0.335912\n",
      "Train Epoch: 8 Loss: 0.333377\n",
      "Train Epoch: 8 Loss: 0.330881\n",
      "Train Epoch: 8 Loss: 0.328422\n",
      "Train Epoch: 8 Loss: 0.326001\n",
      "Train Epoch: 8 Loss: 0.323615\n",
      "Train Epoch: 8 Loss: 0.321265\n",
      "Train Epoch: 8 Loss: 0.318949\n",
      "Train Epoch: 8 Loss: 0.316667\n",
      "Train Epoch: 8 Loss: 0.314419\n",
      "Train Epoch: 8 Loss: 0.312203\n",
      "Train Epoch: 9 Loss: 0.311983\n",
      "Train Epoch: 9 Loss: 0.309802\n",
      "Train Epoch: 9 Loss: 0.307653\n",
      "Train Epoch: 9 Loss: 0.305534\n",
      "Train Epoch: 9 Loss: 0.303446\n",
      "Train Epoch: 9 Loss: 0.301387\n",
      "Train Epoch: 9 Loss: 0.299356\n",
      "Train Epoch: 9 Loss: 0.297355\n",
      "Train Epoch: 9 Loss: 0.295381\n",
      "Train Epoch: 9 Loss: 0.293435\n",
      "Train Epoch: 9 Loss: 0.291515\n",
      "Train Epoch: 9 Loss: 0.289622\n",
      "Train Epoch: 9 Loss: 0.287754\n",
      "Train Epoch: 9 Loss: 0.285912\n",
      "Train Epoch: 9 Loss: 0.284095\n",
      "Train Epoch: 9 Loss: 0.282303\n",
      "Train Epoch: 9 Loss: 0.280534\n",
      "Train Epoch: 9 Loss: 0.278789\n",
      "Train Epoch: 9 Loss: 0.277067\n",
      "Train Epoch: 9 Loss: 0.275368\n",
      "Train Epoch: 9 Loss: 0.273692\n",
      "Train Epoch: 9 Loss: 0.272037\n",
      "Train Epoch: 9 Loss: 0.270404\n",
      "Train Epoch: 10 Loss: 0.270242\n",
      "Train Epoch: 10 Loss: 0.268632\n",
      "Train Epoch: 10 Loss: 0.267043\n",
      "Train Epoch: 10 Loss: 0.265474\n",
      "Train Epoch: 10 Loss: 0.263926\n",
      "Train Epoch: 10 Loss: 0.262397\n",
      "Train Epoch: 10 Loss: 0.260887\n",
      "Train Epoch: 10 Loss: 0.259397\n",
      "Train Epoch: 10 Loss: 0.257925\n",
      "Train Epoch: 10 Loss: 0.256472\n",
      "Train Epoch: 10 Loss: 0.255037\n",
      "Train Epoch: 10 Loss: 0.253620\n",
      "Train Epoch: 10 Loss: 0.252220\n",
      "Train Epoch: 10 Loss: 0.250837\n",
      "Train Epoch: 10 Loss: 0.249472\n",
      "Train Epoch: 10 Loss: 0.248123\n",
      "Train Epoch: 10 Loss: 0.246790\n",
      "Train Epoch: 10 Loss: 0.245474\n",
      "Train Epoch: 10 Loss: 0.244173\n",
      "Train Epoch: 10 Loss: 0.242888\n",
      "Train Epoch: 10 Loss: 0.241619\n",
      "Train Epoch: 10 Loss: 0.240364\n",
      "Train Epoch: 10 Loss: 0.239125\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.131314\n",
      "Train Epoch: 1 Loss: 17.794589\n",
      "Train Epoch: 1 Loss: 16.537467\n",
      "Train Epoch: 1 Loss: 15.366252\n",
      "Train Epoch: 1 Loss: 14.282711\n",
      "Train Epoch: 1 Loss: 13.284961\n",
      "Train Epoch: 1 Loss: 12.368833\n",
      "Train Epoch: 1 Loss: 11.529027\n",
      "Train Epoch: 1 Loss: 10.759830\n",
      "Train Epoch: 1 Loss: 10.055519\n",
      "Train Epoch: 1 Loss: 9.410559\n",
      "Train Epoch: 1 Loss: 8.819729\n",
      "Train Epoch: 1 Loss: 8.278158\n",
      "Train Epoch: 1 Loss: 7.781339\n",
      "Train Epoch: 1 Loss: 7.325141\n",
      "Train Epoch: 1 Loss: 6.905791\n",
      "Train Epoch: 1 Loss: 6.519860\n",
      "Train Epoch: 1 Loss: 6.164242\n",
      "Train Epoch: 1 Loss: 5.836120\n",
      "Train Epoch: 1 Loss: 5.532960\n",
      "Train Epoch: 1 Loss: 5.252479\n",
      "Train Epoch: 1 Loss: 4.992615\n",
      "Train Epoch: 1 Loss: 4.751514\n",
      "Train Epoch: 2 Loss: 4.728369\n",
      "Train Epoch: 2 Loss: 4.505986\n",
      "Train Epoch: 2 Loss: 4.299053\n",
      "Train Epoch: 2 Loss: 4.106232\n",
      "Train Epoch: 2 Loss: 3.926316\n",
      "Train Epoch: 2 Loss: 3.758216\n",
      "Train Epoch: 2 Loss: 3.600951\n",
      "Train Epoch: 2 Loss: 3.453632\n",
      "Train Epoch: 2 Loss: 3.315458\n",
      "Train Epoch: 2 Loss: 3.185702\n",
      "Train Epoch: 2 Loss: 3.063704\n",
      "Train Epoch: 2 Loss: 2.948869\n",
      "Train Epoch: 2 Loss: 2.840650\n",
      "Train Epoch: 2 Loss: 2.738555\n",
      "Train Epoch: 2 Loss: 2.642135\n",
      "Train Epoch: 2 Loss: 2.550978\n",
      "Train Epoch: 2 Loss: 2.464709\n",
      "Train Epoch: 2 Loss: 2.382986\n",
      "Train Epoch: 2 Loss: 2.305496\n",
      "Train Epoch: 2 Loss: 2.231949\n",
      "Train Epoch: 2 Loss: 2.162083\n",
      "Train Epoch: 2 Loss: 2.095655\n",
      "Train Epoch: 2 Loss: 2.032441\n",
      "Train Epoch: 3 Loss: 2.026289\n",
      "Train Epoch: 3 Loss: 1.966375\n",
      "Train Epoch: 3 Loss: 1.909262\n",
      "Train Epoch: 3 Loss: 1.854777\n",
      "Train Epoch: 3 Loss: 1.802762\n",
      "Train Epoch: 3 Loss: 1.753064\n",
      "Train Epoch: 3 Loss: 1.705548\n",
      "Train Epoch: 3 Loss: 1.660088\n",
      "Train Epoch: 3 Loss: 1.616562\n",
      "Train Epoch: 3 Loss: 1.574863\n",
      "Train Epoch: 3 Loss: 1.534888\n",
      "Train Epoch: 3 Loss: 1.496542\n",
      "Train Epoch: 3 Loss: 1.459736\n",
      "Train Epoch: 3 Loss: 1.424386\n",
      "Train Epoch: 3 Loss: 1.390417\n",
      "Train Epoch: 3 Loss: 1.357756\n",
      "Train Epoch: 3 Loss: 1.326335\n",
      "Train Epoch: 3 Loss: 1.296091\n",
      "Train Epoch: 3 Loss: 1.266965\n",
      "Train Epoch: 3 Loss: 1.238901\n",
      "Train Epoch: 3 Loss: 1.211848\n",
      "Train Epoch: 3 Loss: 1.185756\n",
      "Train Epoch: 3 Loss: 1.160580\n",
      "Train Epoch: 4 Loss: 1.158110\n",
      "Train Epoch: 4 Loss: 1.133891\n",
      "Train Epoch: 4 Loss: 1.110499\n",
      "Train Epoch: 4 Loss: 1.087897\n",
      "Train Epoch: 4 Loss: 1.066048\n",
      "Train Epoch: 4 Loss: 1.044918\n",
      "Train Epoch: 4 Loss: 1.024477\n",
      "Train Epoch: 4 Loss: 1.004693\n",
      "Train Epoch: 4 Loss: 0.985538\n",
      "Train Epoch: 4 Loss: 0.966984\n",
      "Train Epoch: 4 Loss: 0.949007\n",
      "Train Epoch: 4 Loss: 0.931583\n",
      "Train Epoch: 4 Loss: 0.914687\n",
      "Train Epoch: 4 Loss: 0.898299\n",
      "Train Epoch: 4 Loss: 0.882397\n",
      "Train Epoch: 4 Loss: 0.866964\n",
      "Train Epoch: 4 Loss: 0.851978\n",
      "Train Epoch: 4 Loss: 0.837424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Loss: 0.823284\n",
      "Train Epoch: 4 Loss: 0.809543\n",
      "Train Epoch: 4 Loss: 0.796184\n",
      "Train Epoch: 4 Loss: 0.783194\n",
      "Train Epoch: 4 Loss: 0.770560\n",
      "Train Epoch: 5 Loss: 0.769315\n",
      "Train Epoch: 5 Loss: 0.757055\n",
      "Train Epoch: 5 Loss: 0.745123\n",
      "Train Epoch: 5 Loss: 0.733507\n",
      "Train Epoch: 5 Loss: 0.722196\n",
      "Train Epoch: 5 Loss: 0.711179\n",
      "Train Epoch: 5 Loss: 0.700445\n",
      "Train Epoch: 5 Loss: 0.689985\n",
      "Train Epoch: 5 Loss: 0.679789\n",
      "Train Epoch: 5 Loss: 0.669848\n",
      "Train Epoch: 5 Loss: 0.660153\n",
      "Train Epoch: 5 Loss: 0.650697\n",
      "Train Epoch: 5 Loss: 0.641471\n",
      "Train Epoch: 5 Loss: 0.632467\n",
      "Train Epoch: 5 Loss: 0.623679\n",
      "Train Epoch: 5 Loss: 0.615099\n",
      "Train Epoch: 5 Loss: 0.606721\n",
      "Train Epoch: 5 Loss: 0.598538\n",
      "Train Epoch: 5 Loss: 0.590543\n",
      "Train Epoch: 5 Loss: 0.582733\n",
      "Train Epoch: 5 Loss: 0.575099\n",
      "Train Epoch: 5 Loss: 0.567637\n",
      "Train Epoch: 5 Loss: 0.560342\n",
      "Train Epoch: 6 Loss: 0.559622\n",
      "Train Epoch: 6 Loss: 0.552504\n",
      "Train Epoch: 6 Loss: 0.545543\n",
      "Train Epoch: 6 Loss: 0.538733\n",
      "Train Epoch: 6 Loss: 0.532070\n",
      "Train Epoch: 6 Loss: 0.525550\n",
      "Train Epoch: 6 Loss: 0.519170\n",
      "Train Epoch: 6 Loss: 0.512923\n",
      "Train Epoch: 6 Loss: 0.506807\n",
      "Train Epoch: 6 Loss: 0.500819\n",
      "Train Epoch: 6 Loss: 0.494954\n",
      "Train Epoch: 6 Loss: 0.489208\n",
      "Train Epoch: 6 Loss: 0.483580\n",
      "Train Epoch: 6 Loss: 0.478065\n",
      "Train Epoch: 6 Loss: 0.472660\n",
      "Train Epoch: 6 Loss: 0.467363\n",
      "Train Epoch: 6 Loss: 0.462170\n",
      "Train Epoch: 6 Loss: 0.457079\n",
      "Train Epoch: 6 Loss: 0.452087\n",
      "Train Epoch: 6 Loss: 0.447191\n",
      "Train Epoch: 6 Loss: 0.442389\n",
      "Train Epoch: 6 Loss: 0.437679\n",
      "Train Epoch: 6 Loss: 0.433057\n",
      "Train Epoch: 7 Loss: 0.432600\n",
      "Train Epoch: 7 Loss: 0.428074\n",
      "Train Epoch: 7 Loss: 0.423632\n",
      "Train Epoch: 7 Loss: 0.419272\n",
      "Train Epoch: 7 Loss: 0.414993\n",
      "Train Epoch: 7 Loss: 0.410791\n",
      "Train Epoch: 7 Loss: 0.406666\n",
      "Train Epoch: 7 Loss: 0.402615\n",
      "Train Epoch: 7 Loss: 0.398637\n",
      "Train Epoch: 7 Loss: 0.394729\n",
      "Train Epoch: 7 Loss: 0.390890\n",
      "Train Epoch: 7 Loss: 0.387119\n",
      "Train Epoch: 7 Loss: 0.383413\n",
      "Train Epoch: 7 Loss: 0.379772\n",
      "Train Epoch: 7 Loss: 0.376193\n",
      "Train Epoch: 7 Loss: 0.372676\n",
      "Train Epoch: 7 Loss: 0.369218\n",
      "Train Epoch: 7 Loss: 0.365819\n",
      "Train Epoch: 7 Loss: 0.362477\n",
      "Train Epoch: 7 Loss: 0.359191\n",
      "Train Epoch: 7 Loss: 0.355960\n",
      "Train Epoch: 7 Loss: 0.352782\n",
      "Train Epoch: 7 Loss: 0.349655\n",
      "Train Epoch: 8 Loss: 0.349346\n",
      "Train Epoch: 8 Loss: 0.346275\n",
      "Train Epoch: 8 Loss: 0.343255\n",
      "Train Epoch: 8 Loss: 0.340283\n",
      "Train Epoch: 8 Loss: 0.337359\n",
      "Train Epoch: 8 Loss: 0.334481\n",
      "Train Epoch: 8 Loss: 0.331649\n",
      "Train Epoch: 8 Loss: 0.328862\n",
      "Train Epoch: 8 Loss: 0.326118\n",
      "Train Epoch: 8 Loss: 0.323417\n",
      "Train Epoch: 8 Loss: 0.320758\n",
      "Train Epoch: 8 Loss: 0.318139\n",
      "Train Epoch: 8 Loss: 0.315561\n",
      "Train Epoch: 8 Loss: 0.313022\n",
      "Train Epoch: 8 Loss: 0.310521\n",
      "Train Epoch: 8 Loss: 0.308058\n",
      "Train Epoch: 8 Loss: 0.305632\n",
      "Train Epoch: 8 Loss: 0.303242\n",
      "Train Epoch: 8 Loss: 0.300887\n",
      "Train Epoch: 8 Loss: 0.298568\n",
      "Train Epoch: 8 Loss: 0.296282\n",
      "Train Epoch: 8 Loss: 0.294029\n",
      "Train Epoch: 8 Loss: 0.291809\n",
      "Train Epoch: 9 Loss: 0.291589\n",
      "Train Epoch: 9 Loss: 0.289405\n",
      "Train Epoch: 9 Loss: 0.287251\n",
      "Train Epoch: 9 Loss: 0.285129\n",
      "Train Epoch: 9 Loss: 0.283037\n",
      "Train Epoch: 9 Loss: 0.280974\n",
      "Train Epoch: 9 Loss: 0.278940\n",
      "Train Epoch: 9 Loss: 0.276935\n",
      "Train Epoch: 9 Loss: 0.274958\n",
      "Train Epoch: 9 Loss: 0.273008\n",
      "Train Epoch: 9 Loss: 0.271085\n",
      "Train Epoch: 9 Loss: 0.269188\n",
      "Train Epoch: 9 Loss: 0.267317\n",
      "Train Epoch: 9 Loss: 0.265472\n",
      "Train Epoch: 9 Loss: 0.263652\n",
      "Train Epoch: 9 Loss: 0.261856\n",
      "Train Epoch: 9 Loss: 0.260084\n",
      "Train Epoch: 9 Loss: 0.258336\n",
      "Train Epoch: 9 Loss: 0.256611\n",
      "Train Epoch: 9 Loss: 0.254909\n",
      "Train Epoch: 9 Loss: 0.253230\n",
      "Train Epoch: 9 Loss: 0.251572\n",
      "Train Epoch: 9 Loss: 0.249936\n",
      "Train Epoch: 10 Loss: 0.249773\n",
      "Train Epoch: 10 Loss: 0.248161\n",
      "Train Epoch: 10 Loss: 0.246569\n",
      "Train Epoch: 10 Loss: 0.244997\n",
      "Train Epoch: 10 Loss: 0.243446\n",
      "Train Epoch: 10 Loss: 0.241914\n",
      "Train Epoch: 10 Loss: 0.240402\n",
      "Train Epoch: 10 Loss: 0.238909\n",
      "Train Epoch: 10 Loss: 0.237435\n",
      "Train Epoch: 10 Loss: 0.235979\n",
      "Train Epoch: 10 Loss: 0.234541\n",
      "Train Epoch: 10 Loss: 0.233121\n",
      "Train Epoch: 10 Loss: 0.231719\n",
      "Train Epoch: 10 Loss: 0.230334\n",
      "Train Epoch: 10 Loss: 0.228966\n",
      "Train Epoch: 10 Loss: 0.227615\n",
      "Train Epoch: 10 Loss: 0.226280\n",
      "Train Epoch: 10 Loss: 0.224961\n",
      "Train Epoch: 10 Loss: 0.223658\n",
      "Train Epoch: 10 Loss: 0.222371\n",
      "Train Epoch: 10 Loss: 0.221099\n",
      "Train Epoch: 10 Loss: 0.219842\n",
      "Train Epoch: 10 Loss: 0.218600\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.126849\n",
      "Train Epoch: 1 Loss: 17.790187\n",
      "Train Epoch: 1 Loss: 16.533096\n",
      "Train Epoch: 1 Loss: 15.361857\n",
      "Train Epoch: 1 Loss: 14.278249\n",
      "Train Epoch: 1 Loss: 13.280375\n",
      "Train Epoch: 1 Loss: 12.364081\n",
      "Train Epoch: 1 Loss: 11.524085\n",
      "Train Epoch: 1 Loss: 10.754677\n",
      "Train Epoch: 1 Loss: 10.050137\n",
      "Train Epoch: 1 Loss: 9.404946\n",
      "Train Epoch: 1 Loss: 8.813876\n",
      "Train Epoch: 1 Loss: 8.272071\n",
      "Train Epoch: 1 Loss: 7.775024\n",
      "Train Epoch: 1 Loss: 7.318604\n",
      "Train Epoch: 1 Loss: 6.899044\n",
      "Train Epoch: 1 Loss: 6.512910\n",
      "Train Epoch: 1 Loss: 6.157098\n",
      "Train Epoch: 1 Loss: 5.828799\n",
      "Train Epoch: 1 Loss: 5.525470\n",
      "Train Epoch: 1 Loss: 5.244831\n",
      "Train Epoch: 1 Loss: 4.984816\n",
      "Train Epoch: 1 Loss: 4.743578\n",
      "Train Epoch: 2 Loss: 4.720419\n",
      "Train Epoch: 2 Loss: 4.497907\n",
      "Train Epoch: 2 Loss: 4.290854\n",
      "Train Epoch: 2 Loss: 4.097921\n",
      "Train Epoch: 2 Loss: 3.917897\n",
      "Train Epoch: 2 Loss: 3.749699\n",
      "Train Epoch: 2 Loss: 3.592340\n",
      "Train Epoch: 2 Loss: 3.444933\n",
      "Train Epoch: 2 Loss: 3.306676\n",
      "Train Epoch: 2 Loss: 3.176841\n",
      "Train Epoch: 2 Loss: 3.054771\n",
      "Train Epoch: 2 Loss: 2.939866\n",
      "Train Epoch: 2 Loss: 2.831582\n",
      "Train Epoch: 2 Loss: 2.729426\n",
      "Train Epoch: 2 Loss: 2.632948\n",
      "Train Epoch: 2 Loss: 2.541735\n",
      "Train Epoch: 2 Loss: 2.455413\n",
      "Train Epoch: 2 Loss: 2.373641\n",
      "Train Epoch: 2 Loss: 2.296103\n",
      "Train Epoch: 2 Loss: 2.222511\n",
      "Train Epoch: 2 Loss: 2.152603\n",
      "Train Epoch: 2 Loss: 2.086132\n",
      "Train Epoch: 2 Loss: 2.022880\n",
      "Train Epoch: 3 Loss: 2.016724\n",
      "Train Epoch: 3 Loss: 1.956772\n",
      "Train Epoch: 3 Loss: 1.899625\n",
      "Train Epoch: 3 Loss: 1.845106\n",
      "Train Epoch: 3 Loss: 1.793057\n",
      "Train Epoch: 3 Loss: 1.743329\n",
      "Train Epoch: 3 Loss: 1.695784\n",
      "Train Epoch: 3 Loss: 1.650294\n",
      "Train Epoch: 3 Loss: 1.606741\n",
      "Train Epoch: 3 Loss: 1.565016\n",
      "Train Epoch: 3 Loss: 1.525016\n",
      "Train Epoch: 3 Loss: 1.486645\n",
      "Train Epoch: 3 Loss: 1.449816\n",
      "Train Epoch: 3 Loss: 1.414444\n",
      "Train Epoch: 3 Loss: 1.380453\n",
      "Train Epoch: 3 Loss: 1.347771\n",
      "Train Epoch: 3 Loss: 1.316330\n",
      "Train Epoch: 3 Loss: 1.286067\n",
      "Train Epoch: 3 Loss: 1.256922\n",
      "Train Epoch: 3 Loss: 1.228840\n",
      "Train Epoch: 3 Loss: 1.201770\n",
      "Train Epoch: 3 Loss: 1.175661\n",
      "Train Epoch: 3 Loss: 1.150468\n",
      "Train Epoch: 4 Loss: 1.147997\n",
      "Train Epoch: 4 Loss: 1.123762\n",
      "Train Epoch: 4 Loss: 1.100355\n",
      "Train Epoch: 4 Loss: 1.077738\n",
      "Train Epoch: 4 Loss: 1.055875\n",
      "Train Epoch: 4 Loss: 1.034732\n",
      "Train Epoch: 4 Loss: 1.014278\n",
      "Train Epoch: 4 Loss: 0.994480\n",
      "Train Epoch: 4 Loss: 0.975313\n",
      "Train Epoch: 4 Loss: 0.956747\n",
      "Train Epoch: 4 Loss: 0.938759\n",
      "Train Epoch: 4 Loss: 0.921322\n",
      "Train Epoch: 4 Loss: 0.904416\n",
      "Train Epoch: 4 Loss: 0.888017\n",
      "Train Epoch: 4 Loss: 0.872105\n",
      "Train Epoch: 4 Loss: 0.856661\n",
      "Train Epoch: 4 Loss: 0.841666\n",
      "Train Epoch: 4 Loss: 0.827103\n",
      "Train Epoch: 4 Loss: 0.812953\n",
      "Train Epoch: 4 Loss: 0.799203\n",
      "Train Epoch: 4 Loss: 0.785835\n",
      "Train Epoch: 4 Loss: 0.772837\n",
      "Train Epoch: 4 Loss: 0.760193\n",
      "Train Epoch: 5 Loss: 0.758948\n",
      "Train Epoch: 5 Loss: 0.746680\n",
      "Train Epoch: 5 Loss: 0.734740\n",
      "Train Epoch: 5 Loss: 0.723117\n",
      "Train Epoch: 5 Loss: 0.711798\n",
      "Train Epoch: 5 Loss: 0.700773\n",
      "Train Epoch: 5 Loss: 0.690032\n",
      "Train Epoch: 5 Loss: 0.679565\n",
      "Train Epoch: 5 Loss: 0.669362\n",
      "Train Epoch: 5 Loss: 0.659415\n",
      "Train Epoch: 5 Loss: 0.649714\n",
      "Train Epoch: 5 Loss: 0.640251\n",
      "Train Epoch: 5 Loss: 0.631019\n",
      "Train Epoch: 5 Loss: 0.622009\n",
      "Train Epoch: 5 Loss: 0.613215\n",
      "Train Epoch: 5 Loss: 0.604630\n",
      "Train Epoch: 5 Loss: 0.596246\n",
      "Train Epoch: 5 Loss: 0.588057\n",
      "Train Epoch: 5 Loss: 0.580058\n",
      "Train Epoch: 5 Loss: 0.572241\n",
      "Train Epoch: 5 Loss: 0.564602\n",
      "Train Epoch: 5 Loss: 0.557136\n",
      "Train Epoch: 5 Loss: 0.549836\n",
      "Train Epoch: 6 Loss: 0.549115\n",
      "Train Epoch: 6 Loss: 0.541992\n",
      "Train Epoch: 6 Loss: 0.535026\n",
      "Train Epoch: 6 Loss: 0.528212\n",
      "Train Epoch: 6 Loss: 0.521545\n",
      "Train Epoch: 6 Loss: 0.515021\n",
      "Train Epoch: 6 Loss: 0.508635\n",
      "Train Epoch: 6 Loss: 0.502385\n",
      "Train Epoch: 6 Loss: 0.496265\n",
      "Train Epoch: 6 Loss: 0.490272\n",
      "Train Epoch: 6 Loss: 0.484403\n",
      "Train Epoch: 6 Loss: 0.478654\n",
      "Train Epoch: 6 Loss: 0.473022\n",
      "Train Epoch: 6 Loss: 0.467503\n",
      "Train Epoch: 6 Loss: 0.462095\n",
      "Train Epoch: 6 Loss: 0.456794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 Loss: 0.451597\n",
      "Train Epoch: 6 Loss: 0.446503\n",
      "Train Epoch: 6 Loss: 0.441507\n",
      "Train Epoch: 6 Loss: 0.436608\n",
      "Train Epoch: 6 Loss: 0.431803\n",
      "Train Epoch: 6 Loss: 0.427089\n",
      "Train Epoch: 6 Loss: 0.422464\n",
      "Train Epoch: 7 Loss: 0.422007\n",
      "Train Epoch: 7 Loss: 0.417478\n",
      "Train Epoch: 7 Loss: 0.413033\n",
      "Train Epoch: 7 Loss: 0.408670\n",
      "Train Epoch: 7 Loss: 0.404387\n",
      "Train Epoch: 7 Loss: 0.400183\n",
      "Train Epoch: 7 Loss: 0.396055\n",
      "Train Epoch: 7 Loss: 0.392001\n",
      "Train Epoch: 7 Loss: 0.388020\n",
      "Train Epoch: 7 Loss: 0.384110\n",
      "Train Epoch: 7 Loss: 0.380268\n",
      "Train Epoch: 7 Loss: 0.376494\n",
      "Train Epoch: 7 Loss: 0.372786\n",
      "Train Epoch: 7 Loss: 0.369143\n",
      "Train Epoch: 7 Loss: 0.365562\n",
      "Train Epoch: 7 Loss: 0.362042\n",
      "Train Epoch: 7 Loss: 0.358582\n",
      "Train Epoch: 7 Loss: 0.355180\n",
      "Train Epoch: 7 Loss: 0.351836\n",
      "Train Epoch: 7 Loss: 0.348548\n",
      "Train Epoch: 7 Loss: 0.345314\n",
      "Train Epoch: 7 Loss: 0.342133\n",
      "Train Epoch: 7 Loss: 0.339005\n",
      "Train Epoch: 8 Loss: 0.338695\n",
      "Train Epoch: 8 Loss: 0.335623\n",
      "Train Epoch: 8 Loss: 0.332600\n",
      "Train Epoch: 8 Loss: 0.329627\n",
      "Train Epoch: 8 Loss: 0.326701\n",
      "Train Epoch: 8 Loss: 0.323821\n",
      "Train Epoch: 8 Loss: 0.320987\n",
      "Train Epoch: 8 Loss: 0.318197\n",
      "Train Epoch: 8 Loss: 0.315452\n",
      "Train Epoch: 8 Loss: 0.312749\n",
      "Train Epoch: 8 Loss: 0.310087\n",
      "Train Epoch: 8 Loss: 0.307467\n",
      "Train Epoch: 8 Loss: 0.304887\n",
      "Train Epoch: 8 Loss: 0.302346\n",
      "Train Epoch: 8 Loss: 0.299844\n",
      "Train Epoch: 8 Loss: 0.297379\n",
      "Train Epoch: 8 Loss: 0.294951\n",
      "Train Epoch: 8 Loss: 0.292560\n",
      "Train Epoch: 8 Loss: 0.290203\n",
      "Train Epoch: 8 Loss: 0.287882\n",
      "Train Epoch: 8 Loss: 0.285595\n",
      "Train Epoch: 8 Loss: 0.283340\n",
      "Train Epoch: 8 Loss: 0.281119\n",
      "Train Epoch: 9 Loss: 0.280899\n",
      "Train Epoch: 9 Loss: 0.278713\n",
      "Train Epoch: 9 Loss: 0.276558\n",
      "Train Epoch: 9 Loss: 0.274434\n",
      "Train Epoch: 9 Loss: 0.272340\n",
      "Train Epoch: 9 Loss: 0.270276\n",
      "Train Epoch: 9 Loss: 0.268241\n",
      "Train Epoch: 9 Loss: 0.266234\n",
      "Train Epoch: 9 Loss: 0.264256\n",
      "Train Epoch: 9 Loss: 0.262304\n",
      "Train Epoch: 9 Loss: 0.260380\n",
      "Train Epoch: 9 Loss: 0.258482\n",
      "Train Epoch: 9 Loss: 0.256610\n",
      "Train Epoch: 9 Loss: 0.254763\n",
      "Train Epoch: 9 Loss: 0.252942\n",
      "Train Epoch: 9 Loss: 0.251145\n",
      "Train Epoch: 9 Loss: 0.249372\n",
      "Train Epoch: 9 Loss: 0.247622\n",
      "Train Epoch: 9 Loss: 0.245896\n",
      "Train Epoch: 9 Loss: 0.244193\n",
      "Train Epoch: 9 Loss: 0.242512\n",
      "Train Epoch: 9 Loss: 0.240853\n",
      "Train Epoch: 9 Loss: 0.239216\n",
      "Train Epoch: 10 Loss: 0.239054\n",
      "Train Epoch: 10 Loss: 0.237440\n",
      "Train Epoch: 10 Loss: 0.235847\n",
      "Train Epoch: 10 Loss: 0.234274\n",
      "Train Epoch: 10 Loss: 0.232722\n",
      "Train Epoch: 10 Loss: 0.231189\n",
      "Train Epoch: 10 Loss: 0.229676\n",
      "Train Epoch: 10 Loss: 0.228182\n",
      "Train Epoch: 10 Loss: 0.226706\n",
      "Train Epoch: 10 Loss: 0.225249\n",
      "Train Epoch: 10 Loss: 0.223811\n",
      "Train Epoch: 10 Loss: 0.222390\n",
      "Train Epoch: 10 Loss: 0.220987\n",
      "Train Epoch: 10 Loss: 0.219601\n",
      "Train Epoch: 10 Loss: 0.218232\n",
      "Train Epoch: 10 Loss: 0.216879\n",
      "Train Epoch: 10 Loss: 0.215543\n",
      "Train Epoch: 10 Loss: 0.214224\n",
      "Train Epoch: 10 Loss: 0.212920\n",
      "Train Epoch: 10 Loss: 0.211632\n",
      "Train Epoch: 10 Loss: 0.210359\n",
      "Train Epoch: 10 Loss: 0.209101\n",
      "Train Epoch: 10 Loss: 0.207859\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.115400\n",
      "Train Epoch: 1 Loss: 17.780492\n",
      "Train Epoch: 1 Loss: 16.525081\n",
      "Train Epoch: 1 Loss: 15.355439\n",
      "Train Epoch: 1 Loss: 14.273339\n",
      "Train Epoch: 1 Loss: 13.276898\n",
      "Train Epoch: 1 Loss: 12.361967\n",
      "Train Epoch: 1 Loss: 11.523258\n",
      "Train Epoch: 1 Loss: 10.755064\n",
      "Train Epoch: 1 Loss: 10.051679\n",
      "Train Epoch: 1 Loss: 9.407577\n",
      "Train Epoch: 1 Loss: 8.817541\n",
      "Train Epoch: 1 Loss: 8.276701\n",
      "Train Epoch: 1 Loss: 7.780558\n",
      "Train Epoch: 1 Loss: 7.324990\n",
      "Train Epoch: 1 Loss: 6.906224\n",
      "Train Epoch: 1 Loss: 6.520828\n",
      "Train Epoch: 1 Loss: 6.165710\n",
      "Train Epoch: 1 Loss: 5.838050\n",
      "Train Epoch: 1 Loss: 5.535322\n",
      "Train Epoch: 1 Loss: 5.255237\n",
      "Train Epoch: 1 Loss: 4.995741\n",
      "Train Epoch: 1 Loss: 4.754983\n",
      "Train Epoch: 2 Loss: 4.731872\n",
      "Train Epoch: 2 Loss: 4.509805\n",
      "Train Epoch: 2 Loss: 4.303167\n",
      "Train Epoch: 2 Loss: 4.110621\n",
      "Train Epoch: 2 Loss: 3.930961\n",
      "Train Epoch: 2 Loss: 3.763101\n",
      "Train Epoch: 2 Loss: 3.606059\n",
      "Train Epoch: 2 Loss: 3.458950\n",
      "Train Epoch: 2 Loss: 3.320973\n",
      "Train Epoch: 2 Loss: 3.191400\n",
      "Train Epoch: 2 Loss: 3.069576\n",
      "Train Epoch: 2 Loss: 2.954903\n",
      "Train Epoch: 2 Loss: 2.846837\n",
      "Train Epoch: 2 Loss: 2.744887\n",
      "Train Epoch: 2 Loss: 2.648602\n",
      "Train Epoch: 2 Loss: 2.557574\n",
      "Train Epoch: 2 Loss: 2.471428\n",
      "Train Epoch: 2 Loss: 2.389820\n",
      "Train Epoch: 2 Loss: 2.312437\n",
      "Train Epoch: 2 Loss: 2.238994\n",
      "Train Epoch: 2 Loss: 2.169226\n",
      "Train Epoch: 2 Loss: 2.102890\n",
      "Train Epoch: 2 Loss: 2.039765\n",
      "Train Epoch: 3 Loss: 2.033621\n",
      "Train Epoch: 3 Loss: 1.973791\n",
      "Train Epoch: 3 Loss: 1.916757\n",
      "Train Epoch: 3 Loss: 1.862349\n",
      "Train Epoch: 3 Loss: 1.810404\n",
      "Train Epoch: 3 Loss: 1.760776\n",
      "Train Epoch: 3 Loss: 1.713326\n",
      "Train Epoch: 3 Loss: 1.667928\n",
      "Train Epoch: 3 Loss: 1.624463\n",
      "Train Epoch: 3 Loss: 1.582821\n",
      "Train Epoch: 3 Loss: 1.542901\n",
      "Train Epoch: 3 Loss: 1.504607\n",
      "Train Epoch: 3 Loss: 1.467852\n",
      "Train Epoch: 3 Loss: 1.432551\n",
      "Train Epoch: 3 Loss: 1.398628\n",
      "Train Epoch: 3 Loss: 1.366012\n",
      "Train Epoch: 3 Loss: 1.334633\n",
      "Train Epoch: 3 Loss: 1.304431\n",
      "Train Epoch: 3 Loss: 1.275345\n",
      "Train Epoch: 3 Loss: 1.247319\n",
      "Train Epoch: 3 Loss: 1.220302\n",
      "Train Epoch: 3 Loss: 1.194245\n",
      "Train Epoch: 3 Loss: 1.169103\n",
      "Train Epoch: 4 Loss: 1.166637\n",
      "Train Epoch: 4 Loss: 1.142451\n",
      "Train Epoch: 4 Loss: 1.119090\n",
      "Train Epoch: 4 Loss: 1.096518\n",
      "Train Epoch: 4 Loss: 1.074699\n",
      "Train Epoch: 4 Loss: 1.053598\n",
      "Train Epoch: 4 Loss: 1.033184\n",
      "Train Epoch: 4 Loss: 1.013427\n",
      "Train Epoch: 4 Loss: 0.994297\n",
      "Train Epoch: 4 Loss: 0.975769\n",
      "Train Epoch: 4 Loss: 0.957816\n",
      "Train Epoch: 4 Loss: 0.940415\n",
      "Train Epoch: 4 Loss: 0.923542\n",
      "Train Epoch: 4 Loss: 0.907175\n",
      "Train Epoch: 4 Loss: 0.891295\n",
      "Train Epoch: 4 Loss: 0.875882\n",
      "Train Epoch: 4 Loss: 0.860917\n",
      "Train Epoch: 4 Loss: 0.846382\n",
      "Train Epoch: 4 Loss: 0.832261\n",
      "Train Epoch: 4 Loss: 0.818538\n",
      "Train Epoch: 4 Loss: 0.805197\n",
      "Train Epoch: 4 Loss: 0.792224\n",
      "Train Epoch: 4 Loss: 0.779606\n",
      "Train Epoch: 5 Loss: 0.778363\n",
      "Train Epoch: 5 Loss: 0.766119\n",
      "Train Epoch: 5 Loss: 0.754203\n",
      "Train Epoch: 5 Loss: 0.742603\n",
      "Train Epoch: 5 Loss: 0.731307\n",
      "Train Epoch: 5 Loss: 0.720304\n",
      "Train Epoch: 5 Loss: 0.709584\n",
      "Train Epoch: 5 Loss: 0.699138\n",
      "Train Epoch: 5 Loss: 0.688955\n",
      "Train Epoch: 5 Loss: 0.679028\n",
      "Train Epoch: 5 Loss: 0.669346\n",
      "Train Epoch: 5 Loss: 0.659902\n",
      "Train Epoch: 5 Loss: 0.650688\n",
      "Train Epoch: 5 Loss: 0.641696\n",
      "Train Epoch: 5 Loss: 0.632920\n",
      "Train Epoch: 5 Loss: 0.624351\n",
      "Train Epoch: 5 Loss: 0.615984\n",
      "Train Epoch: 5 Loss: 0.607811\n",
      "Train Epoch: 5 Loss: 0.599828\n",
      "Train Epoch: 5 Loss: 0.592027\n",
      "Train Epoch: 5 Loss: 0.584403\n",
      "Train Epoch: 5 Loss: 0.576951\n",
      "Train Epoch: 5 Loss: 0.569666\n",
      "Train Epoch: 6 Loss: 0.568946\n",
      "Train Epoch: 6 Loss: 0.561838\n",
      "Train Epoch: 6 Loss: 0.554886\n",
      "Train Epoch: 6 Loss: 0.548085\n",
      "Train Epoch: 6 Loss: 0.541431\n",
      "Train Epoch: 6 Loss: 0.534920\n",
      "Train Epoch: 6 Loss: 0.528547\n",
      "Train Epoch: 6 Loss: 0.522309\n",
      "Train Epoch: 6 Loss: 0.516201\n",
      "Train Epoch: 6 Loss: 0.510220\n",
      "Train Epoch: 6 Loss: 0.504362\n",
      "Train Epoch: 6 Loss: 0.498625\n",
      "Train Epoch: 6 Loss: 0.493004\n",
      "Train Epoch: 6 Loss: 0.487496\n",
      "Train Epoch: 6 Loss: 0.482099\n",
      "Train Epoch: 6 Loss: 0.476808\n",
      "Train Epoch: 6 Loss: 0.471622\n",
      "Train Epoch: 6 Loss: 0.466537\n",
      "Train Epoch: 6 Loss: 0.461552\n",
      "Train Epoch: 6 Loss: 0.456662\n",
      "Train Epoch: 6 Loss: 0.451867\n",
      "Train Epoch: 6 Loss: 0.447162\n",
      "Train Epoch: 6 Loss: 0.442547\n",
      "Train Epoch: 7 Loss: 0.442090\n",
      "Train Epoch: 7 Loss: 0.437570\n",
      "Train Epoch: 7 Loss: 0.433133\n",
      "Train Epoch: 7 Loss: 0.428780\n",
      "Train Epoch: 7 Loss: 0.424505\n",
      "Train Epoch: 7 Loss: 0.420309\n",
      "Train Epoch: 7 Loss: 0.416189\n",
      "Train Epoch: 7 Loss: 0.412144\n",
      "Train Epoch: 7 Loss: 0.408170\n",
      "Train Epoch: 7 Loss: 0.404268\n",
      "Train Epoch: 7 Loss: 0.400434\n",
      "Train Epoch: 7 Loss: 0.396668\n",
      "Train Epoch: 7 Loss: 0.392967\n",
      "Train Epoch: 7 Loss: 0.389330\n",
      "Train Epoch: 7 Loss: 0.385756\n",
      "Train Epoch: 7 Loss: 0.382244\n",
      "Train Epoch: 7 Loss: 0.378791\n",
      "Train Epoch: 7 Loss: 0.375396\n",
      "Train Epoch: 7 Loss: 0.372058\n",
      "Train Epoch: 7 Loss: 0.368776\n",
      "Train Epoch: 7 Loss: 0.365549\n",
      "Train Epoch: 7 Loss: 0.362375\n",
      "Train Epoch: 7 Loss: 0.359253\n",
      "Train Epoch: 8 Loss: 0.358943\n",
      "Train Epoch: 8 Loss: 0.355877\n",
      "Train Epoch: 8 Loss: 0.352861\n",
      "Train Epoch: 8 Loss: 0.349893\n",
      "Train Epoch: 8 Loss: 0.346972\n",
      "Train Epoch: 8 Loss: 0.344098\n",
      "Train Epoch: 8 Loss: 0.341270\n",
      "Train Epoch: 8 Loss: 0.338486\n",
      "Train Epoch: 8 Loss: 0.335746\n",
      "Train Epoch: 8 Loss: 0.333048\n",
      "Train Epoch: 8 Loss: 0.330392\n",
      "Train Epoch: 8 Loss: 0.327777\n",
      "Train Epoch: 8 Loss: 0.325202\n",
      "Train Epoch: 8 Loss: 0.322666\n",
      "Train Epoch: 8 Loss: 0.320169\n",
      "Train Epoch: 8 Loss: 0.317709\n",
      "Train Epoch: 8 Loss: 0.315286\n",
      "Train Epoch: 8 Loss: 0.312899\n",
      "Train Epoch: 8 Loss: 0.310547\n",
      "Train Epoch: 8 Loss: 0.308231\n",
      "Train Epoch: 8 Loss: 0.305948\n",
      "Train Epoch: 8 Loss: 0.303698\n",
      "Train Epoch: 8 Loss: 0.301481\n",
      "Train Epoch: 9 Loss: 0.301261\n",
      "Train Epoch: 9 Loss: 0.299079\n",
      "Train Epoch: 9 Loss: 0.296929\n",
      "Train Epoch: 9 Loss: 0.294809\n",
      "Train Epoch: 9 Loss: 0.292719\n",
      "Train Epoch: 9 Loss: 0.290659\n",
      "Train Epoch: 9 Loss: 0.288628\n",
      "Train Epoch: 9 Loss: 0.286626\n",
      "Train Epoch: 9 Loss: 0.284651\n",
      "Train Epoch: 9 Loss: 0.282703\n",
      "Train Epoch: 9 Loss: 0.280783\n",
      "Train Epoch: 9 Loss: 0.278889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 Loss: 0.277020\n",
      "Train Epoch: 9 Loss: 0.275178\n",
      "Train Epoch: 9 Loss: 0.273359\n",
      "Train Epoch: 9 Loss: 0.271566\n",
      "Train Epoch: 9 Loss: 0.269797\n",
      "Train Epoch: 9 Loss: 0.268051\n",
      "Train Epoch: 9 Loss: 0.266328\n",
      "Train Epoch: 9 Loss: 0.264628\n",
      "Train Epoch: 9 Loss: 0.262951\n",
      "Train Epoch: 9 Loss: 0.261295\n",
      "Train Epoch: 9 Loss: 0.259661\n",
      "Train Epoch: 10 Loss: 0.259499\n",
      "Train Epoch: 10 Loss: 0.257888\n",
      "Train Epoch: 10 Loss: 0.256298\n",
      "Train Epoch: 10 Loss: 0.254729\n",
      "Train Epoch: 10 Loss: 0.253179\n",
      "Train Epoch: 10 Loss: 0.251650\n",
      "Train Epoch: 10 Loss: 0.250140\n",
      "Train Epoch: 10 Loss: 0.248648\n",
      "Train Epoch: 10 Loss: 0.247176\n",
      "Train Epoch: 10 Loss: 0.245722\n",
      "Train Epoch: 10 Loss: 0.244286\n",
      "Train Epoch: 10 Loss: 0.242868\n",
      "Train Epoch: 10 Loss: 0.241468\n",
      "Train Epoch: 10 Loss: 0.240084\n",
      "Train Epoch: 10 Loss: 0.238718\n",
      "Train Epoch: 10 Loss: 0.237368\n",
      "Train Epoch: 10 Loss: 0.236035\n",
      "Train Epoch: 10 Loss: 0.234718\n",
      "Train Epoch: 10 Loss: 0.233417\n",
      "Train Epoch: 10 Loss: 0.232131\n",
      "Train Epoch: 10 Loss: 0.230861\n",
      "Train Epoch: 10 Loss: 0.229606\n",
      "Train Epoch: 10 Loss: 0.228366\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.130653\n",
      "Train Epoch: 1 Loss: 17.793097\n",
      "Train Epoch: 1 Loss: 16.535104\n",
      "Train Epoch: 1 Loss: 15.363009\n",
      "Train Epoch: 1 Loss: 14.278574\n",
      "Train Epoch: 1 Loss: 13.279928\n",
      "Train Epoch: 1 Loss: 12.362903\n",
      "Train Epoch: 1 Loss: 11.522222\n",
      "Train Epoch: 1 Loss: 10.752173\n",
      "Train Epoch: 1 Loss: 10.047032\n",
      "Train Epoch: 1 Loss: 9.401288\n",
      "Train Epoch: 1 Loss: 8.809709\n",
      "Train Epoch: 1 Loss: 8.267425\n",
      "Train Epoch: 1 Loss: 7.769936\n",
      "Train Epoch: 1 Loss: 7.313110\n",
      "Train Epoch: 1 Loss: 6.893173\n",
      "Train Epoch: 1 Loss: 6.506690\n",
      "Train Epoch: 1 Loss: 6.150557\n",
      "Train Epoch: 1 Loss: 5.821958\n",
      "Train Epoch: 1 Loss: 5.518352\n",
      "Train Epoch: 1 Loss: 5.237455\n",
      "Train Epoch: 1 Loss: 4.977202\n",
      "Train Epoch: 1 Loss: 4.735739\n",
      "Train Epoch: 2 Loss: 4.712560\n",
      "Train Epoch: 2 Loss: 4.489841\n",
      "Train Epoch: 2 Loss: 4.282596\n",
      "Train Epoch: 2 Loss: 4.089482\n",
      "Train Epoch: 2 Loss: 3.909292\n",
      "Train Epoch: 2 Loss: 3.740935\n",
      "Train Epoch: 2 Loss: 3.583430\n",
      "Train Epoch: 2 Loss: 3.435885\n",
      "Train Epoch: 2 Loss: 3.297499\n",
      "Train Epoch: 2 Loss: 3.167542\n",
      "Train Epoch: 2 Loss: 3.045357\n",
      "Train Epoch: 2 Loss: 2.930343\n",
      "Train Epoch: 2 Loss: 2.821957\n",
      "Train Epoch: 2 Loss: 2.719705\n",
      "Train Epoch: 2 Loss: 2.623135\n",
      "Train Epoch: 2 Loss: 2.531837\n",
      "Train Epoch: 2 Loss: 2.445434\n",
      "Train Epoch: 2 Loss: 2.363583\n",
      "Train Epoch: 2 Loss: 2.285973\n",
      "Train Epoch: 2 Loss: 2.212310\n",
      "Train Epoch: 2 Loss: 2.142335\n",
      "Train Epoch: 2 Loss: 2.075803\n",
      "Train Epoch: 2 Loss: 2.012490\n",
      "Train Epoch: 3 Loss: 2.006328\n",
      "Train Epoch: 3 Loss: 1.946320\n",
      "Train Epoch: 3 Loss: 1.889117\n",
      "Train Epoch: 3 Loss: 1.834547\n",
      "Train Epoch: 3 Loss: 1.782448\n",
      "Train Epoch: 3 Loss: 1.732674\n",
      "Train Epoch: 3 Loss: 1.685083\n",
      "Train Epoch: 3 Loss: 1.639550\n",
      "Train Epoch: 3 Loss: 1.595956\n",
      "Train Epoch: 3 Loss: 1.554191\n",
      "Train Epoch: 3 Loss: 1.514153\n",
      "Train Epoch: 3 Loss: 1.475745\n",
      "Train Epoch: 3 Loss: 1.438881\n",
      "Train Epoch: 3 Loss: 1.403475\n",
      "Train Epoch: 3 Loss: 1.369452\n",
      "Train Epoch: 3 Loss: 1.336739\n",
      "Train Epoch: 3 Loss: 1.305268\n",
      "Train Epoch: 3 Loss: 1.274976\n",
      "Train Epoch: 3 Loss: 1.245803\n",
      "Train Epoch: 3 Loss: 1.217695\n",
      "Train Epoch: 3 Loss: 1.190598\n",
      "Train Epoch: 3 Loss: 1.164465\n",
      "Train Epoch: 3 Loss: 1.139247\n",
      "Train Epoch: 4 Loss: 1.136775\n",
      "Train Epoch: 4 Loss: 1.112516\n",
      "Train Epoch: 4 Loss: 1.089087\n",
      "Train Epoch: 4 Loss: 1.066448\n",
      "Train Epoch: 4 Loss: 1.044564\n",
      "Train Epoch: 4 Loss: 1.023401\n",
      "Train Epoch: 4 Loss: 1.002927\n",
      "Train Epoch: 4 Loss: 0.983111\n",
      "Train Epoch: 4 Loss: 0.963925\n",
      "Train Epoch: 4 Loss: 0.945341\n",
      "Train Epoch: 4 Loss: 0.927336\n",
      "Train Epoch: 4 Loss: 0.909883\n",
      "Train Epoch: 4 Loss: 0.892960\n",
      "Train Epoch: 4 Loss: 0.876545\n",
      "Train Epoch: 4 Loss: 0.860618\n",
      "Train Epoch: 4 Loss: 0.845160\n",
      "Train Epoch: 4 Loss: 0.830150\n",
      "Train Epoch: 4 Loss: 0.815573\n",
      "Train Epoch: 4 Loss: 0.801410\n",
      "Train Epoch: 4 Loss: 0.787646\n",
      "Train Epoch: 4 Loss: 0.774266\n",
      "Train Epoch: 4 Loss: 0.761255\n",
      "Train Epoch: 4 Loss: 0.748599\n",
      "Train Epoch: 5 Loss: 0.747353\n",
      "Train Epoch: 5 Loss: 0.735073\n",
      "Train Epoch: 5 Loss: 0.723122\n",
      "Train Epoch: 5 Loss: 0.711487\n",
      "Train Epoch: 5 Loss: 0.700157\n",
      "Train Epoch: 5 Loss: 0.689122\n",
      "Train Epoch: 5 Loss: 0.678371\n",
      "Train Epoch: 5 Loss: 0.667894\n",
      "Train Epoch: 5 Loss: 0.657681\n",
      "Train Epoch: 5 Loss: 0.647724\n",
      "Train Epoch: 5 Loss: 0.638014\n",
      "Train Epoch: 5 Loss: 0.628542\n",
      "Train Epoch: 5 Loss: 0.619301\n",
      "Train Epoch: 5 Loss: 0.610282\n",
      "Train Epoch: 5 Loss: 0.601480\n",
      "Train Epoch: 5 Loss: 0.592886\n",
      "Train Epoch: 5 Loss: 0.584494\n",
      "Train Epoch: 5 Loss: 0.576298\n",
      "Train Epoch: 5 Loss: 0.568290\n",
      "Train Epoch: 5 Loss: 0.560466\n",
      "Train Epoch: 5 Loss: 0.552820\n",
      "Train Epoch: 5 Loss: 0.545346\n",
      "Train Epoch: 5 Loss: 0.538040\n",
      "Train Epoch: 6 Loss: 0.537318\n",
      "Train Epoch: 6 Loss: 0.530188\n",
      "Train Epoch: 6 Loss: 0.523216\n",
      "Train Epoch: 6 Loss: 0.516395\n",
      "Train Epoch: 6 Loss: 0.509721\n",
      "Train Epoch: 6 Loss: 0.503191\n",
      "Train Epoch: 6 Loss: 0.496799\n",
      "Train Epoch: 6 Loss: 0.490542\n",
      "Train Epoch: 6 Loss: 0.484417\n",
      "Train Epoch: 6 Loss: 0.478418\n",
      "Train Epoch: 6 Loss: 0.472543\n",
      "Train Epoch: 6 Loss: 0.466789\n",
      "Train Epoch: 6 Loss: 0.461151\n",
      "Train Epoch: 6 Loss: 0.455627\n",
      "Train Epoch: 6 Loss: 0.450214\n",
      "Train Epoch: 6 Loss: 0.444908\n",
      "Train Epoch: 6 Loss: 0.439706\n",
      "Train Epoch: 6 Loss: 0.434607\n",
      "Train Epoch: 6 Loss: 0.429606\n",
      "Train Epoch: 6 Loss: 0.424702\n",
      "Train Epoch: 6 Loss: 0.419893\n",
      "Train Epoch: 6 Loss: 0.415174\n",
      "Train Epoch: 6 Loss: 0.410545\n",
      "Train Epoch: 7 Loss: 0.410087\n",
      "Train Epoch: 7 Loss: 0.405553\n",
      "Train Epoch: 7 Loss: 0.401104\n",
      "Train Epoch: 7 Loss: 0.396737\n",
      "Train Epoch: 7 Loss: 0.392451\n",
      "Train Epoch: 7 Loss: 0.388242\n",
      "Train Epoch: 7 Loss: 0.384110\n",
      "Train Epoch: 7 Loss: 0.380052\n",
      "Train Epoch: 7 Loss: 0.376067\n",
      "Train Epoch: 7 Loss: 0.372153\n",
      "Train Epoch: 7 Loss: 0.368308\n",
      "Train Epoch: 7 Loss: 0.364530\n",
      "Train Epoch: 7 Loss: 0.360819\n",
      "Train Epoch: 7 Loss: 0.357171\n",
      "Train Epoch: 7 Loss: 0.353587\n",
      "Train Epoch: 7 Loss: 0.350064\n",
      "Train Epoch: 7 Loss: 0.346601\n",
      "Train Epoch: 7 Loss: 0.343196\n",
      "Train Epoch: 7 Loss: 0.339848\n",
      "Train Epoch: 7 Loss: 0.336557\n",
      "Train Epoch: 7 Loss: 0.333320\n",
      "Train Epoch: 7 Loss: 0.330136\n",
      "Train Epoch: 7 Loss: 0.327005\n",
      "Train Epoch: 8 Loss: 0.326695\n",
      "Train Epoch: 8 Loss: 0.323619\n",
      "Train Epoch: 8 Loss: 0.320594\n",
      "Train Epoch: 8 Loss: 0.317617\n",
      "Train Epoch: 8 Loss: 0.314688\n",
      "Train Epoch: 8 Loss: 0.311806\n",
      "Train Epoch: 8 Loss: 0.308969\n",
      "Train Epoch: 8 Loss: 0.306177\n",
      "Train Epoch: 8 Loss: 0.303428\n",
      "Train Epoch: 8 Loss: 0.300723\n",
      "Train Epoch: 8 Loss: 0.298059\n",
      "Train Epoch: 8 Loss: 0.295436\n",
      "Train Epoch: 8 Loss: 0.292853\n",
      "Train Epoch: 8 Loss: 0.290310\n",
      "Train Epoch: 8 Loss: 0.287805\n",
      "Train Epoch: 8 Loss: 0.285338\n",
      "Train Epoch: 8 Loss: 0.282908\n",
      "Train Epoch: 8 Loss: 0.280514\n",
      "Train Epoch: 8 Loss: 0.278156\n",
      "Train Epoch: 8 Loss: 0.275832\n",
      "Train Epoch: 8 Loss: 0.273542\n",
      "Train Epoch: 8 Loss: 0.271286\n",
      "Train Epoch: 8 Loss: 0.269062\n",
      "Train Epoch: 9 Loss: 0.268842\n",
      "Train Epoch: 9 Loss: 0.266653\n",
      "Train Epoch: 9 Loss: 0.264497\n",
      "Train Epoch: 9 Loss: 0.262371\n",
      "Train Epoch: 9 Loss: 0.260275\n",
      "Train Epoch: 9 Loss: 0.258209\n",
      "Train Epoch: 9 Loss: 0.256171\n",
      "Train Epoch: 9 Loss: 0.254163\n",
      "Train Epoch: 9 Loss: 0.252182\n",
      "Train Epoch: 9 Loss: 0.250229\n",
      "Train Epoch: 9 Loss: 0.248303\n",
      "Train Epoch: 9 Loss: 0.246403\n",
      "Train Epoch: 9 Loss: 0.244529\n",
      "Train Epoch: 9 Loss: 0.242681\n",
      "Train Epoch: 9 Loss: 0.240857\n",
      "Train Epoch: 9 Loss: 0.239059\n",
      "Train Epoch: 9 Loss: 0.237284\n",
      "Train Epoch: 9 Loss: 0.235533\n",
      "Train Epoch: 9 Loss: 0.233805\n",
      "Train Epoch: 9 Loss: 0.232100\n",
      "Train Epoch: 9 Loss: 0.230418\n",
      "Train Epoch: 9 Loss: 0.228757\n",
      "Train Epoch: 9 Loss: 0.227118\n",
      "Train Epoch: 10 Loss: 0.226956\n",
      "Train Epoch: 10 Loss: 0.225340\n",
      "Train Epoch: 10 Loss: 0.223746\n",
      "Train Epoch: 10 Loss: 0.222171\n",
      "Train Epoch: 10 Loss: 0.220617\n",
      "Train Epoch: 10 Loss: 0.219083\n",
      "Train Epoch: 10 Loss: 0.217569\n",
      "Train Epoch: 10 Loss: 0.216073\n",
      "Train Epoch: 10 Loss: 0.214596\n",
      "Train Epoch: 10 Loss: 0.213138\n",
      "Train Epoch: 10 Loss: 0.211698\n",
      "Train Epoch: 10 Loss: 0.210276\n",
      "Train Epoch: 10 Loss: 0.208871\n",
      "Train Epoch: 10 Loss: 0.207483\n",
      "Train Epoch: 10 Loss: 0.206113\n",
      "Train Epoch: 10 Loss: 0.204760\n",
      "Train Epoch: 10 Loss: 0.203422\n",
      "Train Epoch: 10 Loss: 0.202101\n",
      "Train Epoch: 10 Loss: 0.200796\n",
      "Train Epoch: 10 Loss: 0.199507\n",
      "Train Epoch: 10 Loss: 0.198233\n",
      "Train Epoch: 10 Loss: 0.196974\n",
      "Train Epoch: 10 Loss: 0.195730\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.125551\n",
      "Train Epoch: 1 Loss: 17.790657\n",
      "Train Epoch: 1 Loss: 16.535331\n",
      "Train Epoch: 1 Loss: 15.365858\n",
      "Train Epoch: 1 Loss: 14.284001\n",
      "Train Epoch: 1 Loss: 13.287844\n",
      "Train Epoch: 1 Loss: 12.373226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Loss: 11.534826\n",
      "Train Epoch: 1 Loss: 10.766935\n",
      "Train Epoch: 1 Loss: 10.063828\n",
      "Train Epoch: 1 Loss: 9.419981\n",
      "Train Epoch: 1 Loss: 8.830169\n",
      "Train Epoch: 1 Loss: 8.289532\n",
      "Train Epoch: 1 Loss: 7.793573\n",
      "Train Epoch: 1 Loss: 7.338165\n",
      "Train Epoch: 1 Loss: 6.919543\n",
      "Train Epoch: 1 Loss: 6.534284\n",
      "Train Epoch: 1 Loss: 6.179284\n",
      "Train Epoch: 1 Loss: 5.851735\n",
      "Train Epoch: 1 Loss: 5.549109\n",
      "Train Epoch: 1 Loss: 5.269118\n",
      "Train Epoch: 1 Loss: 5.009710\n",
      "Train Epoch: 1 Loss: 4.769032\n",
      "Train Epoch: 2 Loss: 4.745931\n",
      "Train Epoch: 2 Loss: 4.523941\n",
      "Train Epoch: 2 Loss: 4.317374\n",
      "Train Epoch: 2 Loss: 4.124894\n",
      "Train Epoch: 2 Loss: 3.945297\n",
      "Train Epoch: 2 Loss: 3.777498\n",
      "Train Epoch: 2 Loss: 3.620512\n",
      "Train Epoch: 2 Loss: 3.473458\n",
      "Train Epoch: 2 Loss: 3.335530\n",
      "Train Epoch: 2 Loss: 3.206006\n",
      "Train Epoch: 2 Loss: 3.084227\n",
      "Train Epoch: 2 Loss: 2.969597\n",
      "Train Epoch: 2 Loss: 2.861573\n",
      "Train Epoch: 2 Loss: 2.759663\n",
      "Train Epoch: 2 Loss: 2.663416\n",
      "Train Epoch: 2 Loss: 2.572424\n",
      "Train Epoch: 2 Loss: 2.486311\n",
      "Train Epoch: 2 Loss: 2.404735\n",
      "Train Epoch: 2 Loss: 2.327385\n",
      "Train Epoch: 2 Loss: 2.253970\n",
      "Train Epoch: 2 Loss: 2.184231\n",
      "Train Epoch: 2 Loss: 2.117922\n",
      "Train Epoch: 2 Loss: 2.054823\n",
      "Train Epoch: 3 Loss: 2.048682\n",
      "Train Epoch: 3 Loss: 1.988876\n",
      "Train Epoch: 3 Loss: 1.931868\n",
      "Train Epoch: 3 Loss: 1.877482\n",
      "Train Epoch: 3 Loss: 1.825560\n",
      "Train Epoch: 3 Loss: 1.775952\n",
      "Train Epoch: 3 Loss: 1.728524\n",
      "Train Epoch: 3 Loss: 1.683145\n",
      "Train Epoch: 3 Loss: 1.639699\n",
      "Train Epoch: 3 Loss: 1.598076\n",
      "Train Epoch: 3 Loss: 1.558174\n",
      "Train Epoch: 3 Loss: 1.519897\n",
      "Train Epoch: 3 Loss: 1.483158\n",
      "Train Epoch: 3 Loss: 1.447873\n",
      "Train Epoch: 3 Loss: 1.413965\n",
      "Train Epoch: 3 Loss: 1.381364\n",
      "Train Epoch: 3 Loss: 1.350000\n",
      "Train Epoch: 3 Loss: 1.319811\n",
      "Train Epoch: 3 Loss: 1.290738\n",
      "Train Epoch: 3 Loss: 1.262726\n",
      "Train Epoch: 3 Loss: 1.235722\n",
      "Train Epoch: 3 Loss: 1.209677\n",
      "Train Epoch: 3 Loss: 1.184547\n",
      "Train Epoch: 4 Loss: 1.182082\n",
      "Train Epoch: 4 Loss: 1.157907\n",
      "Train Epoch: 4 Loss: 1.134557\n",
      "Train Epoch: 4 Loss: 1.111996\n",
      "Train Epoch: 4 Loss: 1.090188\n",
      "Train Epoch: 4 Loss: 1.069097\n",
      "Train Epoch: 4 Loss: 1.048692\n",
      "Train Epoch: 4 Loss: 1.028945\n",
      "Train Epoch: 4 Loss: 1.009824\n",
      "Train Epoch: 4 Loss: 0.991305\n",
      "Train Epoch: 4 Loss: 0.973361\n",
      "Train Epoch: 4 Loss: 0.955968\n",
      "Train Epoch: 4 Loss: 0.939103\n",
      "Train Epoch: 4 Loss: 0.922746\n",
      "Train Epoch: 4 Loss: 0.906873\n",
      "Train Epoch: 4 Loss: 0.891467\n",
      "Train Epoch: 4 Loss: 0.876510\n",
      "Train Epoch: 4 Loss: 0.861982\n",
      "Train Epoch: 4 Loss: 0.847868\n",
      "Train Epoch: 4 Loss: 0.834152\n",
      "Train Epoch: 4 Loss: 0.820818\n",
      "Train Epoch: 4 Loss: 0.807852\n",
      "Train Epoch: 4 Loss: 0.795240\n",
      "Train Epoch: 5 Loss: 0.793998\n",
      "Train Epoch: 5 Loss: 0.781760\n",
      "Train Epoch: 5 Loss: 0.769850\n",
      "Train Epoch: 5 Loss: 0.758256\n",
      "Train Epoch: 5 Loss: 0.746965\n",
      "Train Epoch: 5 Loss: 0.735968\n",
      "Train Epoch: 5 Loss: 0.725254\n",
      "Train Epoch: 5 Loss: 0.714813\n",
      "Train Epoch: 5 Loss: 0.704636\n",
      "Train Epoch: 5 Loss: 0.694713\n",
      "Train Epoch: 5 Loss: 0.685037\n",
      "Train Epoch: 5 Loss: 0.675598\n",
      "Train Epoch: 5 Loss: 0.666389\n",
      "Train Epoch: 5 Loss: 0.657401\n",
      "Train Epoch: 5 Loss: 0.648630\n",
      "Train Epoch: 5 Loss: 0.640065\n",
      "Train Epoch: 5 Loss: 0.631702\n",
      "Train Epoch: 5 Loss: 0.623534\n",
      "Train Epoch: 5 Loss: 0.615555\n",
      "Train Epoch: 5 Loss: 0.607758\n",
      "Train Epoch: 5 Loss: 0.600139\n",
      "Train Epoch: 5 Loss: 0.592691\n",
      "Train Epoch: 5 Loss: 0.585409\n",
      "Train Epoch: 6 Loss: 0.584690\n",
      "Train Epoch: 6 Loss: 0.577586\n",
      "Train Epoch: 6 Loss: 0.570637\n",
      "Train Epoch: 6 Loss: 0.563840\n",
      "Train Epoch: 6 Loss: 0.557190\n",
      "Train Epoch: 6 Loss: 0.550682\n",
      "Train Epoch: 6 Loss: 0.544313\n",
      "Train Epoch: 6 Loss: 0.538078\n",
      "Train Epoch: 6 Loss: 0.531973\n",
      "Train Epoch: 6 Loss: 0.525996\n",
      "Train Epoch: 6 Loss: 0.520141\n",
      "Train Epoch: 6 Loss: 0.514407\n",
      "Train Epoch: 6 Loss: 0.508789\n",
      "Train Epoch: 6 Loss: 0.503284\n",
      "Train Epoch: 6 Loss: 0.497889\n",
      "Train Epoch: 6 Loss: 0.492602\n",
      "Train Epoch: 6 Loss: 0.487419\n",
      "Train Epoch: 6 Loss: 0.482337\n",
      "Train Epoch: 6 Loss: 0.477354\n",
      "Train Epoch: 6 Loss: 0.472468\n",
      "Train Epoch: 6 Loss: 0.467674\n",
      "Train Epoch: 6 Loss: 0.462973\n",
      "Train Epoch: 6 Loss: 0.458360\n",
      "Train Epoch: 7 Loss: 0.457903\n",
      "Train Epoch: 7 Loss: 0.453385\n",
      "Train Epoch: 7 Loss: 0.448952\n",
      "Train Epoch: 7 Loss: 0.444600\n",
      "Train Epoch: 7 Loss: 0.440328\n",
      "Train Epoch: 7 Loss: 0.436135\n",
      "Train Epoch: 7 Loss: 0.432017\n",
      "Train Epoch: 7 Loss: 0.427974\n",
      "Train Epoch: 7 Loss: 0.424003\n",
      "Train Epoch: 7 Loss: 0.420102\n",
      "Train Epoch: 7 Loss: 0.416271\n",
      "Train Epoch: 7 Loss: 0.412506\n",
      "Train Epoch: 7 Loss: 0.408808\n",
      "Train Epoch: 7 Loss: 0.405173\n",
      "Train Epoch: 7 Loss: 0.401601\n",
      "Train Epoch: 7 Loss: 0.398091\n",
      "Train Epoch: 7 Loss: 0.394640\n",
      "Train Epoch: 7 Loss: 0.391247\n",
      "Train Epoch: 7 Loss: 0.387911\n",
      "Train Epoch: 7 Loss: 0.384631\n",
      "Train Epoch: 7 Loss: 0.381405\n",
      "Train Epoch: 7 Loss: 0.378233\n",
      "Train Epoch: 7 Loss: 0.375113\n",
      "Train Epoch: 8 Loss: 0.374803\n",
      "Train Epoch: 8 Loss: 0.371739\n",
      "Train Epoch: 8 Loss: 0.368724\n",
      "Train Epoch: 8 Loss: 0.365758\n",
      "Train Epoch: 8 Loss: 0.362839\n",
      "Train Epoch: 8 Loss: 0.359967\n",
      "Train Epoch: 8 Loss: 0.357140\n",
      "Train Epoch: 8 Loss: 0.354358\n",
      "Train Epoch: 8 Loss: 0.351619\n",
      "Train Epoch: 8 Loss: 0.348923\n",
      "Train Epoch: 8 Loss: 0.346269\n",
      "Train Epoch: 8 Loss: 0.343655\n",
      "Train Epoch: 8 Loss: 0.341082\n",
      "Train Epoch: 8 Loss: 0.338548\n",
      "Train Epoch: 8 Loss: 0.336052\n",
      "Train Epoch: 8 Loss: 0.333593\n",
      "Train Epoch: 8 Loss: 0.331172\n",
      "Train Epoch: 8 Loss: 0.328786\n",
      "Train Epoch: 8 Loss: 0.326436\n",
      "Train Epoch: 8 Loss: 0.324120\n",
      "Train Epoch: 8 Loss: 0.321839\n",
      "Train Epoch: 8 Loss: 0.319591\n",
      "Train Epoch: 8 Loss: 0.317375\n",
      "Train Epoch: 9 Loss: 0.317155\n",
      "Train Epoch: 9 Loss: 0.314975\n",
      "Train Epoch: 9 Loss: 0.312825\n",
      "Train Epoch: 9 Loss: 0.310707\n",
      "Train Epoch: 9 Loss: 0.308619\n",
      "Train Epoch: 9 Loss: 0.306560\n",
      "Train Epoch: 9 Loss: 0.304530\n",
      "Train Epoch: 9 Loss: 0.302528\n",
      "Train Epoch: 9 Loss: 0.300555\n",
      "Train Epoch: 9 Loss: 0.298608\n",
      "Train Epoch: 9 Loss: 0.296689\n",
      "Train Epoch: 9 Loss: 0.294796\n",
      "Train Epoch: 9 Loss: 0.292929\n",
      "Train Epoch: 9 Loss: 0.291087\n",
      "Train Epoch: 9 Loss: 0.289270\n",
      "Train Epoch: 9 Loss: 0.287478\n",
      "Train Epoch: 9 Loss: 0.285709\n",
      "Train Epoch: 9 Loss: 0.283965\n",
      "Train Epoch: 9 Loss: 0.282243\n",
      "Train Epoch: 9 Loss: 0.280544\n",
      "Train Epoch: 9 Loss: 0.278867\n",
      "Train Epoch: 9 Loss: 0.277213\n",
      "Train Epoch: 9 Loss: 0.275580\n",
      "Train Epoch: 10 Loss: 0.275418\n",
      "Train Epoch: 10 Loss: 0.273808\n",
      "Train Epoch: 10 Loss: 0.272219\n",
      "Train Epoch: 10 Loss: 0.270651\n",
      "Train Epoch: 10 Loss: 0.269102\n",
      "Train Epoch: 10 Loss: 0.267573\n",
      "Train Epoch: 10 Loss: 0.266064\n",
      "Train Epoch: 10 Loss: 0.264574\n",
      "Train Epoch: 10 Loss: 0.263102\n",
      "Train Epoch: 10 Loss: 0.261649\n",
      "Train Epoch: 10 Loss: 0.260214\n",
      "Train Epoch: 10 Loss: 0.258797\n",
      "Train Epoch: 10 Loss: 0.257398\n",
      "Train Epoch: 10 Loss: 0.256015\n",
      "Train Epoch: 10 Loss: 0.254650\n",
      "Train Epoch: 10 Loss: 0.253301\n",
      "Train Epoch: 10 Loss: 0.251968\n",
      "Train Epoch: 10 Loss: 0.250652\n",
      "Train Epoch: 10 Loss: 0.249352\n",
      "Train Epoch: 10 Loss: 0.248067\n",
      "Train Epoch: 10 Loss: 0.246797\n",
      "Train Epoch: 10 Loss: 0.245543\n",
      "Train Epoch: 10 Loss: 0.244304\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.116134\n",
      "Train Epoch: 1 Loss: 17.783412\n",
      "Train Epoch: 1 Loss: 16.530109\n",
      "Train Epoch: 1 Loss: 15.362468\n",
      "Train Epoch: 1 Loss: 14.282256\n",
      "Train Epoch: 1 Loss: 13.287575\n",
      "Train Epoch: 1 Loss: 12.374274\n",
      "Train Epoch: 1 Loss: 11.537075\n",
      "Train Epoch: 1 Loss: 10.770277\n",
      "Train Epoch: 1 Loss: 10.068168\n",
      "Train Epoch: 1 Loss: 9.425236\n",
      "Train Epoch: 1 Loss: 8.836273\n",
      "Train Epoch: 1 Loss: 8.296418\n",
      "Train Epoch: 1 Loss: 7.801179\n",
      "Train Epoch: 1 Loss: 7.346441\n",
      "Train Epoch: 1 Loss: 6.928435\n",
      "Train Epoch: 1 Loss: 6.543743\n",
      "Train Epoch: 1 Loss: 6.189271\n",
      "Train Epoch: 1 Loss: 5.862212\n",
      "Train Epoch: 1 Loss: 5.560035\n",
      "Train Epoch: 1 Loss: 5.280465\n",
      "Train Epoch: 1 Loss: 5.021445\n",
      "Train Epoch: 1 Loss: 4.781131\n",
      "Train Epoch: 2 Loss: 4.758062\n",
      "Train Epoch: 2 Loss: 4.536406\n",
      "Train Epoch: 2 Loss: 4.330149\n",
      "Train Epoch: 2 Loss: 4.137959\n",
      "Train Epoch: 2 Loss: 3.958633\n",
      "Train Epoch: 2 Loss: 3.791085\n",
      "Train Epoch: 2 Loss: 3.634337\n",
      "Train Epoch: 2 Loss: 3.487504\n",
      "Train Epoch: 2 Loss: 3.349782\n",
      "Train Epoch: 2 Loss: 3.220452\n",
      "Train Epoch: 2 Loss: 3.098857\n",
      "Train Epoch: 2 Loss: 2.984400\n",
      "Train Epoch: 2 Loss: 2.876538\n",
      "Train Epoch: 2 Loss: 2.774780\n",
      "Train Epoch: 2 Loss: 2.678678\n",
      "Train Epoch: 2 Loss: 2.587822\n",
      "Train Epoch: 2 Loss: 2.501838\n",
      "Train Epoch: 2 Loss: 2.420385\n",
      "Train Epoch: 2 Loss: 2.343149\n",
      "Train Epoch: 2 Loss: 2.269846\n",
      "Train Epoch: 2 Loss: 2.200211\n",
      "Train Epoch: 2 Loss: 2.134002\n",
      "Train Epoch: 2 Loss: 2.070996\n",
      "Train Epoch: 3 Loss: 2.064864\n",
      "Train Epoch: 3 Loss: 2.005148\n",
      "Train Epoch: 3 Loss: 1.948223\n",
      "Train Epoch: 3 Loss: 1.893919\n",
      "Train Epoch: 3 Loss: 1.842075\n",
      "Train Epoch: 3 Loss: 1.792541\n",
      "Train Epoch: 3 Loss: 1.745182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 Loss: 1.699871\n",
      "Train Epoch: 3 Loss: 1.656490\n",
      "Train Epoch: 3 Loss: 1.614929\n",
      "Train Epoch: 3 Loss: 1.575086\n",
      "Train Epoch: 3 Loss: 1.536866\n",
      "Train Epoch: 3 Loss: 1.500181\n",
      "Train Epoch: 3 Loss: 1.464948\n",
      "Train Epoch: 3 Loss: 1.431091\n",
      "Train Epoch: 3 Loss: 1.398538\n",
      "Train Epoch: 3 Loss: 1.367220\n",
      "Train Epoch: 3 Loss: 1.337076\n",
      "Train Epoch: 3 Loss: 1.308046\n",
      "Train Epoch: 3 Loss: 1.280074\n",
      "Train Epoch: 3 Loss: 1.253110\n",
      "Train Epoch: 3 Loss: 1.227105\n",
      "Train Epoch: 3 Loss: 1.202011\n",
      "Train Epoch: 4 Loss: 1.199550\n",
      "Train Epoch: 4 Loss: 1.175410\n",
      "Train Epoch: 4 Loss: 1.152096\n",
      "Train Epoch: 4 Loss: 1.129568\n",
      "Train Epoch: 4 Loss: 1.107791\n",
      "Train Epoch: 4 Loss: 1.086731\n",
      "Train Epoch: 4 Loss: 1.066357\n",
      "Train Epoch: 4 Loss: 1.046638\n",
      "Train Epoch: 4 Loss: 1.027546\n",
      "Train Epoch: 4 Loss: 1.009054\n",
      "Train Epoch: 4 Loss: 0.991136\n",
      "Train Epoch: 4 Loss: 0.973769\n",
      "Train Epoch: 4 Loss: 0.956929\n",
      "Train Epoch: 4 Loss: 0.940595\n",
      "Train Epoch: 4 Loss: 0.924745\n",
      "Train Epoch: 4 Loss: 0.909363\n",
      "Train Epoch: 4 Loss: 0.894427\n",
      "Train Epoch: 4 Loss: 0.879920\n",
      "Train Epoch: 4 Loss: 0.865827\n",
      "Train Epoch: 4 Loss: 0.852131\n",
      "Train Epoch: 4 Loss: 0.838816\n",
      "Train Epoch: 4 Loss: 0.825869\n",
      "Train Epoch: 4 Loss: 0.813276\n",
      "Train Epoch: 5 Loss: 0.812035\n",
      "Train Epoch: 5 Loss: 0.799816\n",
      "Train Epoch: 5 Loss: 0.787923\n",
      "Train Epoch: 5 Loss: 0.776346\n",
      "Train Epoch: 5 Loss: 0.765072\n",
      "Train Epoch: 5 Loss: 0.754091\n",
      "Train Epoch: 5 Loss: 0.743392\n",
      "Train Epoch: 5 Loss: 0.732966\n",
      "Train Epoch: 5 Loss: 0.722804\n",
      "Train Epoch: 5 Loss: 0.712896\n",
      "Train Epoch: 5 Loss: 0.703233\n",
      "Train Epoch: 5 Loss: 0.693808\n",
      "Train Epoch: 5 Loss: 0.684612\n",
      "Train Epoch: 5 Loss: 0.675638\n",
      "Train Epoch: 5 Loss: 0.666879\n",
      "Train Epoch: 5 Loss: 0.658327\n",
      "Train Epoch: 5 Loss: 0.649977\n",
      "Train Epoch: 5 Loss: 0.641821\n",
      "Train Epoch: 5 Loss: 0.633853\n",
      "Train Epoch: 5 Loss: 0.626068\n",
      "Train Epoch: 5 Loss: 0.618459\n",
      "Train Epoch: 5 Loss: 0.611022\n",
      "Train Epoch: 5 Loss: 0.603751\n",
      "Train Epoch: 6 Loss: 0.603033\n",
      "Train Epoch: 6 Loss: 0.595939\n",
      "Train Epoch: 6 Loss: 0.589000\n",
      "Train Epoch: 6 Loss: 0.582213\n",
      "Train Epoch: 6 Loss: 0.575572\n",
      "Train Epoch: 6 Loss: 0.569074\n",
      "Train Epoch: 6 Loss: 0.562714\n",
      "Train Epoch: 6 Loss: 0.556488\n",
      "Train Epoch: 6 Loss: 0.550393\n",
      "Train Epoch: 6 Loss: 0.544424\n",
      "Train Epoch: 6 Loss: 0.538578\n",
      "Train Epoch: 6 Loss: 0.532852\n",
      "Train Epoch: 6 Loss: 0.527242\n",
      "Train Epoch: 6 Loss: 0.521745\n",
      "Train Epoch: 6 Loss: 0.516358\n",
      "Train Epoch: 6 Loss: 0.511078\n",
      "Train Epoch: 6 Loss: 0.505903\n",
      "Train Epoch: 6 Loss: 0.500828\n",
      "Train Epoch: 6 Loss: 0.495853\n",
      "Train Epoch: 6 Loss: 0.490973\n",
      "Train Epoch: 6 Loss: 0.486187\n",
      "Train Epoch: 6 Loss: 0.481492\n",
      "Train Epoch: 6 Loss: 0.476886\n",
      "Train Epoch: 7 Loss: 0.476430\n",
      "Train Epoch: 7 Loss: 0.471919\n",
      "Train Epoch: 7 Loss: 0.467491\n",
      "Train Epoch: 7 Loss: 0.463146\n",
      "Train Epoch: 7 Loss: 0.458881\n",
      "Train Epoch: 7 Loss: 0.454693\n",
      "Train Epoch: 7 Loss: 0.450581\n",
      "Train Epoch: 7 Loss: 0.446544\n",
      "Train Epoch: 7 Loss: 0.442578\n",
      "Train Epoch: 7 Loss: 0.438684\n",
      "Train Epoch: 7 Loss: 0.434857\n",
      "Train Epoch: 7 Loss: 0.431099\n",
      "Train Epoch: 7 Loss: 0.427406\n",
      "Train Epoch: 7 Loss: 0.423776\n",
      "Train Epoch: 7 Loss: 0.420209\n",
      "Train Epoch: 7 Loss: 0.416704\n",
      "Train Epoch: 7 Loss: 0.413258\n",
      "Train Epoch: 7 Loss: 0.409870\n",
      "Train Epoch: 7 Loss: 0.406539\n",
      "Train Epoch: 7 Loss: 0.403264\n",
      "Train Epoch: 7 Loss: 0.400043\n",
      "Train Epoch: 7 Loss: 0.396875\n",
      "Train Epoch: 7 Loss: 0.393759\n",
      "Train Epoch: 8 Loss: 0.393450\n",
      "Train Epoch: 8 Loss: 0.390390\n",
      "Train Epoch: 8 Loss: 0.387380\n",
      "Train Epoch: 8 Loss: 0.384418\n",
      "Train Epoch: 8 Loss: 0.381504\n",
      "Train Epoch: 8 Loss: 0.378635\n",
      "Train Epoch: 8 Loss: 0.375813\n",
      "Train Epoch: 8 Loss: 0.373035\n",
      "Train Epoch: 8 Loss: 0.370300\n",
      "Train Epoch: 8 Loss: 0.367608\n",
      "Train Epoch: 8 Loss: 0.364957\n",
      "Train Epoch: 8 Loss: 0.362347\n",
      "Train Epoch: 8 Loss: 0.359777\n",
      "Train Epoch: 8 Loss: 0.357247\n",
      "Train Epoch: 8 Loss: 0.354754\n",
      "Train Epoch: 8 Loss: 0.352300\n",
      "Train Epoch: 8 Loss: 0.349881\n",
      "Train Epoch: 8 Loss: 0.347499\n",
      "Train Epoch: 8 Loss: 0.345153\n",
      "Train Epoch: 8 Loss: 0.342840\n",
      "Train Epoch: 8 Loss: 0.340562\n",
      "Train Epoch: 8 Loss: 0.338317\n",
      "Train Epoch: 8 Loss: 0.336105\n",
      "Train Epoch: 9 Loss: 0.335885\n",
      "Train Epoch: 9 Loss: 0.333708\n",
      "Train Epoch: 9 Loss: 0.331562\n",
      "Train Epoch: 9 Loss: 0.329446\n",
      "Train Epoch: 9 Loss: 0.327361\n",
      "Train Epoch: 9 Loss: 0.325305\n",
      "Train Epoch: 9 Loss: 0.323278\n",
      "Train Epoch: 9 Loss: 0.321279\n",
      "Train Epoch: 9 Loss: 0.319309\n",
      "Train Epoch: 9 Loss: 0.317365\n",
      "Train Epoch: 9 Loss: 0.315449\n",
      "Train Epoch: 9 Loss: 0.313558\n",
      "Train Epoch: 9 Loss: 0.311694\n",
      "Train Epoch: 9 Loss: 0.309855\n",
      "Train Epoch: 9 Loss: 0.308040\n",
      "Train Epoch: 9 Loss: 0.306251\n",
      "Train Epoch: 9 Loss: 0.304485\n",
      "Train Epoch: 9 Loss: 0.302742\n",
      "Train Epoch: 9 Loss: 0.301023\n",
      "Train Epoch: 9 Loss: 0.299327\n",
      "Train Epoch: 9 Loss: 0.297653\n",
      "Train Epoch: 9 Loss: 0.296001\n",
      "Train Epoch: 9 Loss: 0.294370\n",
      "Train Epoch: 10 Loss: 0.294208\n",
      "Train Epoch: 10 Loss: 0.292601\n",
      "Train Epoch: 10 Loss: 0.291014\n",
      "Train Epoch: 10 Loss: 0.289448\n",
      "Train Epoch: 10 Loss: 0.287902\n",
      "Train Epoch: 10 Loss: 0.286375\n",
      "Train Epoch: 10 Loss: 0.284868\n",
      "Train Epoch: 10 Loss: 0.283380\n",
      "Train Epoch: 10 Loss: 0.281910\n",
      "Train Epoch: 10 Loss: 0.280460\n",
      "Train Epoch: 10 Loss: 0.279027\n",
      "Train Epoch: 10 Loss: 0.277612\n",
      "Train Epoch: 10 Loss: 0.276214\n",
      "Train Epoch: 10 Loss: 0.274833\n",
      "Train Epoch: 10 Loss: 0.273470\n",
      "Train Epoch: 10 Loss: 0.272123\n",
      "Train Epoch: 10 Loss: 0.270793\n",
      "Train Epoch: 10 Loss: 0.269478\n",
      "Train Epoch: 10 Loss: 0.268180\n",
      "Train Epoch: 10 Loss: 0.266897\n",
      "Train Epoch: 10 Loss: 0.265629\n",
      "Train Epoch: 10 Loss: 0.264376\n",
      "Train Epoch: 10 Loss: 0.263139\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.124503\n",
      "Train Epoch: 1 Loss: 17.788886\n",
      "Train Epoch: 1 Loss: 16.532881\n",
      "Train Epoch: 1 Loss: 15.362792\n",
      "Train Epoch: 1 Loss: 14.280385\n",
      "Train Epoch: 1 Loss: 13.283757\n",
      "Train Epoch: 1 Loss: 12.368731\n",
      "Train Epoch: 1 Loss: 11.530011\n",
      "Train Epoch: 1 Loss: 10.761866\n",
      "Train Epoch: 1 Loss: 10.058570\n",
      "Train Epoch: 1 Loss: 9.414584\n",
      "Train Epoch: 1 Loss: 8.824682\n",
      "Train Epoch: 1 Loss: 8.283988\n",
      "Train Epoch: 1 Loss: 7.788000\n",
      "Train Epoch: 1 Loss: 7.332585\n",
      "Train Epoch: 1 Loss: 6.913967\n",
      "Train Epoch: 1 Loss: 6.528723\n",
      "Train Epoch: 1 Loss: 6.173742\n",
      "Train Epoch: 1 Loss: 5.846219\n",
      "Train Epoch: 1 Loss: 5.543617\n",
      "Train Epoch: 1 Loss: 5.263655\n",
      "Train Epoch: 1 Loss: 5.004274\n",
      "Train Epoch: 1 Loss: 4.763622\n",
      "Train Epoch: 2 Loss: 4.740521\n",
      "Train Epoch: 2 Loss: 4.518556\n",
      "Train Epoch: 2 Loss: 4.312013\n",
      "Train Epoch: 2 Loss: 4.119556\n",
      "Train Epoch: 2 Loss: 3.939979\n",
      "Train Epoch: 2 Loss: 3.772199\n",
      "Train Epoch: 2 Loss: 3.615230\n",
      "Train Epoch: 2 Loss: 3.468193\n",
      "Train Epoch: 2 Loss: 3.330281\n",
      "Train Epoch: 2 Loss: 3.200771\n",
      "Train Epoch: 2 Loss: 3.079006\n",
      "Train Epoch: 2 Loss: 2.964389\n",
      "Train Epoch: 2 Loss: 2.856377\n",
      "Train Epoch: 2 Loss: 2.754478\n",
      "Train Epoch: 2 Loss: 2.658241\n",
      "Train Epoch: 2 Loss: 2.567258\n",
      "Train Epoch: 2 Loss: 2.481154\n",
      "Train Epoch: 2 Loss: 2.399588\n",
      "Train Epoch: 2 Loss: 2.322246\n",
      "Train Epoch: 2 Loss: 2.248840\n",
      "Train Epoch: 2 Loss: 2.179108\n",
      "Train Epoch: 2 Loss: 2.112806\n",
      "Train Epoch: 2 Loss: 2.049714\n",
      "Train Epoch: 3 Loss: 2.043573\n",
      "Train Epoch: 3 Loss: 1.983774\n",
      "Train Epoch: 3 Loss: 1.926771\n",
      "Train Epoch: 3 Loss: 1.872391\n",
      "Train Epoch: 3 Loss: 1.820474\n",
      "Train Epoch: 3 Loss: 1.770872\n",
      "Train Epoch: 3 Loss: 1.723448\n",
      "Train Epoch: 3 Loss: 1.678074\n",
      "Train Epoch: 3 Loss: 1.634632\n",
      "Train Epoch: 3 Loss: 1.593013\n",
      "Train Epoch: 3 Loss: 1.553115\n",
      "Train Epoch: 3 Loss: 1.514843\n",
      "Train Epoch: 3 Loss: 1.478107\n",
      "Train Epoch: 3 Loss: 1.442825\n",
      "Train Epoch: 3 Loss: 1.408922\n",
      "Train Epoch: 3 Loss: 1.376323\n",
      "Train Epoch: 3 Loss: 1.344962\n",
      "Train Epoch: 3 Loss: 1.314777\n",
      "Train Epoch: 3 Loss: 1.285707\n",
      "Train Epoch: 3 Loss: 1.257697\n",
      "Train Epoch: 3 Loss: 1.230695\n",
      "Train Epoch: 3 Loss: 1.204654\n",
      "Train Epoch: 3 Loss: 1.179525\n",
      "Train Epoch: 4 Loss: 1.177061\n",
      "Train Epoch: 4 Loss: 1.152888\n",
      "Train Epoch: 4 Loss: 1.129541\n",
      "Train Epoch: 4 Loss: 1.106982\n",
      "Train Epoch: 4 Loss: 1.085176\n",
      "Train Epoch: 4 Loss: 1.064087\n",
      "Train Epoch: 4 Loss: 1.043685\n",
      "Train Epoch: 4 Loss: 1.023939\n",
      "Train Epoch: 4 Loss: 1.004820\n",
      "Train Epoch: 4 Loss: 0.986303\n",
      "Train Epoch: 4 Loss: 0.968360\n",
      "Train Epoch: 4 Loss: 0.950969\n",
      "Train Epoch: 4 Loss: 0.934106\n",
      "Train Epoch: 4 Loss: 0.917750\n",
      "Train Epoch: 4 Loss: 0.901879\n",
      "Train Epoch: 4 Loss: 0.886475\n",
      "Train Epoch: 4 Loss: 0.871519\n",
      "Train Epoch: 4 Loss: 0.856992\n",
      "Train Epoch: 4 Loss: 0.842880\n",
      "Train Epoch: 4 Loss: 0.829165\n",
      "Train Epoch: 4 Loss: 0.815832\n",
      "Train Epoch: 4 Loss: 0.802867\n",
      "Train Epoch: 4 Loss: 0.790257\n",
      "Train Epoch: 5 Loss: 0.789014\n",
      "Train Epoch: 5 Loss: 0.776778\n",
      "Train Epoch: 5 Loss: 0.764869\n",
      "Train Epoch: 5 Loss: 0.753276\n",
      "Train Epoch: 5 Loss: 0.741986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Loss: 0.730991\n",
      "Train Epoch: 5 Loss: 0.720277\n",
      "Train Epoch: 5 Loss: 0.709837\n",
      "Train Epoch: 5 Loss: 0.699661\n",
      "Train Epoch: 5 Loss: 0.689739\n",
      "Train Epoch: 5 Loss: 0.680063\n",
      "Train Epoch: 5 Loss: 0.670625\n",
      "Train Epoch: 5 Loss: 0.661417\n",
      "Train Epoch: 5 Loss: 0.652431\n",
      "Train Epoch: 5 Loss: 0.643660\n",
      "Train Epoch: 5 Loss: 0.635096\n",
      "Train Epoch: 5 Loss: 0.626734\n",
      "Train Epoch: 5 Loss: 0.618567\n",
      "Train Epoch: 5 Loss: 0.610588\n",
      "Train Epoch: 5 Loss: 0.602792\n",
      "Train Epoch: 5 Loss: 0.595174\n",
      "Train Epoch: 5 Loss: 0.587726\n",
      "Train Epoch: 5 Loss: 0.580445\n",
      "Train Epoch: 6 Loss: 0.579726\n",
      "Train Epoch: 6 Loss: 0.572622\n",
      "Train Epoch: 6 Loss: 0.565674\n",
      "Train Epoch: 6 Loss: 0.558878\n",
      "Train Epoch: 6 Loss: 0.552228\n",
      "Train Epoch: 6 Loss: 0.545721\n",
      "Train Epoch: 6 Loss: 0.539352\n",
      "Train Epoch: 6 Loss: 0.533118\n",
      "Train Epoch: 6 Loss: 0.527014\n",
      "Train Epoch: 6 Loss: 0.521037\n",
      "Train Epoch: 6 Loss: 0.515183\n",
      "Train Epoch: 6 Loss: 0.509449\n",
      "Train Epoch: 6 Loss: 0.503832\n",
      "Train Epoch: 6 Loss: 0.498327\n",
      "Train Epoch: 6 Loss: 0.492933\n",
      "Train Epoch: 6 Loss: 0.487646\n",
      "Train Epoch: 6 Loss: 0.482464\n",
      "Train Epoch: 6 Loss: 0.477382\n",
      "Train Epoch: 6 Loss: 0.472400\n",
      "Train Epoch: 6 Loss: 0.467514\n",
      "Train Epoch: 6 Loss: 0.462721\n",
      "Train Epoch: 6 Loss: 0.458020\n",
      "Train Epoch: 6 Loss: 0.453407\n",
      "Train Epoch: 7 Loss: 0.452951\n",
      "Train Epoch: 7 Loss: 0.448433\n",
      "Train Epoch: 7 Loss: 0.444000\n",
      "Train Epoch: 7 Loss: 0.439649\n",
      "Train Epoch: 7 Loss: 0.435377\n",
      "Train Epoch: 7 Loss: 0.431184\n",
      "Train Epoch: 7 Loss: 0.427067\n",
      "Train Epoch: 7 Loss: 0.423024\n",
      "Train Epoch: 7 Loss: 0.419053\n",
      "Train Epoch: 7 Loss: 0.415153\n",
      "Train Epoch: 7 Loss: 0.411321\n",
      "Train Epoch: 7 Loss: 0.407558\n",
      "Train Epoch: 7 Loss: 0.403859\n",
      "Train Epoch: 7 Loss: 0.400225\n",
      "Train Epoch: 7 Loss: 0.396654\n",
      "Train Epoch: 7 Loss: 0.393143\n",
      "Train Epoch: 7 Loss: 0.389692\n",
      "Train Epoch: 7 Loss: 0.386300\n",
      "Train Epoch: 7 Loss: 0.382964\n",
      "Train Epoch: 7 Loss: 0.379685\n",
      "Train Epoch: 7 Loss: 0.376459\n",
      "Train Epoch: 7 Loss: 0.373287\n",
      "Train Epoch: 7 Loss: 0.370167\n",
      "Train Epoch: 8 Loss: 0.369858\n",
      "Train Epoch: 8 Loss: 0.366794\n",
      "Train Epoch: 8 Loss: 0.363779\n",
      "Train Epoch: 8 Loss: 0.360813\n",
      "Train Epoch: 8 Loss: 0.357895\n",
      "Train Epoch: 8 Loss: 0.355023\n",
      "Train Epoch: 8 Loss: 0.352196\n",
      "Train Epoch: 8 Loss: 0.349414\n",
      "Train Epoch: 8 Loss: 0.346676\n",
      "Train Epoch: 8 Loss: 0.343980\n",
      "Train Epoch: 8 Loss: 0.341326\n",
      "Train Epoch: 8 Loss: 0.338712\n",
      "Train Epoch: 8 Loss: 0.336139\n",
      "Train Epoch: 8 Loss: 0.333605\n",
      "Train Epoch: 8 Loss: 0.331109\n",
      "Train Epoch: 8 Loss: 0.328651\n",
      "Train Epoch: 8 Loss: 0.326230\n",
      "Train Epoch: 8 Loss: 0.323844\n",
      "Train Epoch: 8 Loss: 0.321494\n",
      "Train Epoch: 8 Loss: 0.319179\n",
      "Train Epoch: 8 Loss: 0.316898\n",
      "Train Epoch: 8 Loss: 0.314649\n",
      "Train Epoch: 8 Loss: 0.312434\n",
      "Train Epoch: 9 Loss: 0.312214\n",
      "Train Epoch: 9 Loss: 0.310034\n",
      "Train Epoch: 9 Loss: 0.307885\n",
      "Train Epoch: 9 Loss: 0.305766\n",
      "Train Epoch: 9 Loss: 0.303678\n",
      "Train Epoch: 9 Loss: 0.301620\n",
      "Train Epoch: 9 Loss: 0.299590\n",
      "Train Epoch: 9 Loss: 0.297589\n",
      "Train Epoch: 9 Loss: 0.295615\n",
      "Train Epoch: 9 Loss: 0.293669\n",
      "Train Epoch: 9 Loss: 0.291750\n",
      "Train Epoch: 9 Loss: 0.289857\n",
      "Train Epoch: 9 Loss: 0.287990\n",
      "Train Epoch: 9 Loss: 0.286148\n",
      "Train Epoch: 9 Loss: 0.284331\n",
      "Train Epoch: 9 Loss: 0.282539\n",
      "Train Epoch: 9 Loss: 0.280771\n",
      "Train Epoch: 9 Loss: 0.279026\n",
      "Train Epoch: 9 Loss: 0.277305\n",
      "Train Epoch: 9 Loss: 0.275606\n",
      "Train Epoch: 9 Loss: 0.273930\n",
      "Train Epoch: 9 Loss: 0.272275\n",
      "Train Epoch: 9 Loss: 0.270642\n",
      "Train Epoch: 10 Loss: 0.270480\n",
      "Train Epoch: 10 Loss: 0.268871\n",
      "Train Epoch: 10 Loss: 0.267282\n",
      "Train Epoch: 10 Loss: 0.265713\n",
      "Train Epoch: 10 Loss: 0.264165\n",
      "Train Epoch: 10 Loss: 0.262636\n",
      "Train Epoch: 10 Loss: 0.261127\n",
      "Train Epoch: 10 Loss: 0.259637\n",
      "Train Epoch: 10 Loss: 0.258166\n",
      "Train Epoch: 10 Loss: 0.256713\n",
      "Train Epoch: 10 Loss: 0.255278\n",
      "Train Epoch: 10 Loss: 0.253861\n",
      "Train Epoch: 10 Loss: 0.252461\n",
      "Train Epoch: 10 Loss: 0.251079\n",
      "Train Epoch: 10 Loss: 0.249714\n",
      "Train Epoch: 10 Loss: 0.248365\n",
      "Train Epoch: 10 Loss: 0.247033\n",
      "Train Epoch: 10 Loss: 0.245716\n",
      "Train Epoch: 10 Loss: 0.244416\n",
      "Train Epoch: 10 Loss: 0.243131\n",
      "Train Epoch: 10 Loss: 0.241862\n",
      "Train Epoch: 10 Loss: 0.240608\n",
      "Train Epoch: 10 Loss: 0.239368\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.129342\n",
      "Train Epoch: 1 Loss: 17.794078\n",
      "Train Epoch: 1 Loss: 16.538415\n",
      "Train Epoch: 1 Loss: 15.368661\n",
      "Train Epoch: 1 Loss: 14.286583\n",
      "Train Epoch: 1 Loss: 13.290242\n",
      "Train Epoch: 1 Loss: 12.375473\n",
      "Train Epoch: 1 Loss: 11.536955\n",
      "Train Epoch: 1 Loss: 10.768963\n",
      "Train Epoch: 1 Loss: 10.065768\n",
      "Train Epoch: 1 Loss: 9.421840\n",
      "Train Epoch: 1 Loss: 8.831964\n",
      "Train Epoch: 1 Loss: 8.291267\n",
      "Train Epoch: 1 Loss: 7.795250\n",
      "Train Epoch: 1 Loss: 7.339791\n",
      "Train Epoch: 1 Loss: 6.921124\n",
      "Train Epoch: 1 Loss: 6.535822\n",
      "Train Epoch: 1 Loss: 6.180779\n",
      "Train Epoch: 1 Loss: 5.853194\n",
      "Train Epoch: 1 Loss: 5.550531\n",
      "Train Epoch: 1 Loss: 5.270508\n",
      "Train Epoch: 1 Loss: 5.011071\n",
      "Train Epoch: 1 Loss: 4.770365\n",
      "Train Epoch: 2 Loss: 4.747259\n",
      "Train Epoch: 2 Loss: 4.525242\n",
      "Train Epoch: 2 Loss: 4.318651\n",
      "Train Epoch: 2 Loss: 4.126148\n",
      "Train Epoch: 2 Loss: 3.946530\n",
      "Train Epoch: 2 Loss: 3.778710\n",
      "Train Epoch: 2 Loss: 3.621704\n",
      "Train Epoch: 2 Loss: 3.474631\n",
      "Train Epoch: 2 Loss: 3.336687\n",
      "Train Epoch: 2 Loss: 3.207146\n",
      "Train Epoch: 2 Loss: 3.085353\n",
      "Train Epoch: 2 Loss: 2.970708\n",
      "Train Epoch: 2 Loss: 2.862671\n",
      "Train Epoch: 2 Loss: 2.760748\n",
      "Train Epoch: 2 Loss: 2.664489\n",
      "Train Epoch: 2 Loss: 2.573485\n",
      "Train Epoch: 2 Loss: 2.487361\n",
      "Train Epoch: 2 Loss: 2.405775\n",
      "Train Epoch: 2 Loss: 2.328416\n",
      "Train Epoch: 2 Loss: 2.254993\n",
      "Train Epoch: 2 Loss: 2.185245\n",
      "Train Epoch: 2 Loss: 2.118928\n",
      "Train Epoch: 2 Loss: 2.055822\n",
      "Train Epoch: 3 Loss: 2.049679\n",
      "Train Epoch: 3 Loss: 1.989867\n",
      "Train Epoch: 3 Loss: 1.932851\n",
      "Train Epoch: 3 Loss: 1.878458\n",
      "Train Epoch: 3 Loss: 1.826530\n",
      "Train Epoch: 3 Loss: 1.776917\n",
      "Train Epoch: 3 Loss: 1.729482\n",
      "Train Epoch: 3 Loss: 1.684098\n",
      "Train Epoch: 3 Loss: 1.640647\n",
      "Train Epoch: 3 Loss: 1.599018\n",
      "Train Epoch: 3 Loss: 1.559111\n",
      "Train Epoch: 3 Loss: 1.520830\n",
      "Train Epoch: 3 Loss: 1.484087\n",
      "Train Epoch: 3 Loss: 1.448797\n",
      "Train Epoch: 3 Loss: 1.414886\n",
      "Train Epoch: 3 Loss: 1.382281\n",
      "Train Epoch: 3 Loss: 1.350913\n",
      "Train Epoch: 3 Loss: 1.320720\n",
      "Train Epoch: 3 Loss: 1.291644\n",
      "Train Epoch: 3 Loss: 1.263628\n",
      "Train Epoch: 3 Loss: 1.236621\n",
      "Train Epoch: 3 Loss: 1.210573\n",
      "Train Epoch: 3 Loss: 1.185440\n",
      "Train Epoch: 4 Loss: 1.182976\n",
      "Train Epoch: 4 Loss: 1.158798\n",
      "Train Epoch: 4 Loss: 1.135445\n",
      "Train Epoch: 4 Loss: 1.112882\n",
      "Train Epoch: 4 Loss: 1.091070\n",
      "Train Epoch: 4 Loss: 1.069977\n",
      "Train Epoch: 4 Loss: 1.049571\n",
      "Train Epoch: 4 Loss: 1.029820\n",
      "Train Epoch: 4 Loss: 1.010698\n",
      "Train Epoch: 4 Loss: 0.992176\n",
      "Train Epoch: 4 Loss: 0.974230\n",
      "Train Epoch: 4 Loss: 0.956835\n",
      "Train Epoch: 4 Loss: 0.939969\n",
      "Train Epoch: 4 Loss: 0.923609\n",
      "Train Epoch: 4 Loss: 0.907735\n",
      "Train Epoch: 4 Loss: 0.892328\n",
      "Train Epoch: 4 Loss: 0.877368\n",
      "Train Epoch: 4 Loss: 0.862839\n",
      "Train Epoch: 4 Loss: 0.848723\n",
      "Train Epoch: 4 Loss: 0.835005\n",
      "Train Epoch: 4 Loss: 0.821670\n",
      "Train Epoch: 4 Loss: 0.808702\n",
      "Train Epoch: 4 Loss: 0.796089\n",
      "Train Epoch: 5 Loss: 0.794847\n",
      "Train Epoch: 5 Loss: 0.782608\n",
      "Train Epoch: 5 Loss: 0.770697\n",
      "Train Epoch: 5 Loss: 0.759101\n",
      "Train Epoch: 5 Loss: 0.747809\n",
      "Train Epoch: 5 Loss: 0.736811\n",
      "Train Epoch: 5 Loss: 0.726096\n",
      "Train Epoch: 5 Loss: 0.715654\n",
      "Train Epoch: 5 Loss: 0.705475\n",
      "Train Epoch: 5 Loss: 0.695551\n",
      "Train Epoch: 5 Loss: 0.685874\n",
      "Train Epoch: 5 Loss: 0.676434\n",
      "Train Epoch: 5 Loss: 0.667223\n",
      "Train Epoch: 5 Loss: 0.658235\n",
      "Train Epoch: 5 Loss: 0.649462\n",
      "Train Epoch: 5 Loss: 0.640897\n",
      "Train Epoch: 5 Loss: 0.632533\n",
      "Train Epoch: 5 Loss: 0.624364\n",
      "Train Epoch: 5 Loss: 0.616384\n",
      "Train Epoch: 5 Loss: 0.608587\n",
      "Train Epoch: 5 Loss: 0.600966\n",
      "Train Epoch: 5 Loss: 0.593518\n",
      "Train Epoch: 5 Loss: 0.586235\n",
      "Train Epoch: 6 Loss: 0.585516\n",
      "Train Epoch: 6 Loss: 0.578411\n",
      "Train Epoch: 6 Loss: 0.571461\n",
      "Train Epoch: 6 Loss: 0.564664\n",
      "Train Epoch: 6 Loss: 0.558013\n",
      "Train Epoch: 6 Loss: 0.551504\n",
      "Train Epoch: 6 Loss: 0.545134\n",
      "Train Epoch: 6 Loss: 0.538898\n",
      "Train Epoch: 6 Loss: 0.532793\n",
      "Train Epoch: 6 Loss: 0.526815\n",
      "Train Epoch: 6 Loss: 0.520960\n",
      "Train Epoch: 6 Loss: 0.515225\n",
      "Train Epoch: 6 Loss: 0.509606\n",
      "Train Epoch: 6 Loss: 0.504101\n",
      "Train Epoch: 6 Loss: 0.498706\n",
      "Train Epoch: 6 Loss: 0.493418\n",
      "Train Epoch: 6 Loss: 0.488234\n",
      "Train Epoch: 6 Loss: 0.483152\n",
      "Train Epoch: 6 Loss: 0.478168\n",
      "Train Epoch: 6 Loss: 0.473281\n",
      "Train Epoch: 6 Loss: 0.468488\n",
      "Train Epoch: 6 Loss: 0.463785\n",
      "Train Epoch: 6 Loss: 0.459172\n",
      "Train Epoch: 7 Loss: 0.458715\n",
      "Train Epoch: 7 Loss: 0.454197\n",
      "Train Epoch: 7 Loss: 0.449763\n",
      "Train Epoch: 7 Loss: 0.445411\n",
      "Train Epoch: 7 Loss: 0.441139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 Loss: 0.436944\n",
      "Train Epoch: 7 Loss: 0.432826\n",
      "Train Epoch: 7 Loss: 0.428782\n",
      "Train Epoch: 7 Loss: 0.424811\n",
      "Train Epoch: 7 Loss: 0.420910\n",
      "Train Epoch: 7 Loss: 0.417078\n",
      "Train Epoch: 7 Loss: 0.413313\n",
      "Train Epoch: 7 Loss: 0.409615\n",
      "Train Epoch: 7 Loss: 0.405979\n",
      "Train Epoch: 7 Loss: 0.402407\n",
      "Train Epoch: 7 Loss: 0.398896\n",
      "Train Epoch: 7 Loss: 0.395445\n",
      "Train Epoch: 7 Loss: 0.392051\n",
      "Train Epoch: 7 Loss: 0.388715\n",
      "Train Epoch: 7 Loss: 0.385435\n",
      "Train Epoch: 7 Loss: 0.382209\n",
      "Train Epoch: 7 Loss: 0.379036\n",
      "Train Epoch: 7 Loss: 0.375916\n",
      "Train Epoch: 8 Loss: 0.375607\n",
      "Train Epoch: 8 Loss: 0.372542\n",
      "Train Epoch: 8 Loss: 0.369527\n",
      "Train Epoch: 8 Loss: 0.366560\n",
      "Train Epoch: 8 Loss: 0.363641\n",
      "Train Epoch: 8 Loss: 0.360769\n",
      "Train Epoch: 8 Loss: 0.357941\n",
      "Train Epoch: 8 Loss: 0.355159\n",
      "Train Epoch: 8 Loss: 0.352420\n",
      "Train Epoch: 8 Loss: 0.349723\n",
      "Train Epoch: 8 Loss: 0.347069\n",
      "Train Epoch: 8 Loss: 0.344455\n",
      "Train Epoch: 8 Loss: 0.341881\n",
      "Train Epoch: 8 Loss: 0.339346\n",
      "Train Epoch: 8 Loss: 0.336850\n",
      "Train Epoch: 8 Loss: 0.334392\n",
      "Train Epoch: 8 Loss: 0.331970\n",
      "Train Epoch: 8 Loss: 0.329584\n",
      "Train Epoch: 8 Loss: 0.327234\n",
      "Train Epoch: 8 Loss: 0.324918\n",
      "Train Epoch: 8 Loss: 0.322636\n",
      "Train Epoch: 8 Loss: 0.320387\n",
      "Train Epoch: 8 Loss: 0.318172\n",
      "Train Epoch: 9 Loss: 0.317952\n",
      "Train Epoch: 9 Loss: 0.315771\n",
      "Train Epoch: 9 Loss: 0.313622\n",
      "Train Epoch: 9 Loss: 0.311503\n",
      "Train Epoch: 9 Loss: 0.309414\n",
      "Train Epoch: 9 Loss: 0.307355\n",
      "Train Epoch: 9 Loss: 0.305325\n",
      "Train Epoch: 9 Loss: 0.303323\n",
      "Train Epoch: 9 Loss: 0.301349\n",
      "Train Epoch: 9 Loss: 0.299403\n",
      "Train Epoch: 9 Loss: 0.297483\n",
      "Train Epoch: 9 Loss: 0.295590\n",
      "Train Epoch: 9 Loss: 0.293723\n",
      "Train Epoch: 9 Loss: 0.291881\n",
      "Train Epoch: 9 Loss: 0.290064\n",
      "Train Epoch: 9 Loss: 0.288271\n",
      "Train Epoch: 9 Loss: 0.286502\n",
      "Train Epoch: 9 Loss: 0.284757\n",
      "Train Epoch: 9 Loss: 0.283036\n",
      "Train Epoch: 9 Loss: 0.281336\n",
      "Train Epoch: 9 Loss: 0.279660\n",
      "Train Epoch: 9 Loss: 0.278005\n",
      "Train Epoch: 9 Loss: 0.276372\n",
      "Train Epoch: 10 Loss: 0.276210\n",
      "Train Epoch: 10 Loss: 0.274600\n",
      "Train Epoch: 10 Loss: 0.273011\n",
      "Train Epoch: 10 Loss: 0.271442\n",
      "Train Epoch: 10 Loss: 0.269894\n",
      "Train Epoch: 10 Loss: 0.268365\n",
      "Train Epoch: 10 Loss: 0.266855\n",
      "Train Epoch: 10 Loss: 0.265365\n",
      "Train Epoch: 10 Loss: 0.263893\n",
      "Train Epoch: 10 Loss: 0.262440\n",
      "Train Epoch: 10 Loss: 0.261005\n",
      "Train Epoch: 10 Loss: 0.259587\n",
      "Train Epoch: 10 Loss: 0.258188\n",
      "Train Epoch: 10 Loss: 0.256805\n",
      "Train Epoch: 10 Loss: 0.255439\n",
      "Train Epoch: 10 Loss: 0.254090\n",
      "Train Epoch: 10 Loss: 0.252758\n",
      "Train Epoch: 10 Loss: 0.251441\n",
      "Train Epoch: 10 Loss: 0.250141\n",
      "Train Epoch: 10 Loss: 0.248856\n",
      "Train Epoch: 10 Loss: 0.247586\n",
      "Train Epoch: 10 Loss: 0.246332\n",
      "Train Epoch: 10 Loss: 0.245092\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.128510\n",
      "Train Epoch: 1 Loss: 17.794464\n",
      "Train Epoch: 1 Loss: 16.539851\n",
      "Train Epoch: 1 Loss: 15.370917\n",
      "Train Epoch: 1 Loss: 14.289429\n",
      "Train Epoch: 1 Loss: 13.293508\n",
      "Train Epoch: 1 Loss: 12.379006\n",
      "Train Epoch: 1 Loss: 11.540653\n",
      "Train Epoch: 1 Loss: 10.772747\n",
      "Train Epoch: 1 Loss: 10.069587\n",
      "Train Epoch: 1 Loss: 9.425657\n",
      "Train Epoch: 1 Loss: 8.835749\n",
      "Train Epoch: 1 Loss: 8.295004\n",
      "Train Epoch: 1 Loss: 7.798939\n",
      "Train Epoch: 1 Loss: 7.343416\n",
      "Train Epoch: 1 Loss: 6.924686\n",
      "Train Epoch: 1 Loss: 6.539319\n",
      "Train Epoch: 1 Loss: 6.184214\n",
      "Train Epoch: 1 Loss: 5.856568\n",
      "Train Epoch: 1 Loss: 5.553846\n",
      "Train Epoch: 1 Loss: 5.273768\n",
      "Train Epoch: 1 Loss: 5.014275\n",
      "Train Epoch: 1 Loss: 4.773521\n",
      "Train Epoch: 2 Loss: 4.750409\n",
      "Train Epoch: 2 Loss: 4.528346\n",
      "Train Epoch: 2 Loss: 4.321711\n",
      "Train Epoch: 2 Loss: 4.129167\n",
      "Train Epoch: 2 Loss: 3.949509\n",
      "Train Epoch: 2 Loss: 3.781651\n",
      "Train Epoch: 2 Loss: 3.624613\n",
      "Train Epoch: 2 Loss: 3.477507\n",
      "Train Epoch: 2 Loss: 3.339532\n",
      "Train Epoch: 2 Loss: 3.209964\n",
      "Train Epoch: 2 Loss: 3.088144\n",
      "Train Epoch: 2 Loss: 2.973474\n",
      "Train Epoch: 2 Loss: 2.865412\n",
      "Train Epoch: 2 Loss: 2.763466\n",
      "Train Epoch: 2 Loss: 2.667187\n",
      "Train Epoch: 2 Loss: 2.576163\n",
      "Train Epoch: 2 Loss: 2.490020\n",
      "Train Epoch: 2 Loss: 2.408417\n",
      "Train Epoch: 2 Loss: 2.331039\n",
      "Train Epoch: 2 Loss: 2.257600\n",
      "Train Epoch: 2 Loss: 2.187837\n",
      "Train Epoch: 2 Loss: 2.121506\n",
      "Train Epoch: 2 Loss: 2.058385\n",
      "Train Epoch: 3 Loss: 2.052241\n",
      "Train Epoch: 3 Loss: 1.992415\n",
      "Train Epoch: 3 Loss: 1.935386\n",
      "Train Epoch: 3 Loss: 1.880982\n",
      "Train Epoch: 3 Loss: 1.829042\n",
      "Train Epoch: 3 Loss: 1.779418\n",
      "Train Epoch: 3 Loss: 1.731973\n",
      "Train Epoch: 3 Loss: 1.686578\n",
      "Train Epoch: 3 Loss: 1.643118\n",
      "Train Epoch: 3 Loss: 1.601480\n",
      "Train Epoch: 3 Loss: 1.561564\n",
      "Train Epoch: 3 Loss: 1.523274\n",
      "Train Epoch: 3 Loss: 1.486522\n",
      "Train Epoch: 3 Loss: 1.451225\n",
      "Train Epoch: 3 Loss: 1.417306\n",
      "Train Epoch: 3 Loss: 1.384693\n",
      "Train Epoch: 3 Loss: 1.353318\n",
      "Train Epoch: 3 Loss: 1.323120\n",
      "Train Epoch: 3 Loss: 1.294036\n",
      "Train Epoch: 3 Loss: 1.266014\n",
      "Train Epoch: 3 Loss: 1.239001\n",
      "Train Epoch: 3 Loss: 1.212947\n",
      "Train Epoch: 3 Loss: 1.187809\n",
      "Train Epoch: 4 Loss: 1.185343\n",
      "Train Epoch: 4 Loss: 1.161160\n",
      "Train Epoch: 4 Loss: 1.137803\n",
      "Train Epoch: 4 Loss: 1.115234\n",
      "Train Epoch: 4 Loss: 1.093417\n",
      "Train Epoch: 4 Loss: 1.072320\n",
      "Train Epoch: 4 Loss: 1.051908\n",
      "Train Epoch: 4 Loss: 1.032153\n",
      "Train Epoch: 4 Loss: 1.013027\n",
      "Train Epoch: 4 Loss: 0.994501\n",
      "Train Epoch: 4 Loss: 0.976551\n",
      "Train Epoch: 4 Loss: 0.959152\n",
      "Train Epoch: 4 Loss: 0.942282\n",
      "Train Epoch: 4 Loss: 0.925918\n",
      "Train Epoch: 4 Loss: 0.910040\n",
      "Train Epoch: 4 Loss: 0.894630\n",
      "Train Epoch: 4 Loss: 0.879667\n",
      "Train Epoch: 4 Loss: 0.865134\n",
      "Train Epoch: 4 Loss: 0.851015\n",
      "Train Epoch: 4 Loss: 0.837294\n",
      "Train Epoch: 4 Loss: 0.823956\n",
      "Train Epoch: 4 Loss: 0.810985\n",
      "Train Epoch: 4 Loss: 0.798369\n",
      "Train Epoch: 5 Loss: 0.797127\n",
      "Train Epoch: 5 Loss: 0.784885\n",
      "Train Epoch: 5 Loss: 0.772971\n",
      "Train Epoch: 5 Loss: 0.761372\n",
      "Train Epoch: 5 Loss: 0.750078\n",
      "Train Epoch: 5 Loss: 0.739077\n",
      "Train Epoch: 5 Loss: 0.728360\n",
      "Train Epoch: 5 Loss: 0.717915\n",
      "Train Epoch: 5 Loss: 0.707734\n",
      "Train Epoch: 5 Loss: 0.697808\n",
      "Train Epoch: 5 Loss: 0.688128\n",
      "Train Epoch: 5 Loss: 0.678686\n",
      "Train Epoch: 5 Loss: 0.669474\n",
      "Train Epoch: 5 Loss: 0.660484\n",
      "Train Epoch: 5 Loss: 0.651709\n",
      "Train Epoch: 5 Loss: 0.643142\n",
      "Train Epoch: 5 Loss: 0.634776\n",
      "Train Epoch: 5 Loss: 0.626605\n",
      "Train Epoch: 5 Loss: 0.618623\n",
      "Train Epoch: 5 Loss: 0.610824\n",
      "Train Epoch: 5 Loss: 0.603202\n",
      "Train Epoch: 5 Loss: 0.595751\n",
      "Train Epoch: 5 Loss: 0.588467\n",
      "Train Epoch: 6 Loss: 0.587748\n",
      "Train Epoch: 6 Loss: 0.580641\n",
      "Train Epoch: 6 Loss: 0.573690\n",
      "Train Epoch: 6 Loss: 0.566890\n",
      "Train Epoch: 6 Loss: 0.560238\n",
      "Train Epoch: 6 Loss: 0.553728\n",
      "Train Epoch: 6 Loss: 0.547356\n",
      "Train Epoch: 6 Loss: 0.541119\n",
      "Train Epoch: 6 Loss: 0.535013\n",
      "Train Epoch: 6 Loss: 0.529033\n",
      "Train Epoch: 6 Loss: 0.523177\n",
      "Train Epoch: 6 Loss: 0.517441\n",
      "Train Epoch: 6 Loss: 0.511821\n",
      "Train Epoch: 6 Loss: 0.506314\n",
      "Train Epoch: 6 Loss: 0.500918\n",
      "Train Epoch: 6 Loss: 0.495628\n",
      "Train Epoch: 6 Loss: 0.490443\n",
      "Train Epoch: 6 Loss: 0.485360\n",
      "Train Epoch: 6 Loss: 0.480375\n",
      "Train Epoch: 6 Loss: 0.475487\n",
      "Train Epoch: 6 Loss: 0.470692\n",
      "Train Epoch: 6 Loss: 0.465989\n",
      "Train Epoch: 6 Loss: 0.461374\n",
      "Train Epoch: 7 Loss: 0.460918\n",
      "Train Epoch: 7 Loss: 0.456398\n",
      "Train Epoch: 7 Loss: 0.451963\n",
      "Train Epoch: 7 Loss: 0.447610\n",
      "Train Epoch: 7 Loss: 0.443337\n",
      "Train Epoch: 7 Loss: 0.439142\n",
      "Train Epoch: 7 Loss: 0.435023\n",
      "Train Epoch: 7 Loss: 0.430978\n",
      "Train Epoch: 7 Loss: 0.427005\n",
      "Train Epoch: 7 Loss: 0.423104\n",
      "Train Epoch: 7 Loss: 0.419271\n",
      "Train Epoch: 7 Loss: 0.415505\n",
      "Train Epoch: 7 Loss: 0.411805\n",
      "Train Epoch: 7 Loss: 0.408170\n",
      "Train Epoch: 7 Loss: 0.404596\n",
      "Train Epoch: 7 Loss: 0.401084\n",
      "Train Epoch: 7 Loss: 0.397632\n",
      "Train Epoch: 7 Loss: 0.394238\n",
      "Train Epoch: 7 Loss: 0.390902\n",
      "Train Epoch: 7 Loss: 0.387620\n",
      "Train Epoch: 7 Loss: 0.384394\n",
      "Train Epoch: 7 Loss: 0.381220\n",
      "Train Epoch: 7 Loss: 0.378099\n",
      "Train Epoch: 8 Loss: 0.377790\n",
      "Train Epoch: 8 Loss: 0.374724\n",
      "Train Epoch: 8 Loss: 0.371708\n",
      "Train Epoch: 8 Loss: 0.368741\n",
      "Train Epoch: 8 Loss: 0.365821\n",
      "Train Epoch: 8 Loss: 0.362948\n",
      "Train Epoch: 8 Loss: 0.360120\n",
      "Train Epoch: 8 Loss: 0.357337\n",
      "Train Epoch: 8 Loss: 0.354598\n",
      "Train Epoch: 8 Loss: 0.351901\n",
      "Train Epoch: 8 Loss: 0.349245\n",
      "Train Epoch: 8 Loss: 0.346631\n",
      "Train Epoch: 8 Loss: 0.344056\n",
      "Train Epoch: 8 Loss: 0.341521\n",
      "Train Epoch: 8 Loss: 0.339024\n",
      "Train Epoch: 8 Loss: 0.336565\n",
      "Train Epoch: 8 Loss: 0.334143\n",
      "Train Epoch: 8 Loss: 0.331756\n",
      "Train Epoch: 8 Loss: 0.329405\n",
      "Train Epoch: 8 Loss: 0.327089\n",
      "Train Epoch: 8 Loss: 0.324807\n",
      "Train Epoch: 8 Loss: 0.322558\n",
      "Train Epoch: 8 Loss: 0.320341\n",
      "Train Epoch: 9 Loss: 0.320121\n",
      "Train Epoch: 9 Loss: 0.317940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 Loss: 0.315790\n",
      "Train Epoch: 9 Loss: 0.313671\n",
      "Train Epoch: 9 Loss: 0.311582\n",
      "Train Epoch: 9 Loss: 0.309522\n",
      "Train Epoch: 9 Loss: 0.307492\n",
      "Train Epoch: 9 Loss: 0.305490\n",
      "Train Epoch: 9 Loss: 0.303515\n",
      "Train Epoch: 9 Loss: 0.301568\n",
      "Train Epoch: 9 Loss: 0.299648\n",
      "Train Epoch: 9 Loss: 0.297755\n",
      "Train Epoch: 9 Loss: 0.295887\n",
      "Train Epoch: 9 Loss: 0.294044\n",
      "Train Epoch: 9 Loss: 0.292227\n",
      "Train Epoch: 9 Loss: 0.290434\n",
      "Train Epoch: 9 Loss: 0.288665\n",
      "Train Epoch: 9 Loss: 0.286919\n",
      "Train Epoch: 9 Loss: 0.285197\n",
      "Train Epoch: 9 Loss: 0.283498\n",
      "Train Epoch: 9 Loss: 0.281821\n",
      "Train Epoch: 9 Loss: 0.280165\n",
      "Train Epoch: 9 Loss: 0.278532\n",
      "Train Epoch: 10 Loss: 0.278370\n",
      "Train Epoch: 10 Loss: 0.276760\n",
      "Train Epoch: 10 Loss: 0.275170\n",
      "Train Epoch: 10 Loss: 0.273601\n",
      "Train Epoch: 10 Loss: 0.272052\n",
      "Train Epoch: 10 Loss: 0.270523\n",
      "Train Epoch: 10 Loss: 0.269013\n",
      "Train Epoch: 10 Loss: 0.267522\n",
      "Train Epoch: 10 Loss: 0.266050\n",
      "Train Epoch: 10 Loss: 0.264597\n",
      "Train Epoch: 10 Loss: 0.263161\n",
      "Train Epoch: 10 Loss: 0.261743\n",
      "Train Epoch: 10 Loss: 0.260343\n",
      "Train Epoch: 10 Loss: 0.258960\n",
      "Train Epoch: 10 Loss: 0.257594\n",
      "Train Epoch: 10 Loss: 0.256245\n",
      "Train Epoch: 10 Loss: 0.254912\n",
      "Train Epoch: 10 Loss: 0.253596\n",
      "Train Epoch: 10 Loss: 0.252295\n",
      "Train Epoch: 10 Loss: 0.251009\n",
      "Train Epoch: 10 Loss: 0.249739\n",
      "Train Epoch: 10 Loss: 0.248485\n",
      "Train Epoch: 10 Loss: 0.247245\n",
      "Done\n",
      "Train Epoch: 1 Loss: 19.123031\n",
      "Train Epoch: 1 Loss: 17.787492\n",
      "Train Epoch: 1 Loss: 16.531535\n",
      "Train Epoch: 1 Loss: 15.361477\n",
      "Train Epoch: 1 Loss: 14.279075\n",
      "Train Epoch: 1 Loss: 13.282440\n",
      "Train Epoch: 1 Loss: 12.367396\n",
      "Train Epoch: 1 Loss: 11.528655\n",
      "Train Epoch: 1 Loss: 10.760493\n",
      "Train Epoch: 1 Loss: 10.057180\n",
      "Train Epoch: 1 Loss: 9.413183\n",
      "Train Epoch: 1 Loss: 8.823276\n",
      "Train Epoch: 1 Loss: 8.282584\n",
      "Train Epoch: 1 Loss: 7.786596\n",
      "Train Epoch: 1 Loss: 7.331184\n",
      "Train Epoch: 1 Loss: 6.912573\n",
      "Train Epoch: 1 Loss: 6.527336\n",
      "Train Epoch: 1 Loss: 6.172363\n",
      "Train Epoch: 1 Loss: 5.844848\n",
      "Train Epoch: 1 Loss: 5.542253\n",
      "Train Epoch: 1 Loss: 5.262299\n",
      "Train Epoch: 1 Loss: 5.002927\n",
      "Train Epoch: 1 Loss: 4.762282\n",
      "Train Epoch: 2 Loss: 4.739184\n",
      "Train Epoch: 2 Loss: 4.517225\n",
      "Train Epoch: 2 Loss: 4.310687\n",
      "Train Epoch: 2 Loss: 4.118236\n",
      "Train Epoch: 2 Loss: 3.938665\n",
      "Train Epoch: 2 Loss: 3.770889\n",
      "Train Epoch: 2 Loss: 3.613927\n",
      "Train Epoch: 2 Loss: 3.466892\n",
      "Train Epoch: 2 Loss: 3.328983\n",
      "Train Epoch: 2 Loss: 3.199478\n",
      "Train Epoch: 2 Loss: 3.077715\n",
      "Train Epoch: 2 Loss: 2.963101\n",
      "Train Epoch: 2 Loss: 2.855092\n",
      "Train Epoch: 2 Loss: 2.753194\n",
      "Train Epoch: 2 Loss: 2.656960\n",
      "Train Epoch: 2 Loss: 2.565979\n",
      "Train Epoch: 2 Loss: 2.479878\n",
      "Train Epoch: 2 Loss: 2.398313\n",
      "Train Epoch: 2 Loss: 2.320971\n",
      "Train Epoch: 2 Loss: 2.247566\n",
      "Train Epoch: 2 Loss: 2.177835\n",
      "Train Epoch: 2 Loss: 2.111535\n",
      "Train Epoch: 2 Loss: 2.048443\n",
      "Train Epoch: 3 Loss: 2.042303\n",
      "Train Epoch: 3 Loss: 1.982504\n",
      "Train Epoch: 3 Loss: 1.925502\n",
      "Train Epoch: 3 Loss: 1.871123\n",
      "Train Epoch: 3 Loss: 1.819206\n",
      "Train Epoch: 3 Loss: 1.769605\n",
      "Train Epoch: 3 Loss: 1.722181\n",
      "Train Epoch: 3 Loss: 1.676807\n",
      "Train Epoch: 3 Loss: 1.633366\n",
      "Train Epoch: 3 Loss: 1.591747\n",
      "Train Epoch: 3 Loss: 1.551849\n",
      "Train Epoch: 3 Loss: 1.513577\n",
      "Train Epoch: 3 Loss: 1.476841\n",
      "Train Epoch: 3 Loss: 1.441560\n",
      "Train Epoch: 3 Loss: 1.407656\n",
      "Train Epoch: 3 Loss: 1.375058\n",
      "Train Epoch: 3 Loss: 1.343697\n",
      "Train Epoch: 3 Loss: 1.313511\n",
      "Train Epoch: 3 Loss: 1.284441\n",
      "Train Epoch: 3 Loss: 1.256431\n",
      "Train Epoch: 3 Loss: 1.229430\n",
      "Train Epoch: 3 Loss: 1.203388\n",
      "Train Epoch: 3 Loss: 1.178260\n",
      "Train Epoch: 4 Loss: 1.175795\n",
      "Train Epoch: 4 Loss: 1.151622\n",
      "Train Epoch: 4 Loss: 1.128275\n",
      "Train Epoch: 4 Loss: 1.105716\n",
      "Train Epoch: 4 Loss: 1.083910\n",
      "Train Epoch: 4 Loss: 1.062821\n",
      "Train Epoch: 4 Loss: 1.042418\n",
      "Train Epoch: 4 Loss: 1.022672\n",
      "Train Epoch: 4 Loss: 1.003554\n",
      "Train Epoch: 4 Loss: 0.985036\n",
      "Train Epoch: 4 Loss: 0.967094\n",
      "Train Epoch: 4 Loss: 0.949702\n",
      "Train Epoch: 4 Loss: 0.932839\n",
      "Train Epoch: 4 Loss: 0.916482\n",
      "Train Epoch: 4 Loss: 0.900611\n",
      "Train Epoch: 4 Loss: 0.885207\n",
      "Train Epoch: 4 Loss: 0.870251\n",
      "Train Epoch: 4 Loss: 0.855724\n",
      "Train Epoch: 4 Loss: 0.841611\n",
      "Train Epoch: 4 Loss: 0.827896\n",
      "Train Epoch: 4 Loss: 0.814563\n",
      "Train Epoch: 4 Loss: 0.801598\n",
      "Train Epoch: 4 Loss: 0.788987\n",
      "Train Epoch: 5 Loss: 0.787745\n",
      "Train Epoch: 5 Loss: 0.775509\n",
      "Train Epoch: 5 Loss: 0.763599\n",
      "Train Epoch: 5 Loss: 0.752006\n",
      "Train Epoch: 5 Loss: 0.740717\n",
      "Train Epoch: 5 Loss: 0.729720\n",
      "Train Epoch: 5 Loss: 0.719007\n",
      "Train Epoch: 5 Loss: 0.708567\n",
      "Train Epoch: 5 Loss: 0.698390\n",
      "Train Epoch: 5 Loss: 0.688468\n",
      "Train Epoch: 5 Loss: 0.678792\n",
      "Train Epoch: 5 Loss: 0.669354\n",
      "Train Epoch: 5 Loss: 0.660146\n",
      "Train Epoch: 5 Loss: 0.651159\n",
      "Train Epoch: 5 Loss: 0.642388\n",
      "Train Epoch: 5 Loss: 0.633825\n",
      "Train Epoch: 5 Loss: 0.625462\n",
      "Train Epoch: 5 Loss: 0.617295\n",
      "Train Epoch: 5 Loss: 0.609316\n",
      "Train Epoch: 5 Loss: 0.601520\n",
      "Train Epoch: 5 Loss: 0.593901\n",
      "Train Epoch: 5 Loss: 0.586453\n",
      "Train Epoch: 5 Loss: 0.579172\n",
      "Train Epoch: 6 Loss: 0.578453\n",
      "Train Epoch: 6 Loss: 0.571349\n",
      "Train Epoch: 6 Loss: 0.564401\n",
      "Train Epoch: 6 Loss: 0.557604\n",
      "Train Epoch: 6 Loss: 0.550954\n",
      "Train Epoch: 6 Loss: 0.544447\n",
      "Train Epoch: 6 Loss: 0.538078\n",
      "Train Epoch: 6 Loss: 0.531844\n",
      "Train Epoch: 6 Loss: 0.525740\n",
      "Train Epoch: 6 Loss: 0.519762\n",
      "Train Epoch: 6 Loss: 0.513908\n",
      "Train Epoch: 6 Loss: 0.508174\n",
      "Train Epoch: 6 Loss: 0.502557\n",
      "Train Epoch: 6 Loss: 0.497052\n",
      "Train Epoch: 6 Loss: 0.491658\n",
      "Train Epoch: 6 Loss: 0.486371\n",
      "Train Epoch: 6 Loss: 0.481188\n",
      "Train Epoch: 6 Loss: 0.476107\n",
      "Train Epoch: 6 Loss: 0.471124\n",
      "Train Epoch: 6 Loss: 0.466238\n",
      "Train Epoch: 6 Loss: 0.461445\n",
      "Train Epoch: 6 Loss: 0.456743\n",
      "Train Epoch: 6 Loss: 0.452130\n",
      "Train Epoch: 7 Loss: 0.451674\n",
      "Train Epoch: 7 Loss: 0.447156\n",
      "Train Epoch: 7 Loss: 0.442723\n",
      "Train Epoch: 7 Loss: 0.438372\n",
      "Train Epoch: 7 Loss: 0.434100\n",
      "Train Epoch: 7 Loss: 0.429907\n",
      "Train Epoch: 7 Loss: 0.425789\n",
      "Train Epoch: 7 Loss: 0.421746\n",
      "Train Epoch: 7 Loss: 0.417775\n",
      "Train Epoch: 7 Loss: 0.413875\n",
      "Train Epoch: 7 Loss: 0.410044\n",
      "Train Epoch: 7 Loss: 0.406280\n",
      "Train Epoch: 7 Loss: 0.402581\n",
      "Train Epoch: 7 Loss: 0.398947\n",
      "Train Epoch: 7 Loss: 0.395375\n",
      "Train Epoch: 7 Loss: 0.391864\n",
      "Train Epoch: 7 Loss: 0.388414\n",
      "Train Epoch: 7 Loss: 0.385021\n",
      "Train Epoch: 7 Loss: 0.381686\n",
      "Train Epoch: 7 Loss: 0.378406\n",
      "Train Epoch: 7 Loss: 0.375180\n",
      "Train Epoch: 7 Loss: 0.372008\n",
      "Train Epoch: 7 Loss: 0.368888\n",
      "Train Epoch: 8 Loss: 0.368579\n",
      "Train Epoch: 8 Loss: 0.365514\n",
      "Train Epoch: 8 Loss: 0.362500\n",
      "Train Epoch: 8 Loss: 0.359534\n",
      "Train Epoch: 8 Loss: 0.356615\n",
      "Train Epoch: 8 Loss: 0.353743\n",
      "Train Epoch: 8 Loss: 0.350916\n",
      "Train Epoch: 8 Loss: 0.348134\n",
      "Train Epoch: 8 Loss: 0.345396\n",
      "Train Epoch: 8 Loss: 0.342700\n",
      "Train Epoch: 8 Loss: 0.340045\n",
      "Train Epoch: 8 Loss: 0.337432\n",
      "Train Epoch: 8 Loss: 0.334859\n",
      "Train Epoch: 8 Loss: 0.332324\n",
      "Train Epoch: 8 Loss: 0.329828\n",
      "Train Epoch: 8 Loss: 0.327370\n",
      "Train Epoch: 8 Loss: 0.324949\n",
      "Train Epoch: 8 Loss: 0.322563\n",
      "Train Epoch: 8 Loss: 0.320213\n",
      "Train Epoch: 8 Loss: 0.317898\n",
      "Train Epoch: 8 Loss: 0.315616\n",
      "Train Epoch: 8 Loss: 0.313368\n",
      "Train Epoch: 8 Loss: 0.311153\n",
      "Train Epoch: 9 Loss: 0.310933\n",
      "Train Epoch: 9 Loss: 0.308752\n",
      "Train Epoch: 9 Loss: 0.306603\n",
      "Train Epoch: 9 Loss: 0.304485\n",
      "Train Epoch: 9 Loss: 0.302397\n",
      "Train Epoch: 9 Loss: 0.300338\n",
      "Train Epoch: 9 Loss: 0.298308\n",
      "Train Epoch: 9 Loss: 0.296307\n",
      "Train Epoch: 9 Loss: 0.294333\n",
      "Train Epoch: 9 Loss: 0.292387\n",
      "Train Epoch: 9 Loss: 0.290468\n",
      "Train Epoch: 9 Loss: 0.288575\n",
      "Train Epoch: 9 Loss: 0.286707\n",
      "Train Epoch: 9 Loss: 0.284866\n",
      "Train Epoch: 9 Loss: 0.283049\n",
      "Train Epoch: 9 Loss: 0.281257\n",
      "Train Epoch: 9 Loss: 0.279488\n",
      "Train Epoch: 9 Loss: 0.277743\n",
      "Train Epoch: 9 Loss: 0.276022\n",
      "Train Epoch: 9 Loss: 0.274323\n",
      "Train Epoch: 9 Loss: 0.272647\n",
      "Train Epoch: 9 Loss: 0.270992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/39092 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 Loss: 0.269359\n",
      "Train Epoch: 10 Loss: 0.269197\n",
      "Train Epoch: 10 Loss: 0.267587\n",
      "Train Epoch: 10 Loss: 0.265999\n",
      "Train Epoch: 10 Loss: 0.264430\n",
      "Train Epoch: 10 Loss: 0.262882\n",
      "Train Epoch: 10 Loss: 0.261353\n",
      "Train Epoch: 10 Loss: 0.259844\n",
      "Train Epoch: 10 Loss: 0.258354\n",
      "Train Epoch: 10 Loss: 0.256882\n",
      "Train Epoch: 10 Loss: 0.255429\n",
      "Train Epoch: 10 Loss: 0.253994\n",
      "Train Epoch: 10 Loss: 0.252577\n",
      "Train Epoch: 10 Loss: 0.251177\n",
      "Train Epoch: 10 Loss: 0.249795\n",
      "Train Epoch: 10 Loss: 0.248430\n",
      "Train Epoch: 10 Loss: 0.247081\n",
      "Train Epoch: 10 Loss: 0.245748\n",
      "Train Epoch: 10 Loss: 0.244432\n",
      "Train Epoch: 10 Loss: 0.243132\n",
      "Train Epoch: 10 Loss: 0.241847\n",
      "Train Epoch: 10 Loss: 0.240578\n",
      "Train Epoch: 10 Loss: 0.239323\n",
      "Train Epoch: 10 Loss: 0.238084\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39092/39092 [02:38<00:00, 247.23it/s]\n",
      "100%|██████████| 39092/39092 [00:07<00:00, 4986.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from preprocessing import mappings, transforms, treebank_reader\n",
    "from training import pcfg, lpcfg\n",
    "\n",
    "config.train = treebank_reader.read(config.train_file, cutoff=True)\n",
    "config.nonterminal_map = mappings.NonterminalMap(config.train)\n",
    "config.terminal_map = mappings.TerminalMap(config.train, len(config.nonterminal_map))\n",
    "transforms.transform_trees(config.train)\n",
    "config.pcfg = pcfg.PCFG()\n",
    "from training_ import vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nonterminal mappings: 100%|██████████| 39092/39092 [00:02<00:00, 18850.25it/s]\n",
      "Transform from strs to ints: 100%|██████████| 39092/39092 [00:05<00:00, 6788.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from training_.pcfg_t import PCFGT\n",
    "from training_.mappings_t import NonterminalMap, TerminalMap\n",
    "from training_.transforms_t import transform_trees\n",
    "config.nonterminal_map = NonterminalMap(config.train)\n",
    "config.terminal_map = TerminalMap(config.train, len(config.nonterminal_map))\n",
    "transforms.transform_trees(config.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_ import pcfg_t\n",
    "config.pcfg = pcfg_t.PCFGT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86684"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config.pcfg.rule3s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19949"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config.pcfg.rule1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({IN->in: 0.17063732769980547,\n",
       "         DT->an: 0.04151933239896619,\n",
       "         NNP->oct.: 0.0039991743640022705,\n",
       "         CD->19: 0.0029396292972738805,\n",
       "         NN->review: 0.0001881805506847206,\n",
       "         IN->of: 0.23518584366960196,\n",
       "         ``->``: 0.982565741682406,\n",
       "         DT->the: 0.6033740083064382,\n",
       "         NN->NN: 0.08421079643141247,\n",
       "         ''->'': 0.9809353589514448,\n",
       "         IN->at: 0.0480662636742036,\n",
       "         NNP->chicago: 0.0015996697456009082,\n",
       "         POS->'s: 0.9297057449789817,\n",
       "         NNP->NNP: 0.17245471902574952,\n",
       "         -LRB-->-lrb-: 0.8399390243902439,\n",
       "         VBN->VBN: 0.1126990378664266,\n",
       "         NNS->NNS: 0.10502172863351038,\n",
       "         VBP->take: 0.003111495246326707,\n",
       "         NN->stage: 0.00023094885765852073,\n",
       "         NNP->city: 0.0016641725579235255,\n",
       "         ,->,: 0.9999159222280609,\n",
       "         CC->&: 0.04362344278436577,\n",
       "         NNS->arts: 8.779245862780387e-05,\n",
       "         -RRB-->-rrb-: 0.8385140257771039,\n",
       "         NN->role: 0.0010606540129502434,\n",
       "         NP+NNP->NNP: 0.18834589512926495,\n",
       "         VBN->played: 0.0011815675462780622,\n",
       "         IN->by: 0.047334183940262294,\n",
       "         NNP->kim: 0.00010320449971618763,\n",
       "         VBD->was: 0.14198501872659175,\n",
       "         ADVP+RB->RB: 0.05738530130878757,\n",
       "         VBN->attributed: 0.000956507061272717,\n",
       "         TO->to: 0.9997710203333944,\n",
       "         .->.: 0.9891879338373804,\n",
       "         NNP->ms.: 0.0028123226172661127,\n",
       "         VBZ->plays: 0.0008955852913286271,\n",
       "         NNP->motor: 0.001251354559058775,\n",
       "         NNPS->cars: 0.0008410428931875525,\n",
       "         NNP->inc.: 0.013790701274575571,\n",
       "         VBD->said: 0.13876404494382022,\n",
       "         NP+PRP->it: 0.3366201366201366,\n",
       "         VBZ->expects: 0.01285428300495206,\n",
       "         PRP$->its: 0.44110123035692533,\n",
       "         NNP->u.s.: 0.0200216729449404,\n",
       "         NNS->sales: 0.014858873622755805,\n",
       "         VB->remain: 0.003887229428372683,\n",
       "         ADJP+JJ->steady: 0.0014069644741470278,\n",
       "         IN->about: 0.015990713045660857,\n",
       "         CD->CD: 0.1894668440758734,\n",
       "         NNS->cars: 0.0024142926122646064,\n",
       "         NP+CD->1990: 0.03182069728832319,\n",
       "         NN->luxury: 0.00038491476276420123,\n",
       "         NN->auto: 0.0014199077915301645,\n",
       "         NN->maker: 0.002292381253795687,\n",
       "         JJ->last: 0.020223164393038975,\n",
       "         NN->year: 0.01874962577731398,\n",
       "         VBD->sold: 0.004456928838951311,\n",
       "         NNP->howard: 0.0003096134991485629,\n",
       "         NP+NN->president: 0.023596603291500713,\n",
       "         CC->and: 0.6970760734620489,\n",
       "         JJ->chief: 0.005552500399141402,\n",
       "         NN->executive: 0.0029595668425869692,\n",
       "         NN->officer: 0.0027029570007441684,\n",
       "         NP+PRP->he: 0.20297000297000298,\n",
       "         VBZ->anticipates: 0.0005794963649773469,\n",
       "         NP+NN->growth: 0.003531975651912527,\n",
       "         IN->for: 0.08634357547742057,\n",
       "         NNP->britain: 0.0009030393725166417,\n",
       "         NNP->europe: 0.0009546416223747355,\n",
       "         JJ->far: 0.00010643770733178407,\n",
       "         JJ->eastern: 0.00030157350410672156,\n",
       "         NNS->markets: 0.007396514639392476,\n",
       "         NNP->bell: 0.0007482326229423603,\n",
       "         NNP->industries: 0.0006708292481552195,\n",
       "         VBD->increased: 0.004644194756554307,\n",
       "         NN->quarterly: 5.987562976332019e-05,\n",
       "         CD->10: 0.01609060246928861,\n",
       "         NNS->cents: 0.016878100171195294,\n",
       "         IN->from: 0.046256980903177224,\n",
       "         CD->seven: 0.003280007426431909,\n",
       "         DT->a: 0.253024906456134,\n",
       "         NN->share: 0.011778391740584556,\n",
       "         JJ->new: 0.024853204661971582,\n",
       "         NN->rate: 0.004473564909459494,\n",
       "         MD->will: 0.31435461885288873,\n",
       "         VB->be: 0.14808298211874463,\n",
       "         JJ->payable: 0.0005854073903248124,\n",
       "         NNP->feb.: 0.0002451106868259456,\n",
       "         CD->15: 0.012315499582263205,\n",
       "         NN->record: 0.0011718516110821237,\n",
       "         NN->date: 0.0004362367311327614,\n",
       "         VBZ->has: 0.17042461279106522,\n",
       "         RB->n't: 0.19788901529515865,\n",
       "         VBN->been: 0.08631069599954988,\n",
       "         VP+VBN->set: 0.0031426775612822125,\n",
       "         NP+NNP->bell: 8.104384471999351e-05,\n",
       "         VBN->based: 0.017554717830416924,\n",
       "         NNP->los: 0.0020640899943237525,\n",
       "         NNP->angeles: 0.0017415759327106663,\n",
       "         VBZ->makes: 0.00942998630281319,\n",
       "         VBZ->distributes: 0.0004741333895269202,\n",
       "         JJ->electronic: 0.0012062940164268862,\n",
       "         NN->computer: 0.002608866725401808,\n",
       "         NN->building: 0.0011889589338716438,\n",
       "         NNS->products: 0.008362231684298319,\n",
       "         NP+NNS->investors: 0.02375114924915722,\n",
       "         VBP->are: 0.3041486603284356,\n",
       "         VBG->VBG: 0.18639816540060197,\n",
       "         NNPS->securities: 0.06265769554247266,\n",
       "         NNP->exchange: 0.0057665514216419834,\n",
       "         NNP->commission: 0.001883482119820424,\n",
       "         RB->not: 0.08412337251927696,\n",
       "         VB->limit: 0.0010638733172388395,\n",
       "         PRP$->their: 0.20526251674990864,\n",
       "         NN->access: 0.00029937814881660096,\n",
       "         NP+NN->information: 0.002855639888780341,\n",
       "         NN->stock: 0.00954588611655219,\n",
       "         NNS->purchases: 0.001272990650103156,\n",
       "         JJ->corporate: 0.004594561033155346,\n",
       "         NNS->insiders: 0.00021948114656950967,\n",
       "         NNP->sec: 0.001109448371949017,\n",
       "         NN->proposal: 0.0017535005859258056,\n",
       "         VB->ease: 0.00180040099840419,\n",
       "         NN->reporting: 8.553661394760027e-05,\n",
       "         NNS->requirements: 0.0012290944207892542,\n",
       "         DT->some: 0.01550706561571794,\n",
       "         NN->company: 0.021016346046925385,\n",
       "         NNS->executives: 0.004016504982222027,\n",
       "         MD->would: 0.22564747824263395,\n",
       "         VB->undermine: 0.00028642743156430297,\n",
       "         IN->on: 0.05326402978518689,\n",
       "         NN->insider: 0.00017962688928996058,\n",
       "         NNS->trades: 0.0009437689302488916,\n",
       "         IN->as: 0.038957100127591036,\n",
       "         JJ->JJ: 0.16799418140533254,\n",
       "         NN->tool: 0.00017107322789520053,\n",
       "         JJ->individual: 0.0019158787319721133,\n",
       "         NNS->investors: 0.007813528817874544,\n",
       "         JJ->professional: 0.0006741054797679658,\n",
       "         NN->money: 0.0030108888109555295,\n",
       "         NNS->managers: 0.002765462446775822,\n",
       "         VP+VBP->contend: 0.00684931506849315,\n",
       "         NP+PRP->they: 0.13816453816453816,\n",
       "         VBP->make: 0.007951598962834918,\n",
       "         NN->argument: 0.00023950251905328077,\n",
       "         NP+NNS->letters: 0.0014557155991418939,\n",
       "         NN->agency: 0.0023950251905328077,\n",
       "         NN->rule: 0.0005132196836856016,\n",
       "         NNS->changes: 0.0035336464597691057,\n",
       "         VBD->proposed: 0.0011610486891385767,\n",
       "         DT->this: 0.022707693098970052,\n",
       "         JJ->past: 0.005126749569814266,\n",
       "         NN->summer: 0.0008040441711074425,\n",
       "         WHNP+IN->that: 1.0,\n",
       "         IN->among: 0.004277437302599929,\n",
       "         JJ->other: 0.025740185556403117,\n",
       "         NNS->things: 0.0022167595803520477,\n",
       "         VB->exempt: 0.0001227546135275584,\n",
       "         JJ->many: 0.0120274609284916,\n",
       "         VBG->reporting: 0.002078257130571879,\n",
       "         NP+NNS->trades: 0.0009193993257738277,\n",
       "         JJ->own: 0.006333043586241152,\n",
       "         NNS->companies: 0.015078354769325316,\n",
       "         POS->': 0.07029425502101821,\n",
       "         NNS->shares: 0.02291383170185681,\n",
       "         VBN->proposed: 0.007483261126427727,\n",
       "         ADVP+RB->also: 0.10477491730188408,\n",
       "         VB->allow: 0.004009984041900241,\n",
       "         NP+NNS->executives: 0.002375114924915722,\n",
       "         VB->report: 0.0033962109742624496,\n",
       "         NP+NNS->NNS: 0.1209776279497395,\n",
       "         NP+NNS->options: 0.002375114924915722,\n",
       "         ADVP+RBR->later: 0.05426356589147287,\n",
       "         RBR->less: 0.08533145275035262,\n",
       "         RB->often: 0.0026545316647705727,\n",
       "         NP+JJ->many: 0.29141716566866266,\n",
       "         NNS->letters: 0.00030727360519731354,\n",
       "         VBP->maintain: 0.0016421780466724287,\n",
       "         IN->that: 0.04512748645652492,\n",
       "         NN->investor: 0.0014199077915301645,\n",
       "         NN->confidence: 0.0002566098418428008,\n",
       "         ADVP+RB->so: 0.008197900186969653,\n",
       "         VBN->shaken: 0.00045012097001069035,\n",
       "         CD->1987: 0.004703406875638209,\n",
       "         NN->market: 0.015730183304963688,\n",
       "         NN->crash: 0.0007783831869231625,\n",
       "         :->--: 0.42748588797221015,\n",
       "         ADVP+RB->already: 0.020854307493168415,\n",
       "         IN->against: 0.005145474701416052,\n",
       "         JJ->little: 0.0034592254882829824,\n",
       "         NN->guy: 0.00021384153486900067,\n",
       "         DT->any: 0.008679327769991385,\n",
       "         NN->decrease: 5.987562976332019e-05,\n",
       "         NNS->patterns: 0.00021948114656950967,\n",
       "         MD->might: 0.0338680926916221,\n",
       "         VB->prompt: 0.0003273456360734891,\n",
       "         NP+NNS->individuals: 0.003600980692614159,\n",
       "         VB->get: 0.015507999508981546,\n",
       "         RB->out: 0.0024649222601441033,\n",
       "         NP+NNS->stocks: 0.017085504137296967,\n",
       "         ADVP+RB->altogether: 0.000934848266935136,\n",
       "         ADVP+RB->historically: 0.0006472026463397094,\n",
       "         VBN->paid: 0.006414223822652338,\n",
       "         NP+NN->NN: 0.10393026226797926,\n",
       "         NN->ideal: 4.2768306973800133e-05,\n",
       "         JJ->level: 3.547923577726136e-05,\n",
       "         NN->playing: 7.698295255284024e-05,\n",
       "         NN->field: 0.0005645416520541618,\n",
       "         VP+VBD->wrote: 0.004638577502899111,\n",
       "         NNP->s.: 0.0005934258733680789,\n",
       "         NP+NNP->ill.: 0.0009725261366399222,\n",
       "         NP+CD->one: 0.1336469286109574,\n",
       "         CD->92: 0.00027849119658384134,\n",
       "         VBN->received: 0.00410735385134755,\n",
       "         IN->since: 0.005574264259867389,\n",
       "         VBD->were: 0.06846441947565543,\n",
       "         NNP->aug.: 0.0006192269982971258,\n",
       "         CD->17: 0.0035894420893028437,\n",
       "         ADVP+RB->apparently: 0.005824823817057385,\n",
       "         NN->commission: 0.0005474343292646418,\n",
       "         VBD->did: 0.0199625468164794,\n",
       "         ADVP+RB->really: 0.00740687473033223,\n",
       "         VB->believe: 0.002168664838986865,\n",
       "         ADVP+RB->currently: 0.013303609952538473,\n",
       "         NNS->rules: 0.0023265001536368025,\n",
       "         VBP->force: 0.000432152117545376,\n",
       "         NP+NNS->directors: 0.0027581979773214833,\n",
       "         IN->within: 0.002028906691208768,\n",
       "         NN->month: 0.004293938020169533,\n",
       "         IN->after: 0.011043945700600305,\n",
       "         NN->transaction: 0.0014968907440830047,\n",
       "         CC->but: 0.1416584614067383,\n",
       "         CD->25: 0.007271714577466968,\n",
       "         NN->%: 0.04161356268550753,\n",
       "         VBG->according: 0.029453920022932494,\n",
       "         NNS->figures: 0.00272156621746192,\n",
       "         VBP->file: 0.0002592912705272256,\n",
       "         NNS->reports: 0.0019094859751547341,\n",
       "         ADVP+RB->late: 0.0014382281029771322,\n",
       "         NN->effort: 0.0013087101933982842,\n",
       "         VB->streamline: 0.0003682638405826752,\n",
       "         JJ->federal: 0.009100423976867538,\n",
       "         NN->bureaucracy: 0.00014541224371092046,\n",
       "         VB->boost: 0.002700601497606285,\n",
       "         NP+NN->compliance: 0.0009017810175095814,\n",
       "         WHNP+WP->who: 0.6968593536640874,\n",
       "         VBG->calling: 0.0025799054034685394,\n",
       "         VP+VBD->said: 0.6787785079242366,\n",
       "         NNP->brian: 0.000141906187109758,\n",
       "         NNP->lane: 0.000141906187109758,\n",
       "         JJ->special: 0.002714161536960494,\n",
       "         NN->counsel: 0.0002566098418428008,\n",
       "         NN->office: 0.002155522671479527,\n",
       "         NN->disclosure: 0.00016251956650044052,\n",
       "         NN->policy: 0.0020699860575319265,\n",
       "         WHNP+WDT->which: 0.5270069375619425,\n",
       "         NNS->officials: 0.009393793073175014,\n",
       "         VBD->had: 0.06131086142322097,\n",
       "         IN->until: 0.003116568010207283,\n",
       "         NP+NN->today: 0.01833621402269482,\n",
       "         VB->comment: 0.002659683293097099,\n",
       "         NNS->proposals: 0.0009876651595627935,\n",
       "         NN->issue: 0.0033102669597721303,\n",
       "         VBN->produced: 0.0026444606988128058,\n",
       "         JJR->more: 0.35389856169568507,\n",
       "         NN->mail: 0.00046189771531704145,\n",
       "         IN->than: 0.016231253529670146,\n",
       "         RB->almost: 0.01093414233345974,\n",
       "         NP+NN->memory: 0.00022544525437739535,\n",
       "         NNP->mr.: 0.052943908354404254,\n",
       "         ADVP+RB->probably: 0.009276571264202503,\n",
       "         VB->vote: 0.0013503007488031426,\n",
       "         RB->early: 0.0059410946782960435,\n",
       "         JJ->next: 0.008940767415869862,\n",
       "         NNP->committee: 0.0015480674957428144,\n",
       "         NNP->federal: 0.0037153619897827544,\n",
       "         NNP->regulation: 1.2900562464523454e-05,\n",
       "         NP+NNPS->securities: 0.00398406374501992,\n",
       "         NNP->american: 0.004502296300118685,\n",
       "         NNP->bar: 6.450281232261727e-05,\n",
       "         NNP->association: 0.002193095618968987,\n",
       "         VBZ->argues: 0.0008429038036034137,\n",
       "         NP+NN->example: 0.01307582475388893,\n",
       "         JJ->lengthy: 0.00015965656099767612,\n",
       "         NN->letter: 0.0007527222027388824,\n",
       "         ADVP+RB->substantially: 0.001653962318423702,\n",
       "         VB->improve: 0.0030279471336797743,\n",
       "         -LRB-->-lcb-: 0.1600609756097561,\n",
       "         NN->law: 0.0024206861747170876,\n",
       "         -RRB-->-rcb-: 0.16148597422289612,\n",
       "         RBR->more: 0.5119887165021156,\n",
       "         RB->closely: 0.00347617241815194,\n",
       "         JJ->contemporary: 0.00012417732522041475,\n",
       "         NN->business: 0.006449460691649061,\n",
       "         WHNP+WP->what: 0.2803823395539372,\n",
       "         VBP->oppose: 0.0010371650821089024,\n",
       "         VBP->VBP: 0.03258426966292135,\n",
       "         PP+TO->to: 1.0,\n",
       "         ADVP+RBS->most: 0.625,\n",
       "         VBZ->is: 0.35222842693077655,\n",
       "         NN->effect: 0.0007014002343703222,\n",
       "         VBP->say: 0.031201382886776145,\n",
       "         VB->have: 0.04374156062031998,\n",
       "         NN->ability: 0.0007099538957650823,\n",
       "         VB->spot: 0.0002455092270551168,\n",
       "         NN->trading: 0.007022556005097982,\n",
       "         NN->activity: 0.0008724734622655228,\n",
       "         NN->buying: 0.0007954905097126825,\n",
       "         CC->or: 0.10475619675499807,\n",
       "         NN->selling: 0.0007014002343703222,\n",
       "         CD->one: 0.03032459696135161,\n",
       "         NN->director: 0.0021469690100847667,\n",
       "         JJ->short: 0.0019513579677493747,\n",
       "         NN->period: 0.0023950251905328077,\n",
       "         NP+NN->time: 0.008416622830089426,\n",
       "         NNS->estimates: 0.0016022123699574206,\n",
       "         VB->cut: 0.004050902246409428,\n",
       "         NNS->filings: 0.0004170141784820684,\n",
       "         NP+JJR->more: 0.7712418300653595,\n",
       "         NN->third: 6.842929115808022e-05,\n",
       "         VBD->disputed: 0.000149812734082397,\n",
       "         DT->those: 0.004256085173136516,\n",
       "         VB->eliminate: 0.0011457097262572119,\n",
       "         NNS->divisions: 0.00068039155436548,\n",
       "         JJ->such: 0.014759362083340725,\n",
       "         NP+NNS->sales: 0.030646644192460926,\n",
       "         NP+NN->marketing: 0.0012775231081385736,\n",
       "         NP+NN->finance: 0.001502968362515969,\n",
       "         NN->research: 0.0014541224371092047,\n",
       "         NN->development: 0.0011205296427135635,\n",
       "         JJR->tougher: 0.004920514761544285,\n",
       "         ADVP+RB->still: 0.04062994390910398,\n",
       "         JJ->required: 0.00015965656099767612,\n",
       "         VB->file: 0.001227546135275584,\n",
       "         NP+NNS->reports: 0.0028348145878026357,\n",
       "         NP+NNS->companies: 0.011109408519767085,\n",
       "         VB->publish: 0.0007365276811653504,\n",
       "         JJ->annual: 0.004789696829930283,\n",
       "         NN->proxy: 6.842929115808022e-05,\n",
       "         NNS->statements: 0.0005925990957376761,\n",
       "         NNS->names: 0.0008340283569641367,\n",
       "         NP+NNS->insiders: 0.0003830830524057616,\n",
       "         VBP->fail: 0.00034572169403630077,\n",
       "         VBN->considered: 0.004276149215101559,\n",
       "         NN->whole: 0.0001967342120794806,\n",
       "         VBN->required: 0.00410735385134755,\n",
       "         IN->under: 0.006860632935221402,\n",
       "         RBS->least: 0.017857142857142856,\n",
       "         JJ->effective: 0.0012062940164268862,\n",
       "         IN->if: 0.011859691689849192,\n",
       "         RB->so: 0.030400707875110605,\n",
       "         VBG->following: 0.009961301418947972,\n",
       "         NP+NNS->transactions: 0.0009193993257738277,\n",
       "         NNP->robert: 0.0026059136178337374,\n",
       "         NNP->north: 0.0013545590587749625,\n",
       "         NNP->miami: 0.00012900562464523453,\n",
       "         NNP->fla.: 7.740337478714073e-05,\n",
       "         WHNP+WDT->that: 0.4672943508424182,\n",
       "         VBZ->packages: 0.00010536297545042672,\n",
       "         VBZ->sells: 0.0022653039721841745,\n",
       "         NNS->data: 0.0022387076950089986,\n",
       "         RB->RB: 0.03362406775376059,\n",
       "         JJ->key: 0.0014723882847563464,\n",
       "         MD->may: 0.08252070881828667,\n",
       "         VB->fail: 0.0003682638405826752,\n",
       "         VBD->wrote: 0.0016853932584269663,\n",
       "         VBG->asking: 0.0026515694424537766,\n",
       "         VB->require: 0.0022914194525144238,\n",
       "         ADVP+RB->immediately: 0.004098950093484826,\n",
       "         RB->later: 0.006004297813171533,\n",
       "         VBP->want: 0.014088159031979257,\n",
       "         VB->change: 0.002659683293097099,\n",
       "         NN->timing: 0.00016251956650044052,\n",
       "         MD->should: 0.04477298940966761,\n",
       "         VB->write: 0.0013503007488031426,\n",
       "         NNS->representatives: 0.0005487028664237742,\n",
       "         NP+NNP->congress: 0.020666180403598345,\n",
       "         VP+VBD->added: 0.028991109393119444,\n",
       "         ADVP+RB->likely: 0.0017977851287214151,\n",
       "         NP+NN->legislation: 0.002479897798151349,\n",
       "         VBD->required: 0.0005617977528089888,\n",
       "         JJ->timely: 0.00012417732522041475,\n",
       "         NN->basis: 0.0010777613357397635,\n",
       "         NN->nation: 0.0016679639719782053,\n",
       "         JJS->largest: 0.13848920863309352,\n",
       "         NN->pension: 0.0006671855887912822,\n",
       "         NN->fund: 0.0019673421207948064,\n",
       "         VBZ->oversees: 0.0006848593404277737,\n",
       "         $->$: 0.9759350935093509,\n",
       "         CD->80: 0.0028777423646996936,\n",
       "         CD->billion: 0.054212952934987776,\n",
       "         NN->college: 0.00030793181021136095,\n",
       "         NNS->employees: 0.0031824766252578902,\n",
       "         VBZ->plans: 0.008903171425561058,\n",
       "         VB->offer: 0.003559883792299194,\n",
       "         CD->two: 0.03233592227001269,\n",
       "         NN->investment: 0.004122864792274333,\n",
       "         NNS->options: 0.0028313067907466748,\n",
       "         CD->1.2: 0.0015781167806417674,\n",
       "         CD->million: 0.13401615248940185,\n",
       "         NNS->participants: 0.0005487028664237742,\n",
       "         NNPS->teachers: 0.00042052144659377626,\n",
       "         NNP->insurance: 0.0009804427473037824,\n",
       "         NNP->retirement: 0.00010320449971618763,\n",
       "         NNPS->equities: 0.00042052144659377626,\n",
       "         NNP->fund: 0.0009804427473037824,\n",
       "         VB->introduce: 0.001186627930766398,\n",
       "         NN->bond: 0.0023950251905328077,\n",
       "         VB->invest: 0.0014321371578215147,\n",
       "         JJ->responsible: 0.0008515016586542726,\n",
       "         DT->both: 0.004731840917565674,\n",
       "         NNS->funds: 0.007791580703217594,\n",
       "         VBN->expected: 0.020424239014235075,\n",
       "         VB->begin: 0.0042964114734645445,\n",
       "         NP+NN->operation: 0.0009017810175095814,\n",
       "         IN->around: 0.0017465330795456923,\n",
       "         NNP->march: 0.0014061613086330564,\n",
       "         CD->1: 0.018101927777949688,\n",
       "         JJ->subject: 0.0011353355448723635,\n",
       "         NN->approval: 0.0008040441711074425,\n",
       "         VB->sign: 0.0008183640901837227,\n",
       "         PRT+RP->up: 0.3461697722567288,\n",
       "         MD->must: 0.02516514627241271,\n",
       "         VB->approve: 0.0010229551127296534,\n",
       "         NN->plan: 0.003566876801614931,\n",
       "         NNS->institutions: 0.0018436416311838812,\n",
       "         NP+NN->part: 0.020966408657097767,\n",
       "         VBP->carry: 0.0016421780466724287,\n",
       "         PRT+RP->out: 0.220703933747412,\n",
       "         NN->agreement: 0.002540437434243728,\n",
       "         NN->pressure: 0.000607309959027962,\n",
       "         VB->relax: 0.00020459102254593068,\n",
       "         JJ->strict: 0.0002660942683294602,\n",
       "         NN->participation: 0.0001967342120794806,\n",
       "         VB->provide: 0.006219567085396293,\n",
       "         VBN->reached: 0.004613739942609577,\n",
       "         IN->with: 0.04486602940868874,\n",
       "         NP+NNP->december: 0.0025934030310397925,\n",
       "         JJ->social: 0.0007628035692111192,\n",
       "         NN->choice: 0.00029937814881660096,\n",
       "         VB->VB: 0.07492123245631982,\n",
       "         NP+NNS->securities: 0.002221881703953417,\n",
       "         VBN->linked: 0.0012378326675293984,\n",
       "         NNP->south: 0.001909283244749471,\n",
       "         NNP->africa: 0.0005547241859745085,\n",
       "         JJ->nuclear: 0.0008160224228770112,\n",
       "         NN->power: 0.001608088342214885,\n",
       "         NNS->cases: 0.0025020850708924102,\n",
       "         NNP->northern: 0.000425718561329274,\n",
       "         NNP->ireland: 6.450281232261727e-05,\n",
       "         VP+VBN->VBN: 0.16216216216216217,\n",
       "         VP+VB->be: 0.025356576862123614,\n",
       "         NP+NNS->investments: 0.0018387986515476554,\n",
       "         JJ->significant: 0.0018449202604175906,\n",
       "         VBG->stemming: 0.001003296545793321,\n",
       "         NNS->weapons: 0.0006145472103946271,\n",
       "         NN->manufacture: 2.566098418428008e-05,\n",
       "         NP+NN->tobacco: 0.00022544525437739535,\n",
       "         NN->percent: 0.00013685858231616044,\n",
       "         VBN->invested: 0.0012940977887807349,\n",
       "         NN->rest: 0.0007270612185546024,\n",
       "         VBG->going: 0.02135588361760069,\n",
       "         IN->into: 0.009339245748708402,\n",
       "         NP+NNS->bonds: 0.006895494943303708,\n",
       "         JJ->short-term: 0.0016852636994199146,\n",
       "         NNS->investments: 0.00204117466309644,\n",
       "         JJ->high-grade: 0.0002838338862180909,\n",
       "         NNS->bonds: 0.011917826258724376,\n",
       "         NP+NNS->mortgages: 0.00045969966288691386,\n",
       "         JJ->asset-backed: 0.0005499281545475511,\n",
       "         NNS->securities: 0.008647557174838682,\n",
       "         VBG->including: 0.02981224021785868,\n",
       "         JJ->as: 1.773961788863068e-05,\n",
       "         RB->much: 0.015737580583996966,\n",
       "         JJ->foreign: 0.0058895531390253855,\n",
       "         VB->buy: 0.014812390032325382,\n",
       "         VB->sell: 0.015180653872908057,\n",
       "         NNS->futures: 0.0049602739124709186,\n",
       "         NNS->contracts: 0.0028752030200605767,\n",
       "         NP+NN->approval: 0.0033816788156609302,\n",
       "         NNP->new: 0.014577635584911501,\n",
       "         NNP->york: 0.011339594406316116,\n",
       "         NNP->state: 0.001109448371949017,\n",
       "         NNP->department: 0.0028381237421951596,\n",
       "         NNS->features: 0.0003950660638251174,\n",
       "         NP+NNS->participants: 0.0008427827152926755,\n",
       "         JJ->able: 0.003193131219953522,\n",
       "         VB->transfer: 0.0008592822946929089,\n",
       "         NP+NN->money: 0.012174043736379349,\n",
       "         NNS->jobs: 0.0011632500768184013,\n",
       "         VP+VBN->terminated: 0.0018856065367693275,\n",
       "         VB->receive: 0.0037235566103359383,\n",
       "         NP+NN->cash: 0.00871721650259262,\n",
       "         NNS->choices: 0.00028532549054036257,\n",
       "         VBN->offered: 0.006132898216395656,\n",
       "         VBN->limited: 0.001913014122545434,\n",
       "         NN->money-market: 5.987562976332019e-05,\n",
       "         NNP->scientific: 0.00010320449971618763,\n",
       "         NNP->co.: 0.011558903968213014,\n",
       "         NN->biotechnology: 0.0002223951962637607,\n",
       "         NN->equipment: 0.0013001565320035241,\n",
       "         VBD->adopted: 0.0007116104868913857,\n",
       "         JJ->anti-takeover: 0.00012417732522041475,\n",
       "         VBG->giving: 0.0045148344560699445,\n",
       "         NP+NNS->shareholders: 0.005746245786086424,\n",
       "         NN->right: 0.0007698295255284025,\n",
       "         VB->purchase: 0.002373255861532796,\n",
       "         NP+NNS->shares: 0.00796812749003984,\n",
       "         JJ->half: 0.0002838338862180909,\n",
       "         NN->price: 0.005662523843331138,\n",
       "         JJ->certain: 0.0037253197566124428,\n",
       "         NNS->conditions: 0.0016680567139282735,\n",
       "         NP+NN->review: 0.0009769294356353798,\n",
       "         NN->time: 0.005226287112198377,\n",
       "         VB->protect: 0.0020459102254593068,\n",
       "         NN->takeover: 0.0019758957821895662,\n",
       "         NNS->tactics: 0.00021948114656950967,\n",
       "         NNP->w.: 0.0007224314980133134,\n",
       "         NNP->ed: 0.00010320449971618763,\n",
       "         CD->37: 0.0013305690503450196,\n",
       "         NNS->years: 0.023330845880338878,\n",
       "         JJ->old: 0.004026893260719164,\n",
       "         JJ->senior: 0.004044632878607794,\n",
       "         NN->vice: 0.0030707644407188496,\n",
       "         NN->president: 0.0045762088461966145,\n",
       "         VBG->printing: 0.0002149921169557116,\n",
       "         NN->concern: 0.002566098418428008,\n",
       "         VBN->elected: 0.0034321723963315143,\n",
       "         NN->technology: 0.0013258175161878043,\n",
       "         NN->group: 0.005431574985672617,\n",
       "         NN->position: 0.001616642003609645,\n",
       "         JJ->solo: 3.547923577726136e-05,\n",
       "         NNS->players: 0.0010315613888766955,\n",
       "         VBP->have: 0.16257562662057043,\n",
       "         ADJP+JJ->creative: 0.00035174111853675694,\n",
       "         VB->work: 0.002987028929170588,\n",
       "         NN->lot: 0.001548212712451565,\n",
       "         IN->because: 0.01041644878579347,\n",
       "         NN->audience: 0.0003934684241589612,\n",
       "         NN->appeal: 0.00030793181021136095,\n",
       "         ADJP+JJ->limited: 0.0017587055926837848,\n",
       "         VBN->taken: 0.007877116975187082,\n",
       "         JJ->hard: 0.001383690195313193,\n",
       "         NN->line: 0.0013942468073458844,\n",
       "         NN->problem: 0.001890359168241966,\n",
       "         :->:: 0.28289188015631783,\n",
       "         VP+VBZ->commissions: 0.00045871559633027525,\n",
       "         VBZ->VBZ: 0.0674323042882731,\n",
       "         NNS->scores: 0.0001316886879417058,\n",
       "         VBZ->does: 0.024075439890422507,\n",
       "         NN->conducting: 8.553661394760028e-06,\n",
       "         IN->so: 0.001453701185969169,\n",
       "         VB->play: 0.0020049920209501207,\n",
       "         JJ->same: 0.0052686665129233114,\n",
       "         RB->over: 0.0010112501580078373,\n",
       "         ADVP+RB->again: 0.01121817920322163,\n",
       "         NNP->richard: 0.0014964652458847206,\n",
       "         NNP->stoltzman: 0.00012900562464523453,\n",
       "         JJR->JJR: 0.052611657834973506,\n",
       "         NN->approach: 0.00048755869950132153,\n",
       "         NP+NNS->years: 0.007431811216671774,\n",
       "         RB->ago: 0.02104664391353811,\n",
       "         VBD->VBD: 0.04895131086142322,\n",
       "         NN->music: 0.0003763611013694412,\n",
       "         NNP->peter: 0.0010320449971618763,\n",
       "         NNP->fred: 0.00010320449971618763,\n",
       "         RB->very: 0.02193148780179497,\n",
       "         NN->chamber: 0.00014541224371092046,\n",
       "         VBD->won: 0.0022471910112359553,\n",
       "         NP+NNS->audiences: 0.00030646644192460924,\n",
       "         RP->over: 0.024096385542168676,\n",
       "         IN->like: 0.004266979020686482,\n",
       "         NN->end: 0.002583205741217528,\n",
       "         ADVP+RB->mostly: 0.003164101826549691,\n",
       "         VBN->dropped: 0.0010127721825240533,\n",
       "         NN->work: 0.0017107322789520053,\n",
       "         IN->though: 0.002311280302871844,\n",
       "         NN->touch: 5.132196836856016e-05,\n",
       "         VP+VBZ->VBZ: 0.062385321100917435,\n",
       "         ADVP+RB->now: 0.050625629224795056,\n",
       "         VBZ->goes: 0.002897481824886735,\n",
       "         NN->road: 0.00035925377857992115,\n",
       "         NP+NN->bass: 7.514841812579845e-05,\n",
       "         NN->slide: 0.000316485471606121,\n",
       "         NN->show: 0.0006757392501860421,\n",
       "         VBZ->ranges: 0.00021072595090085343,\n",
       "         JJ->light: 0.0006031470082134431,\n",
       "         NN->jazz: 5.987562976332019e-05,\n",
       "         NN->pop: 6.842929115808022e-05,\n",
       "         JJ->few: 0.005925032374802647,\n",
       "         NNS->exceptions: 0.00015363680259865677,\n",
       "         RB->just: 0.019908987485779295,\n",
       "         NN->thing: 0.000949456414818363,\n",
       "         NN->set: 0.000316485471606121,\n",
       "         VBN->embraced: 0.00039385584875935406,\n",
       "         NNP->age: 3.870168739357036e-05,\n",
       "         JJ->easy: 0.0005321885366589204,\n",
       "         NN->listening: 2.566098418428008e-05,\n",
       "         NP+PRP->you: 0.04235224235224235,\n",
       "         MD->ca: 0.020027262241795112,\n",
       "         PRP$->his: 0.21549518820806432,\n",
       "         RB->as: 0.04828719504487423,\n",
       "         RB->merely: 0.0005688282138794084,\n",
       "         JJ->commercial: 0.0029447765695126927,\n",
       "         VBZ->believes: 0.004161837530291855,\n",
       "         VP+VBZ->plays: 0.0009174311926605505,\n",
       "         JJ->recent: 0.007539337602668039,\n",
       "         NN->appearance: 0.00011119759813188036,\n",
       "         NNP->metropolitan: 0.00023221012436142215,\n",
       "         NNP->museum: 0.00012900562464523453,\n",
       "         VBN->dubbed: 0.0007314465762673719,\n",
       "         JJ->musical: 0.00017739617888630678,\n",
       "         NN->case: 0.002583205741217528,\n",
       "         NP+NN->point: 0.00022544525437739535,\n",
       "         VBD->felt: 0.0015730337078651685,\n",
       "         ADVP+RBR->more: 0.1744186046511628,\n",
       "         NN->party: 0.0007869368483179224,\n",
       "         RB->highly: 0.004550625711035267,\n",
       "         NN->session: 0.0007612758641336424,\n",
       "         NNS->friends: 0.0004609104077959703,\n",
       "         JJ->black: 0.001933618349860744,\n",
       "         NN->suit: 0.0011718516110821237,\n",
       "         VBD->announced: 0.005580524344569289,\n",
       "         JJ->inner: 0.00019513579677493746,\n",
       "         NNS->voices: 0.0002633773758834116,\n",
       "         ADVP+RB->just: 0.017905939882065295,\n",
       "         VP+VBN->released: 0.0043997485857950975,\n",
       "         NN->family: 0.0011889589338716438,\n",
       "         NN->front: 0.00011119759813188036,\n",
       "         NN->row: 0.00014541224371092046,\n",
       "         NN->mother: 0.0002822708260270809,\n",
       "         PRP$->her: 0.03800706541600682,\n",
       "         JJ->favorite: 0.00031931312199535224,\n",
       "         VBD->launched: 0.0008614232209737827,\n",
       "         NP+NN->carnival: 7.514841812579845e-05,\n",
       "         NNS->animals: 0.00015363680259865677,\n",
       "         NN->piece: 0.00036780743997468114,\n",
       "         NN->tone: 0.00020528787347424065,\n",
       "         DT->no: 0.008666469506628435,\n",
       "         RB->then: 0.005877891543420554,\n",
       "         VB->show: 0.003355292769753263,\n",
       "         MD->could: 0.10936353150886023,\n",
       "         ADVP+RB->fast: 0.0006472026463397094,\n",
       "         RB->well: 0.017380862090759702,\n",
       "         VBD->offered: 0.0024719101123595504,\n",
       "         JJ->second: 0.004541342179489454,\n",
       "         NN->movement: 0.0003763611013694412,\n",
       "         VBD->reflected: 0.001348314606741573,\n",
       "         NN->side: 0.0007527222027388824,\n",
       "         VBD->went: 0.004456928838951311,\n",
       "         IN->through: 0.005657930515174967,\n",
       "         JJ->first: 0.0135885473026911,\n",
       "         NN->half: 0.000966563737607883,\n",
       "         VBN->chosen: 0.0007314465762673719,\n",
       "         NP+NNS->pieces: 0.0006129328838492185,\n",
       "         NP+NN->none: 0.0033065303975351318,\n",
       "         JJR->longer: 0.00984102952308857,\n",
       "         CD->five: 0.010520778537611783,\n",
       "         NNS->minutes: 0.001382731223387911,\n",
       "         VB->challenge: 0.0004910184541102336,\n",
       "         VBD->introduced: 0.0010861423220973783,\n",
       "         NNS->colleagues: 0.000658443439708529,\n",
       "         NNP->bill: 0.0005031219361164147,\n",
       "         NNP->douglas: 0.00047732081118736776,\n",
       "         NN->buddy: 1.7107322789520055e-05,\n",
       "         NP+NNP->yale: 0.0004862630683199611,\n",
       "         NNP->eddie: 0.00011610506218071107,\n",
       "         NN->section: 0.0004961123608960815,\n",
       "         VBN->built: 0.003600967760085523,\n",
       "         NN->beginning: 0.000316485471606121,\n",
       "         JJ->golden: 0.00044349044721576697,\n",
       "         NN->rain: 9.40902753423603e-05,\n",
       "         NN->lead: 0.0002822708260270809,\n",
       "         NX+NN->sky: 0.007042253521126761,\n",
       "         VBD->gave: 0.00299625468164794,\n",
       "         NN->opportunity: 0.00048755869950132153,\n",
       "         JJ->high: 0.004931613773039328,\n",
       "         NN->register: 8.553661394760028e-06,\n",
       "         PRT+RP->off: 0.115527950310559,\n",
       "         JJ->fleet: 1.773961788863068e-05,\n",
       "         NNS->fingers: 0.00010974057328475484,\n",
       "         NX+NN->air: 0.007042253521126761,\n",
       "         VP+VBD->followed: 0.0015461925009663702,\n",
       "         VBD->tied: 0.00026217228464419474,\n",
       "         PRT+RP->in: 0.06542443064182195,\n",
       "         NP+PRP->him: 0.020255420255420254,\n",
       "         JJ->great: 0.0020400560571925282,\n",
       "         NN->century: 0.00042768306973800133,\n",
       "         VBD->built: 0.00044943820224719103,\n",
       "         NN->image: 0.0006158636204227219,\n",
       "         VBG->joining: 0.001719936935645693,\n",
       "         JJ->two-part: 0.00015965656099767612,\n",
       "         VBN->arranged: 0.0005063860912620266,\n",
       "         VBG->keeping: 0.0030098896373799626,\n",
       "         NN->mood: 0.00016251956650044052,\n",
       "         ADJP+JJ->light: 0.0007034822370735139,\n",
       "         ADVP+RB->then: 0.019847547821084423,\n",
       "         NN->way: 0.0029852278267712496,\n",
       "         NN->alternative: 0.00023094885765852073,\n",
       "         JJ->dry: 0.00014191694310904544,\n",
       "         NNS->techniques: 0.00017558491725560774,\n",
       "         VP+VBD->soared: 0.0011596443757247777,\n",
       "         JJ->tight: 0.00030157350410672156,\n",
       "         ADVP+RB->however: 0.027829713792607506,\n",
       "         VBD->brought: 0.00149812734082397,\n",
       "         NN->crowd: 0.00016251956650044052,\n",
       "         VBD->seemed: 0.00149812734082397,\n",
       "         VBG->waiting: 0.003869858105202809,\n",
       "         PP+IN->for: 0.14027149321266968,\n",
       "         NN->singer: 8.553661394760027e-05,\n",
       "         NNP->collins: 0.00010320449971618763,\n",
       "         VBZ->appears: 0.0035823411653145083,\n",
       "         JJ->glamorous: 0.00014191694310904544,\n",
       "         ADVP+RB->ever: 0.006759672083992521,\n",
       "         NNP->mitchell: 0.00045151968625832084,\n",
       "         ADJP+RB->free: 0.03260869565217391,\n",
       "         VBD->contributed: 0.0024344569288389513,\n",
       "         NN->setting: 7.698295255284024e-05,\n",
       "         JJ->deep: 0.0004080112114385056,\n",
       "         NN->peace: 0.00017962688928996058,\n",
       "         VBD->featured: 0.000149812734082397,\n",
       "         NNS->images: 0.0001975330319125587,\n",
       "         FW->FW: 0.44041450777202074,\n",
       "         RB->all: 0.002148906585766654,\n",
       "         RB->too: 0.015484768044495006,\n",
       "         VP+VBN->believed: 0.00251414204902577,\n",
       "         VBN->gotten: 0.0012378326675293984,\n",
       "         PRT+RP->away: 0.016563146997929608,\n",
       "         VB->add: 0.0027415197021154712,\n",
       "         JJ->amazing: 8.869808944315339e-05,\n",
       "         NN->grace: 4.2768306973800133e-05,\n",
       "         VB->ask: 0.00180040099840419,\n",
       "         NP+WDT->that: 0.9615384615384616,\n",
       "         IN->over: 0.007446296722374448,\n",
       "         JJ->warm: 0.00017739617888630678,\n",
       "         NNS->feelings: 0.0001975330319125587,\n",
       "         NP+DT->this: 0.21071115013169447,\n",
       "         WHADVP+WRB->why: 0.06417112299465241,\n",
       "         NP+DT->some: 0.1488147497805092,\n",
       "         IN->before: 0.005030433600368132,\n",
       "         IN->during: 0.004455228095128532,\n",
       "         .->?: 0.00949603901633422,\n",
       "         VP+VBN->gone: 0.0031426775612822125,\n",
       "         DT->either: 0.0005529053246068586,\n",
       "         RBS->most: 0.9464285714285714,\n",
       "         JJ->substantial: 0.0013482109595359317,\n",
       "         NN->evening: 0.00017107322789520053,\n",
       "         NNP->steve: 0.0002709118117549925,\n",
       "         NN->series: 0.0010777613357397635,\n",
       "         NNS->works: 0.0005048066371098722,\n",
       "         JJ->live: 0.0002483546504408295,\n",
       "         JJ->recorded: 5.3218853665892035e-05,\n",
       "         NNS->tracks: 0.00015363680259865677,\n",
       "         JJ->different: 0.002022316439303897,\n",
       "         NNS->trains: 0.00015363680259865677,\n",
       "         NN->string: 0.00011975125952664038,\n",
       "         VBZ->uses: 0.0018438520703824676,\n",
       "         NN->technique: 0.00023094885765852073,\n",
       "         VBN->worried: 0.001125302425026726,\n",
       "         VB->take: 0.014485044396251893,\n",
       "         VBD->warned: 0.001048689138576779,\n",
       "         NP+PRP->us: 0.01092961092961093,\n",
       "         NP+NN->advance: 0.0012023746900127752,\n",
       "         CD->11: 0.006745675650586379,\n",
       "         CD->1\\/2: 0.0075502057740508095,\n",
       "         ADVP+RB->unfortunately: 0.0015101395081259887,\n",
       "         VBD->illustrated: 7.49063670411985e-05,\n",
       "         NN->structure: 0.0004704513767118015,\n",
       "         NN->execution: 0.00011119759813188036,\n",
       "         JJ->straight: 0.0002660942683294602,\n",
       "         NNS->sounds: 6.58443439708529e-05,\n",
       "         VBN->written: 0.002081809486299443,\n",
       "         NNP->charlie: 0.00010320449971618763,\n",
       "         NNP->parker: 0.00020640899943237526,\n",
       "         NNP->coleman: 0.00010320449971618763,\n",
       "         NP+NNS->pictures: 0.00045969966288691386,\n",
       "         NNS->pieces: 0.0003292217198542645,\n",
       "         ADJP+JJ->JJ: 0.2254660569820612,\n",
       "         VB->hear: 0.0010229551127296534,\n",
       "         IN->without: 0.002834194398544207,\n",
       "         VBG->having: 0.009674645263007023,\n",
       "         VB->sit: 0.0004501002496010475,\n",
       "         NN->club: 0.0001967342120794806,\n",
       "         NP+JJ->much: 0.17964071856287425,\n",
       "         VP+VB->take: 0.0071315372424722665,\n",
       "         RB->ultimately: 0.00018960940462646946,\n",
       "         NN->future: 0.0006928465729755622,\n",
       "         VBP->insist: 0.00216076058772688,\n",
       "         NN->sell: 0.00017107322789520053,\n",
       "         MD->can: 0.09269162210338681,\n",
       "         VB->enjoy: 0.0004501002496010475,\n",
       "         NP+PRP->them: 0.03861003861003861,\n",
       "         RB->only: 0.03533055239539881,\n",
       "         JJ->threatening: 7.095847155452272e-05,\n",
       "         NNS->elements: 0.00017558491725560774,\n",
       "         VBN->served: 0.0012378326675293984,\n",
       "         VBN->accompanied: 0.0006751814550160356,\n",
       "         VBZ->'s: 0.06237488146665262,\n",
       "         ADJP+JJ->next: 0.0007034822370735139,\n",
       "         VB->illustrate: 8.183640901837228e-05,\n",
       "         ADVP+RB->certainly: 0.00424277290378254,\n",
       "         NP+NNS->thanks: 0.0010726325467361323,\n",
       "         NN->level: 0.0017021786175572453,\n",
       "         NP+NN->performance: 0.0009769294356353798,\n",
       "         JJ->obvious: 0.0004257508293271363,\n",
       "         RB->neither: 0.0002528125395019593,\n",
       "         CC->nor: 0.002739843315210411,\n",
       "         JJ->lasting: 8.869808944315339e-05,\n",
       "         NN->entertainment: 0.00030793181021136095,\n",
       "         NN->substitute: 5.987562976332019e-05,\n",
       "         NN->writer: 0.00021384153486900067,\n",
       "         NNP->ronald: 0.0002709118117549925,\n",
       "         NNP->reagan: 0.0009804427473037824,\n",
       "         NP+NNP->president: 0.0004862630683199611,\n",
       "         ADVP+RB->rarely: 0.0011505824823817058,\n",
       "         NP+NN->consensus: 0.0004508905087547907,\n",
       "         JJ->various: 0.0015078675205336077,\n",
       "         JJ->international: 0.002749640772737755,\n",
       "         NP+NN->fact: 0.006087021868189674,\n",
       "         NN->world: 0.0024121325133223278,\n",
       "         JJ->corrupt: 8.869808944315339e-05,\n",
       "         NNS->organizations: 0.0006145472103946271,\n",
       "         NP+NNP->unesco: 0.0004862630683199611,\n",
       "         NNP->u.n.: 0.00018060787450332834,\n",
       "         VBD->managed: 0.0009737827715355805,\n",
       "         NN->charter: 0.00015396590510568048,\n",
       "         VBG->promoting: 0.0012182886627490326,\n",
       "         NN->education: 0.0002908244874218409,\n",
       "         NN->science: 0.00011975125952664038,\n",
       "         NN->culture: 0.00032503913300088104,\n",
       "         RB->ever: 0.0017696877765137151,\n",
       "         VBG->remaining: 0.003941522144188046,\n",
       "         NNS->members: 0.0035994908037399586,\n",
       "         JJ->desperate: 0.00014191694310904544,\n",
       "         NNP->united: 0.002193095618968987,\n",
       "         NNPS->states: 0.010513036164844407,\n",
       "         NNP->unesco: 2.5801124929046907e-05,\n",
       "         VBG->lobbying: 0.0007883044288376093,\n",
       "         NNP->president: 0.00321224005366634,\n",
       "         NNP->bush: 0.004050776613860364,\n",
       "         NN->decision: 0.001608088342214885,\n",
       "         VP+VB->VB: 0.10538827258320127,\n",
       "         NP+PRP->we: 0.077992277992278,\n",
       "         VB->think: 0.004501002496010475,\n",
       "         NNS->reasons: 0.0009218208155919406,\n",
       "         VB->stay: 0.002168664838986865,\n",
       "         ADJP+RB->out: 0.03260869565217391,\n",
       "         IN->beyond: 0.0007529962977682026,\n",
       "         IN->along: 0.0010772030370850678,\n",
       "         NNP->singapore: 0.00021930956189689872,\n",
       "         VBD->left: 0.0023220973782771535,\n",
       "         WHADVP+WRB->when: 0.6256684491978609,\n",
       "         JJ->financial: 0.008160224228770113,\n",
       "         NN->corruption: 5.987562976332019e-05,\n",
       "         JJ->top: 0.002536765358074187,\n",
       "         NN->leadership: 0.0004105757469484813,\n",
       "         VBD->got: 0.005318352059925094,\n",
       "         IN->out: 0.0032106925474283086,\n",
       "         NP+NN->hand: 0.0021041557075223566,\n",
       "         JJ->personal: 0.0025190257401855563,\n",
       "         NNP->director: 0.00025801124929046907,\n",
       "         VBD->drew: 0.000749063670411985,\n",
       "         JJ->much: 0.004860655301484806,\n",
       "         NN->attention: 0.0004362367311327614,\n",
       "         NP+JJ->several: 0.033932135728542916,\n",
       "         NNS->aides: 0.00043896229313901934,\n",
       "         VBN->uncovered: 0.0002813256062566815,\n",
       "         NNP->kgb: 0.00010320449971618763,\n",
       "         NNS->plants: 0.002128967121724244,\n",
       "         NP+NNP->france: 0.0036469730123997084,\n",
       "         NN->fire: 0.0002822708260270809,\n",
       "         VBN->set: 0.006189163337646993,\n",
       "         VBD->sent: 0.002397003745318352,\n",
       "         NP+NNS->accountants: 0.0003830830524057616,\n",
       "         JJ->extreme: 0.00015965656099767612,\n",
       "         RB->even: 0.029768676526355706,\n",
       "         NN->replacement: 0.00017107322789520053,\n",
       "         RB->personally: 0.00018960940462646946,\n",
       "         JJ->spanish: 0.0002660942683294602,\n",
       "         NNP->mayor: 0.00029671293668403944,\n",
       "         VBN->had: 0.004332414336352895,\n",
       "         NN->success: 0.0004362367311327614,\n",
       "         NP+NNS->reforms: 0.00045969966288691386,\n",
       "         JJ->several: 0.006368522822018414,\n",
       "         JJ->ridiculous: 7.095847155452272e-05,\n",
       "         NNS->projects: 0.002107019007067293,\n",
       "         VBP->continue: 0.004062229904926534,\n",
       "         JJ->economic: 0.005942771992691278,\n",
       "         NN->order: 0.0014199077915301645,\n",
       "         VBZ->means: 0.004741333895269202,\n",
       "         NNP->west: 0.0024253057433304094,\n",
       "         VB->pay: 0.011047915217480256,\n",
       "         NN->everyone: 0.00017962688928996058,\n",
       "         RB->else: 0.002528125395019593,\n",
       "         NN->information: 0.0010948686585292835,\n",
       "         VB->give: 0.007692622447726994,\n",
       "         NN->government: 0.0063553704163067,\n",
       "         NP+NNS->rights: 0.0017621820410665032,\n",
       "         NN->press: 0.0005645416520541618,\n",
       "         :->;: 0.23643074250976986,\n",
       "         NP+NNS->journalists: 0.0006129328838492185,\n",
       "         NN->licensing: 4.2768306973800133e-05,\n",
       "         NNS->powers: 0.00037311794916816644,\n",
       "         RB->indeed: 0.0003160156743774491,\n",
       "         NNS->duties: 0.0004609104077959703,\n",
       "         VB->block: 0.0015958099758582593,\n",
       "         NP+NN->printing: 7.514841812579845e-05,\n",
       "         JJ->wrong: 0.0006208866261020738,\n",
       "         NNS->ideas: 0.0004609104077959703,\n",
       "         ADVP+RB->somehow: 0.0008629368617862793,\n",
       "         VBD->converted: 0.000149812734082397,\n",
       "         JJ->founding: 3.547923577726136e-05,\n",
       "         NNS->rights: 0.0031824766252578902,\n",
       "         NN->liberty: 8.553661394760028e-06,\n",
       "         NNS->peoples: 8.779245862780387e-05,\n",
       "         VBN->held: 0.007820851853935745,\n",
       "         NP+NNS->subjects: 0.00022984983144345693,\n",
       "         JJ->ethical: 0.00012417732522041475,\n",
       "         NNS->responsibilities: 0.0003292217198542645,\n",
       "         NP+NNS->scientists: 0.00199203187250996,\n",
       "         NP+NN->support: 0.0032313819794093333,\n",
       "         NN->impact: 0.000966563737607883,\n",
       "         NNS->activities: 0.0016241604846143716,\n",
       "         NNS->corporations: 0.0008779245862780387,\n",
       "         RB->totally: 0.0012008595626343066,\n",
       "         NNS->principles: 0.00021948114656950967,\n",
       "         NN->founding: 3.421464557904011e-05,\n",
       "         NNPS->soviets: 0.01682085786375105,\n",
       "         VBP->wonder: 0.0012100259291270526,\n",
       "         NP+FW->glasnost: 0.3076923076923077,\n",
       "         RB->partly: 0.001453672102136266,\n",
       "         NNP->soviet: 0.0014577635584911502,\n",
       "         NNP->foreign: 0.00043861912379379743,\n",
       "         NNP->minister: 0.0007353320604778368,\n",
       "         NNP->shevardnadze: 0.00016770731203880488,\n",
       "         VBD->admitted: 0.0003745318352059925,\n",
       "         JJ->ideological: 0.00015965656099767612,\n",
       "         VBG->holding: 0.009889637379962735,\n",
       "         NNS->meetings: 0.0007681840129932838,\n",
       "         NP+NNP->paris: 0.002674446875759786,\n",
       "         NN->hope: 0.00029937814881660096,\n",
       "         NN->freedom: 0.00016251956650044052,\n",
       "         VB->survive: 0.00040918204509186136,\n",
       "         S+ADJP+JJ->JJ: 0.3103448275862069,\n",
       "         VBZ->seems: 0.005689600674323043,\n",
       "         NP+NN->failure: 0.0003005936725031938,\n",
       "         JJ->current: 0.005783115431693601,\n",
       "         NN->public: 0.0005902026362384419,\n",
       "         NNS->media: 0.0018216935165269303,\n",
       "         VB->avoid: 0.0030279471336797743,\n",
       "         NP+NN->manipulation: 7.514841812579845e-05,\n",
       "         VB->replace: 0.001841319202913376,\n",
       "         NP+NNPS->soviets: 0.00796812749003984,\n",
       "         VBP->remain: 0.0038893690579083835,\n",
       "         NP+NN->charge: 0.002179304125648155,\n",
       "         NNS->programs: 0.003248320969228743,\n",
       "         JJ->former: 0.005091270334037005,\n",
       "         NN->head: 0.0005816489748436818,\n",
       "         JJ->african: 0.00035479235777261355,\n",
       "         JJ->military: 0.002057795675081159,\n",
       "         NP+NNS->executions: 0.00030646644192460924,\n",
       "         NP+NN->culture: 7.514841812579845e-05,\n",
       "         JJ->polish: 0.00030157350410672156,\n",
       "         NN->communist: 4.2768306973800133e-05,\n",
       "         VBZ->directs: 0.00042145190180170686,\n",
       "         NN->division: 0.0014797834212934846,\n",
       "         NN->staff: 0.0008468124780812426,\n",
       "         NP+CD->230: 0.0008301051466519093,\n",
       "         VBG->working: 0.00795470832736133,\n",
       "         JJ->actual: 0.0015610863741994997,\n",
       "         ADVP+RB->once: 0.005321443981015389,\n",
       "         NN->budget: 0.0012402809022402038,\n",
       "         NP+NN->nothing: 0.006988802885699256,\n",
       "         VP+VBN->changed: 0.01571338780641106,\n",
       "         NNP->john: 0.0031219361164146757,\n",
       "         NN->assistant: 0.00017962688928996058,\n",
       "         NN->secretary: 0.0005132196836856016,\n",
       "         NP+NN->state: 0.0005260389268805891,\n",
       "         VBD->told: 0.005393258426966292,\n",
       "         VBG->continuing: 0.0058764511967894515,\n",
       "         JJ->restrictive: 0.00015965656099767612,\n",
       "         ADVP+RB->soon: 0.007263051920034518,\n",
       "         RB->extremely: 0.0027809379345215524,\n",
       "         JJ->unlikely: 0.00047896968299302833,\n",
       "         ADVP+RB->much: 0.0015101395081259887,\n",
       "         NN->week: 0.005730953134489218,\n",
       "         ADVP+RB->even: 0.016827268804832447,\n",
       "         VB->agree: 0.0009820369082204673,\n",
       "         VB->raise: 0.00540120299521257,\n",
       "         NP+NNS->funds: 0.004826846460312595,\n",
       "         VBG->selling: 0.011967894510534614,\n",
       "         JJ->fancy: 0.00019513579677493746,\n",
       "         JJ->french: 0.0016143052278653918,\n",
       "         VBZ->owns: 0.0055315562111474025,\n",
       "         NNS->countries: 0.002743514332118871,\n",
       "         NNP->germany: 0.001677073120388049,\n",
       "         JJ->continued: 0.0005854073903248124,\n",
       "         NN->membership: 0.000316485471606121,\n",
       "         VBP->see: 0.005704407951598963,\n",
       "         JJR->stronger: 0.012490537471612415,\n",
       "         ...})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.pcfg.rule1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training.lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "config.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
